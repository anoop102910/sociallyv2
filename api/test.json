[
  {
    "A": "Problem Number",
    "B": "Description"
  },
  {
    "A": "1525",
    "B": "Innovating for Sustainability: Driving Smart Resource Conservation (Energy & Water) in Home Appliances (Refrigerators, Air Conditioners, Washing Machines and Desert Air Coolers)"
  },
  {
    "A": "1586",
    "B": "Smart Education, a Concept that Describes learning in digital age.it enables learner to learn more effectively,efficently,flexibly and comfortably."
  },
  {
    "A": "1587",
    "B": "Disaster Management includes ideas related to risk mitigation and Planning before,after or Duration of Disaster."
  },
  {
    "A": "1588",
    "B": "Technology ideas in tertiary sectors like Hospitality, Financial Services, Entertainment and Retail."
  },
  {
    "A": "1589",
    "B": "Provide ideas in a decentralized and distributed ledger technology used to store digital information that powers cryptocurrencies and NFTs and can radically change multiple sectors"
  },
  {
    "A": "1590",
    "B": "Innovative ideas that help manage and generate renewable /sustainable sources more efficiently."
  },
  {
    "A": "1591",
    "B": "A solution/idea that can boost the current situation of the tourism industries including hotels, travel and others."
  },
  {
    "A": "1592",
    "B": "Solutions could be in the form of waste segregation, disposal, and improve sanitization system."
  },
  {
    "A": "1593",
    "B": "There is a need to design drones and robots that can solve some of the pressing challenges of India such as handling medical emergencies, search and rescue operations, etc."
  },
  {
    "A": "1594",
    "B": "Submit your ideas to address the growing pressures on the city’s resources, transport networks, and logistic infrastructure"
  },
  {
    "A": "1595",
    "B": "Creating intelligent devices to improve the commutation sector"
  },
  {
    "A": "1596",
    "B": "Developing solutions, keeping in mind the need to enhance the primary sector of India - Agriculture and to manage and process our agriculture produce"
  },
  {
    "A": "1597",
    "B": "Cutting-edge technology in these sectors continues to be in demand. Recent shifts in healthcare trends, growing populations also present an array of opportunities for innovation."
  },
  {
    "A": "1598",
    "B": "Ideas that showcase the rich cultural heritage and traditions of India"
  },
  {
    "A": "1599",
    "B": "Ideas that can boost fitness activities and assist in keeping fit."
  },
  {
    "A": "1600",
    "B": "Ideas focused on the intelligent use of resources for transforming and advancements of technology with combining the artificial intelligence to explore more various sources and get valuable insights."
  },
  {
    "A": "1601",
    "B": "Challenges your creative minds to conceptualize and develop unique toys & games."
  },
  {
    "A": "1602",
    "B": "For use of travel or activities beyond earth's atmosphere, for purposes such as spaceflight or space exploration."
  },
  {
    "A": "1603",
    "B": "Design an autonomous water surface cleaning robot, to automate the task of cleaning water surfaces. These robots are particularly useful in environmental protection efforts, as they can perform high-efficiency cleaning without human intervention.\n \n It can be autonomous or remote-controlled. The robot needs to be lightweight and flexible for easy transportation. The specifications are as follows:\n Length × Height × Width - 2.5 m × 1.5 m × 0.75 m\n Weight - 80 kg\n Maximum Speed - 1.5 m/s\n Trash Payload - 25 kg\n Project submission must include conceptual sketches and images in the PPT presentation. At least one component must be optimized using the generative design module. The robot should incorporate Industry 4.0 applications, such as IoT and AI, for a smart and efficient cleaning solution.\n Teams choosing to submit idea for Autodesk’s problem statement are required to request their faculty (SIH SPOC) to fill this mandatory form. (https://forms.gle/KfBguyYGHmv5RQ778)\n Autodesk Fusion is a cloud-based 3D modeling, CAD, CAM, CAE, and PCB software platform for professional product design and manufacturing.\n Students and educators can click here to get FREE access to Fusion. (https://www.autodesk.com/education/edu-software/overview?sorting=featured&filters=individual)\n Participation Guidelines: For Idea Submission: Each student team will have to submit a PowerPoint presentation (5-7 Slides) about their project with conceptual sketches and images. No design files required at this stage and design should only be created during the Grand Finale\n \n For Grand Finale: Students must use Fusion to design autonomous water surface cleaning robot within the given time period and present the following to the jury members:\n PPT explaining the final project\n Public link of the design\n Rendered images and animations\n Note: Teams coming with pre-designed files will be disqualified.\n Marking Criteria: Please note that this marking criteria is for Autodesk's this particular Problem Statement only \n Design Objective:10\n Design Process:10\n Creativity and Novelty:30\n Software Usage:30\n Manufacturability:20\n Total marks:100"
  },
  {
    "A": "1604",
    "B": "Background:\nEver since the birth of AI and computer vision, modeling conversations remains one of the field’s challenges, especially to combine both natural language processing and image recognition. Chatbots are now widely used as part of platform as applications like Apple’s Siri, Google’s Google Assistant or Microsoft’s Cortana.\nDetailed Description:\nGenerally, a conversational Chatbot is an application that is able to communicate with humans using natural language. However there exists a need for an image recognition deep learning based Chatbot is an application to recognize the images, uploaded by user and answer the questions about the image. The main problem domain of this project is building a image recognization Chatbot, which is capable of recognize the object in an image and generating the best response for any the user’s query about the image.\nExpected Solution:\nImage recognition Chatbot is expected to detect the object in the image and have the related dialog of the image after training, also have understanding of the sender’s messages so that it can predict which sort of response will be relevant and it must be correct lexically and grammatically while generating the reply."
  },
  {
    "A": "1605",
    "B": "Background: The growing concern for the safety of women and the increase in crimes against women in various cities, highlight the need for advanced surveillance and analytical solutions to protect women from various possible threats. We need a promising approach to address these issues through real-time threat detection software.\nDetailed Description:\nBy leveraging advanced analytics through real-time monitoring, Women Safety Analytics should create safer environments for women and assist law enforcement in effectively addressing and preventing crimes against women. The proactive approach of detecting anomalies and generating alerts can play a crucial role in enhancing public safety and fostering a secure atmosphere for women.\nWomen safety analytics software should continuously monitor the scene to count the number of men and women present, offering insights into gender distribution in specific locations and times. It should identify unusual patterns, such as a lone woman at night, unusual gestures and generates alerts to pre-empt potential incidents.\nAdvantages of the system:\n? By providing real-time monitoring and alerts, the system helps to create a safer environment for women.\n? Early detection enables law enforcement to intervene before situations escalate.\n? Continuous analysis provides valuable data to identify hotspots and trends, aiding in strategic planning for city safety\nExpected Solution:\nWomen safety analytics should include the following functionalities\n1. Person detection along with Gender Classification\n2. Gender Distribution : Count the number of men and women present in the scene\n3. Identifying a Lone Woman at Night time\n4. Detection of a Woman Surrounded by Men\n5. Recognizing SOS situation through gesture analytics\n6. Identifying hotspots where incidents are more likely to occur, based on the past alerts"
  },
  {
    "A": "1606",
    "B": "Description: The world today has bought on a need to pay increased attention to safety and security issues, for example, search and rescue operations, surveillance, and protection of critical infrastructure. These tasks are often labour intensive and potentially dangerous. This provides an incentive to create systems that aid operators to gain situational awareness. In this regard, unmanned aerial vehicles, pose a significant threat to privacy and security. To understand and assess this threat, classification between different drone models and types is required. One way in which this has been demonstrated experimentally is through this use of micro-Doppler information from radars. Normally birds and drones are often confused and there is need for a method which clarifies their corresponding class.\nBackground: Due to substantial increase in the number of affordable drones in the consumer market and their regrettable misuse, there is a need for efficient technology to detect drones in airspace. Drone and birds both include micro-Doppler signatures due to their propeller blade rotation and wing beats respectively. These distinctive features can then be used to differentiate a drone from a bird, along with studying them separately.\nDetailed Description:\nClassification of drones and non-drones using micro-Doppler signatures captured from Radar as a sensor. Moving parts of an object produce modulated Doppler components called micro-Doppler. The modulated Doppler signature is presented as added components to the Doppler signature of the drone body. Due to rotating blades, frequency modulated components, which are quite revealing, are produced. To observe the time varying micro-Doppler’s, received FMCW should be processed by Joint time-frequency analysis.\nA Conventional air surveillance radar system(operating usually at L-Band or S-Band) can rely on the radar cross section(RCS) of an aircraft for detection, but this may not always provide reliable detection, but this may not always provide reliable detection in case of drones. Even if a dedicated system is built to be sensitive enough to detect small object like a drone, just RCS information is not adequate. Birds have similar physical size to drones and also will fly at similar altitude and speeds. A reliable drone detection radar system must have the capability to discriminate between a drone and a bird. And hence micro-Doppler signature analysis is the key parameter for classification.\nExpected Solution:\nInput: The micro-Doppler signatures of drones and bird\nOutput: Class of the object(Drone or Bird)"
  },
  {
    "A": "1607",
    "B": "Background: Urban areas often face significant traffic congestion, especially at intersections where multiple routes converge. Traditional traffic management systems rely on pre-set traffic light timings, which may not adapt well to fluctuating traffic conditions. This can lead to increased waiting times, fuel consumption, and emissions.\nDescription: An AI-based traffic management system can dynamically adjust traffic light timings based on real-time traffic data, improving traffic flow and reducing congestion.\nExpected Solution: Problem statement is to develop a smart, AI-based traffic management system that can monitor traffic conditions in real-time and adapt traffic light timings accordingly. The system should be capable of handling heavy traffic from multiple directions and optimizing traffic flow to minimize delays and improve overall efficiency."
  },
  {
    "A": "1608",
    "B": "Background: Gujarat has long been a leader in fostering innovation and entrepreneurship. The state is home to numerous research institutions, start-ups, and innovation hubs that drive economic growth and technological advancement. However, the current systems for monitoring and managing research activities, intellectual property rights (IPR), innovation developments, and start-up growth are fragmented and inefficient. Information is dispersed across various departments and organizations, leading to challenges in data accessibility, transparency, resource allocation, and overall management. To address these issues, there is a need for a comprehensive web application that can unify and streamline these processes, enhancing efficiency and productivity.\nDetailed Description:\nThe proposed comprehensive web application aims to address the key challenges faced in monitoring and managing research, IPR, innovation, and start-ups in Gujarat. The application will serve as a centralized platform to integrate various functions and provide seamless access to information and resources. The key features of the web application include:\nUnified Data Repository: A centralized database where all research projects, patents, innovations, and start-up information are stored and easily accessible.\nTransparent Monitoring: Tools for stakeholders to track the progress and outcomes of research projects, innovation developments, and start-up growth, ensuring greater transparency.\nEfficient Resource Allocation: Mechanisms to optimize the allocation of resources, such as funding and mentorship, based on real-time data and insights.\nIPR Management: A streamlined process for managing intellectual property rights, including patent applications, status tracking, and protection of intellectual property.\nSupport for Innovators and Start-ups: Access to resources, mentorship, and support services for innovators and entrepreneurs, facilitating their growth and success.\nCollaboration Tools: Features to enhance collaboration among researchers, innovators, policy makers, and other stakeholders, fostering a cohesive ecosystem.\nData-Driven Insights: Analytics and reporting tools to provide data-driven insights for policy makers and funding agencies to make informed decisions.\nThe application will cater to various users, including researchers, innovators, entrepreneurs, policy makers, investors, funding agencies, and IPR professionals. By integrating all these functions into a single platform, the application will address the inefficiencies and fragmentation currently hindering the growth and success of research and innovation in Gujarat.\nResearchers and Academics: Require a platform to manage and track their research projects, collaborations, and funding. \nInnovators and Entrepreneurs: Need a centralized system to access resources, support, and information related to their innovations and start-ups\nPolicy Makers and Government Bodies: Require data-driven insights to make informed decisions on resource allocation and policy formulation. \nInvestors and Funding Agencies: Need a transparent system to evaluate and support promising research projects and start-ups. \nIPR Professionals: Require an efficient system to manage patent applications, track IPR statuses, and protect intellectual property.\nExpected Solution:\nThe implementation of this comprehensive web application is expected to yield significant positive outcomes:\nCentralized Data Repository: Establishment of a unified platform where all relevant data is stored, reducing fragmentation and improving data accessibility.\nIncreased Transparency: Enhanced transparency in tracking progress and outcomes of various projects, facilitating better oversight and accountability.\nBetter Resource Utilization: More effective allocation and utilization of resources, leading to improved outcomes for research and innovation projects.\nAccelerated Innovation: Faster and more efficient innovation processes due to improved support systems and collaboration opportunities.\nEconomic Growth: Increased start-up success rates and innovation outputs, contributing to the overall economic growth of Gujarat.\nEnhanced IPR Protection: More efficient and effective management of intellectual property rights, reducing delays and improving protection for innovators.\nIn summary, the proposed web application aims to create a more efficient, transparent, and supportive environment for research, IPR management, innovation, and start-up growth in Gujarat. By addressing the current challenges and leveraging modern technology, the application will significantly enhance the state's capacity to foster and sustain innovation and entrepreneurship."
  },
  {
    "A": "1609",
    "B": "Background:\nAlumni associations play a pivotal role in fostering lifelong connections between graduates and their alma mater, facilitating networking, mentorship, and philanthropic support. However, many alumni associations face challenges in maintaining engagement, facilitating donations, and providing valuable services such as job networking and tracking alumni success stories. A comprehensive Alumni Association platform for a University/Institute, encompassing both web and mobile applications, aims to address these challenges effectively.\nDetailed Description:\nThe proposed Alumni Association platform for the Government Engineering College will feature robust functionalities accessible through both web and mobile applications:\nAlumni Registration: User-friendly registration processes on both web and mobile platforms, allowing alumni to join the association, update their profiles, and stay connected with peers and the institution.\nDonation Portal: Secure mechanisms on both platforms for alumni to contribute donations easily and support various initiatives and projects undertaken by the college, fostering a culture of philanthropy.\nNetworking Hub: Dedicated sections on both platforms to connect alumni based on shared interests, professions, and geographic locations, facilitating professional networking, mentorship, and collaboration opportunities.\nJob Portal: Integrated job search and posting features accessible via web and mobile apps, enabling alumni to explore career opportunities, post job openings, and connect with potential employers within the alumni network.\nAlumni Directory: Search functionalities available on both platforms to find alumni based on different criteria such as graduation year, field of study, industry, location, etc., promoting networking and community building.\nSuccess Story Tracking: Features on both web and mobile apps to showcase and track alumni achievements, success stories, and notable contributions to society, inspiring current students and fostering pride among alumni.\nEvents and Reunions: Announcements, registrations, and management tools available on both platforms for organizing alumni events, reunions, workshops, and professional development sessions to maintain engagement and connection.\nFeedback and Surveys: Channels on both web and mobile apps for alumni to provide feedback on their experiences, suggest improvements, and participate in surveys to help shape future initiatives of the association.\nThe platform will prioritize user experience, security, and scalability across both web and mobile applications to cater to the diverse needs of the Government Engineering College's alumni community.\nExpected Solution:\nImplementation of the Alumni Association platform for the Government Engineering College, comprising both web and mobile applications, is expected to achieve several positive outcomes:\nEnhanced Alumni Engagement: Seamless access to networking, career opportunities, and alumni events through web and mobile apps will strengthen connections among alumni, fostering a vibrant and active community.\nIncreased Philanthropic Support: Convenient donation processes accessible via both platforms will encourage alumni to contribute towards the college's growth and development initiatives.\nCareer Advancement: Access to job postings, mentorship opportunities, and professional networking on mobile devices will support alumni in their career growth and advancement.\nKnowledge Sharing: Exchange of knowledge, experiences, and best practices facilitated through both web and mobile apps will enrich professional development and lifelong learning initiatives.\nPride and Recognition: Highlighting alumni achievements and success stories on both platforms will instill pride in the alma mater and inspire current students to excel in their academic and professional pursuits.\nCommunity Building: Interactive features available on both web and mobile apps will nurture a sense of belonging and camaraderie among alumni, strengthening their bond with the institution.\nIn summary, the Alumni Association platform for the University/Institute, integrated with both web and mobile applications, aims to create a dynamic and supportive ecosystem where alumni can connect, contribute, and thrive, thereby enriching the overall educational experience and legacy of the institution."
  },
  {
    "A": "1610",
    "B": "Background:\n“Inclusivity” is the motto of Education department, Government of Gujarat. Opportunity for all is the new slogan and The Indian Government has come up with Indian Sign Language. There has been lot of work in done in American sign language and focusing on interpretation in English. Majority schools in India adopt local language. In Gujarat, the deaf and mute students would be learning Gujarati by sign language. There are two general methods of deaf education are manualism and oralism..The students learn at school but at home if they want to practice material in Digital form is in limited form especially considering Indian Sign Language and Gujarati as local language.\nDetailed Description:\nThe proposed comprehensive Mobile Application aims to address the key challenges faced in learning beyond classroom by deaf and mute students. The key features of the application include:\nInterpretation of Alphabets and numbers in Gujarati: Explaining the alphabets and numbers in Gujarati. The students first should learn and then should get writing pad to practice the writing of alphabets and numbers.\nWords and Sentences: Explaining the basic words starting from each Gujarati alphabet for example ? –???. Writing Exercises based on this\nMathematics : Tables. Basic calculation Sum, Subtract, Multiplication, division in Gujarati. Writing problems for assessment of learning.\nScience : Prepare learning of science principles to sign language tutorials and writing exercises based on this.\nConversion of Gujarati sentences to Sign Language and vice versa: If some Gujarati news/ articles are fed, they should be converted to sign language\nConversion of speech to sign Language and vice versa: If some Gujarati conversation/addressing is taking place, they should be converted to sign language\nData Analytics : Report card of the student to assess his/her learning of Mathematics and Science\nThe application will cater to various users, including teachers, students, parents and HR(company). By integrating all these functions into a single Application , the application will address the lack of resources and bridge of communication gap.\nTeachers: Get a platform for teaching and can give repeated exercises to fine tune students with Mathematics and science. . \nStudents: Learning platform where they can learn at their own pace and do the exercises.\nParents: Helping aid for parents who do not know sign language. \nHR: Inclusivity is part of company policy also. While interviewing speech to text and text to speech will be helpful.\nExpected Solution:\nThe implementation of this comprehensive Mobile application is expected to yield significant positive outcomes:\nLearning of Basic Mathematics and Science: Establishment of a unified platform where all relevant data is stored, reducing fragmentation and improving data accessibility.\nIncreased Communication: Enhanced transparency in tracking progress and outcomes of various projects, facilitating better oversight and accountability.\nBetter Assessment of learning: More effective allocation and utilization of resources, leading to improved outcomes for research and innovation projects.\nIncluding specially abled to mainstream : Conversion of text to sign language, speech to sign language and vice versa will narrow down the communication gap that arises due to non understanding of sign language.\nIn summary, the proposed Mobile application aims to create a more efficient and supportive environment for learning to deaf and mute students in Gujarat. By addressing the current challenges and leveraging modern technology, the application will significantly enhance the learning ability of specially abled students."
  },
  {
    "A": "1612",
    "B": "Background:\n Efficient bus scheduling and route planning are essential for the smooth operation of public bus transport services. Currently, the Delhi Transport Corporation (DTC) relies on manual methods for scheduling and planning, which are time-consuming and resource-intensive. To improve operational efficiency, reduce errors, and enhance service reliability, DTC needs an automated software solution capable of handling both linked and unlinked duty scheduling. Additionally, the solution should facilitate route management by mapping all existing routes and highlighting overlaps with proposed new routes. This project aims to develop a comprehensive software solution to streamline bus scheduling, optimize resource utilization, and improve route planning.\n Detailed Description:\n The Automated Bus Scheduling and Route Management System will utilize lgorithms, data analytics, and geographic information system (GIS) technologies to automate various aspects of bus scheduling and route management. The system will potentially include (but not limited to) features such as:\n Linked Duty Scheduling:\n Assign a specific crew to a bus at the start of their duty, ensuring they remain with the bus throughout their shift.\n Provide tools to manage and monitor crew and bus assignments for better familiarity and accountability.\n Unlinked Duty Scheduling:\n Allow crews to hand over buses to other crew members after assigned completing their trips.\n Manage rest periods for crew menbers and after their reassign them to different buses rest period.\n Route Management:\n Map all existing routes and provide a visual representation of the bus network.\n Enable users to draw new routes and automatically highlight overlaps with existing routes.\n Optimize route planning to reduce congestion and improve service coverage.\n Expected Output:\n A fully functional prototype of the Automated Bus Scheduling and Route Management System demonstrating the above features through the integration of algorithms, data analytics, and GIS technologies. The system will offer a user-friendly interface for schedulers, planners, and managers to interact with the system, manage schedules, plan routes, and access real-time data and reports."
  },
  {
    "A": "1613",
    "B": "Background:\nThis problem requires an innovative approach to enhance the efficiency and transparency of faculty self-appraisal in the university settings. Through a robust web-based platform, the system should address the complexities associated with traditional evaluation processes. It should capture and manages intricate details of faculty activities, encompassing research publications, event participation, seminars, projects, and lectures.\nThe project must aim to create a user-friendly environment for faculty members, optimizing the self-appraisal experience. Employing a secure registration and login system ensures data confidentiality and personalized access. The meticulous automated tracking of research outputs (as done automatically by google scholar) and academic engagements streamlines the evaluation process, providing a consolidated record for administrators.\nBy introducing features for logging events, seminars. projects, and lectures, the system offers a holistic view of faculty contributions beyond the classroom. This comprehensive solution should aligns with the objectives of modernizing appraisal methodologies, fostering a culture of continuous improvement, and supporting Paperless India motive.\nAdministrators, on the other hand, can leverage this data to make informed decisions about faculty development and resource allocation. University Administrators can log in to the Admin Panel and access all the form entries submitted by the faculty members. They can view all the details in the form, sort the form entries according to Name, Employee Code or Date of Submission. They can then download the form submission details in a PDF format. In contemporary academic institutions, the process of faculty self-appraisal plays a crucial role in ensuring quality education, fostering professional development, and aligning individual contributions with institutional goals. However, traditional appraisal methods often entail cumbersome paperwork, lack of transparency, and inefficiencies that can hinder comprehensive evaluation. This real-time application seeks to address these challenges by introducing a streamlined, web-based solution that enhances the efficiency and transparency of the appraisal process.\nThis innovative platform should be designed to meticulously capture and manage a wide range of faculty activity, including research publications (automatically as done by google scholar), event participation, seminars, projects, and lectures. By leveraging technology, the system should provide a user-friendly interface that facilitates easy logging and tracking of academic contributions. The secure registration and login system should ensure that faculty data remains confidential and accessible only to authorized personnel.\nMoreover, the platform should support administrators by offering a consolidated view of faculty performance. The Admin Panel should enable administrators to access, Sort, and download detailed appraisal data, thereby supporting informed decision- making regarding Faculty development and resource allocation. This digital approach should not only modernizes the appraisal process but also it should aligns with the broader objective of promoting sustainable and paperless administrative practices.\n\nDetailed Description:\nIn the dynamic landscape of higher education, the imperative for effective systems to evaluate and enhance faculty performance has become increasingly apparent. Existing approaches to faculty appraisal often lack transparency and a data-driven foundation, hindering the ability to recognize and promote excellence. This underscores the pressing need for an innovative solution. \nThe “Automated System for Career Advancements of the Faculties of Higher Education\"\" project should addresses this critical gap by introducing a comprehensive and dynamic platform. This application must empower faculty members to engage in a transparent and assessment self-driven of their professional activities.\nBy facilitating documentation and evaluation of contributions in teaching, research, and community engagement, the system must offer a transformative approach to performance appraisal within university context.\nThe project must offer numerous benefits to both faculty members and university administrators. Faculty should be able to maintain a detailed and organized record of their professional activities, helping them track progress and identify areas for improvement. Administrators, on the other hand, should leverage this data to make informed decisions about faculty development and resource allocation.\n\nExpected Solutions:\nThe primary objectives of the \"\"Automated System for Career Advancements of the Faculties of Higher Education\"\" are to alleviate the challenges inherent in traditional paper-based processes. This project must aim to streamline and modernize faculty self-appraisal by implementing a secure, user-friendly web-based platform. The key focus must be on reducing administrative burdens, minimizing time consumption through digital processes, and enhancing data accuracy.\nBy centralizing faculty information, the system seeks to provide administrators with efficient tools for evaluation, contributing to a more transparent and accountable appraisal process. Ultimately, the project aims to optimize the overall faculty assessment experience, fostering a culture of continuous improvement in higher education institutions.\nREAL-TIME APPLICATION\nFaculty should be able to update their activities, such as research publications, event participation, and seminars, in real-time, eliminating delays associated with traditional methods.\nThis dynamic system must ensure administrators have instant access to the latest information for timely and informed decision-making. The website's real-time capabilities enhance the overall efficiency of the faculty self-appraisal process, promoting a more agile and responsive approach to performance evaluation in the academic environment.\nSOFTWARE REQUIREMENT\n-Web Browser: Compatible web browser (e.g., Chrome, Firefox) for accessing and interacting with the Faculty Self-Appraisal Database Management Website.\n-Postman: Postman for testing API endpoints and ensuring seamless communication between the web application and server.\n-Git and GitHub: Git for version control and GitHub for collaborative development, facilitating efficient code management and collaboration.\n-VSCode: Visual Studio Code (VSCode) as the integrated development environment (IDE) for code editing, debugging, and project management during the development of the web application.\nHARDWARE REQUIREMENT\n-OS: Windows 10 or above or any other OS (e.g. Linux).\n-Processor (not minimum requirement): A modern quad-core or above for seamless and smooth development process of application. \n-RAM: At least 4 GB of available RAM to be able to run the Web App on the Browser.\n-GPU: Any GPU can be preferred.\n-Storage: Sufficient storage can be fulfilled by SSD or HDD.\nFUNCTIONAL REQUIREMENTS\n-User Authentication: Users must register and log in securely. Unique user profiles for faculty members and authorized administrators.\n-Data Collection Form: Implement a comprehensive \"\"SELF APPRAISAL FORM\"\" for faculty activities. Capture personal and professional details in a user-friendly interface.\n-Manage Database: Establish a secure database to store faculty self- appraisal data. Ensure efficient data retrieval and management for evaluation purposes.\n-Client-Side Scripting: Employ client-side scripting (e.g., JavaScript) for dynamic and responsive user interfaces. Enhance user experience with real-time form validation and interactive features.\n-Server-Side Scripting: Utilize server-side scripting (e.g.. Node.js, Python) for processing and storing data securely. Enable seamless communication between the front-end and back-end components.\n-Event Logging: Enable faculty to log events, seminars, projects, and lectures for a comprehensive assessment. Capture details to provide insights into faculty contributions beyond traditional metrics\nNON - FUNCTIONAL REQUIREMENTS\n-Performance: The system must respond promptly to user interactions, with minimal latency during data retrieval and form submissions.\n-Scalability: The web application should accommodate an increasing number of users and data entries without compromising performance.\n-Reliability: Ensure high system availability with minimal downtime for routine maintenance, updates, or unforeseen issues.\n-Security: Implement robust security measures, including encryption and access controls, to protect sensitive faculty data and maintain user privacy.\n-Usability: The interface must be intuitive and user-friendly, requiring minimal training for faculty members and administrators to navigate and use the system efficiently.\n\nThe implementation of the given problem must successfully address the longstanding challenges embedded in traditional paper-based faculty self-appraisal processes within higher education. The system must possess crucial features, such as secure user authentication, ensuring that faculty members and authorized administrators have unique and protected access to the platform.\nA comprehensive system should be seamlessly integrated, providing faculty members with a user-friendly interface to submit personal and professional details efficiently. The system must establishe a secure database, ensuring the confidentiality and integrity of faculty self-appraisal data. Robust client-side scripting, powered by JavaScript, it should enhance the user experience with dynamic and responsive interfaces, real-time form validation, and interactive features.\nMoreover, the system must include an admin panel that provides administrators with centralized access to all submitted appraisal forms. This panel must allow administrators to view, sort, and manage appraisal data efficiently. They can sort entries based on various criteria such as Name, Employee Code, or Date of Submission, streamlining the process of data retrieval and analysis. Additionally, administrators can download the submission details in PDF format, facilitating easy record-keeping and reporting."
  },
  {
    "A": "1614",
    "B": "Description:\n1. Background: For a much simplified and initial solution, input (publication record) can also be provided in a consolidated single bibtex file. However, it is desirable to provide input as an excel sheet, as mentioned earlier.\n2. Description: The proposed solution should be able to crawl different popular academic databases, like Google Scholar, DBLP, etc. Often it is desired to have a publication record in a specific period for submission to various accrediting agencies by HEI's; therefore solution may have a provision for such customized queries.\nExpected solutions: The desired solution is required for generating publication summary for faculty profile showcase. Following are the identified inputs and expected outcomes \nInput:\n1. Faculty names as mentioned in their respective academic profile (research papers) in an excel sheet\n2. Year-wise publication record in journals which is exportable in words and excel\n3. Year-wise publication record in conferences which is exportable in words and excel\n4. Customized publication records in a particular duration"
  },
  {
    "A": "1615",
    "B": "Background: For a much simplified and initial solution, input (publication record) can also be provided in a consolidated single .bibtex file. However, it is desirable to provide input as an excel sheet, as mentioned earlier.\nDescription: The proposed solution should be able. Instructor shall have educational resources files in different formats like pdf, word, etc. and hyper-links of relevant academic literature\nExpected solutions: The desired solution is required to:\n-Learning dashboard showing different reading statistics like reading time of a particular topic. Total finishing time of a particular skill. \n-The instructor should be able to easily create a learning path along with incorporating learning resources, as mentioned \"\"inputs.\"\" including videos.\n-Progress made by the learner should be continuously updated.\n-The desired solution must follow UX principles"
  },
  {
    "A": "1616",
    "B": "DPCC is using different stations at fixed sites for measurement of AQI and other pollution parameters. These fixed stations suffered from various limitations and generally do not give representative values e.g. station located near an industrial area will give higher readings due to proximity to such industrial area which may not be representative of the wider area. Similarly, a temporary construction site/activity near these fixed sites give higher pollution readings due to local reasons. The technological solutions may be required for capturing AQI values through mobile and other forms of stations. Drone would be one of the options where they can record real-time pollution parameters through on-board sensors."
  },
  {
    "A": "1617",
    "B": "Transport Sector - DTC is trying to work out various modules for route rationalization. The real-time monitoring of buses for effective route rationalization may be one of the challenges to prevent bunching of buses on a specific route or long delays in arrival of buses. The problem cannot be addressed by fixed time schedule owing to various factors like traffic Conditions, road conditions and other such factors. A dynamic route rationalization model based on machine learning/AI would be required based on real-time traffic and road parameters."
  },
  {
    "A": "1618",
    "B": "MCD is working on monitoring of unauthorized construction across th ecity. A viable and low cost solution is required e.g. Drone based surveys of swathes of land/areas as per defined time intervals will help real-time detection of unauthorized construction"
  },
  {
    "A": "1619",
    "B": "Technological solution for real-time survey and monitoring of water bodies in Delhi is one of the critical areas for rejuvenation of these water bodies"
  },
  {
    "A": "1620",
    "B": "Technological solution as per queuing models in OPDs/availability of beds/admission of patients would be one area. Study of dispensation of various types of medicines/consumables and Inventory management modules at hospital level are key areas requiring support. NIC has already developed some modules but their implementation in Delhi is yet to be started. A hospital based solution is ideal which can be integrated with city wide module may be required."
  },
  {
    "A": "1621",
    "B": "Suitable technological module for testing and monitoring of quality of medicines and consumables being received in hospitals would be required so that the system ensures necessary compilance and rejection of low quality supplies without manual intervention"
  },
  {
    "A": "1622",
    "B": "The issuance of Caste and other certificates by Revenue Department need real-time monitoring to evaluate the resource allocation and demand for such certificates. The allocation of resources at present is done without any analysis leading to huge backlogs in some Sub-divison where the application load is very high. Any effective monitoring at District and Central level with detailed evaluation shall enable providing better allocation of resources for issuanc of such certificates"
  },
  {
    "A": "1623",
    "B": "A real-time monitoring and evaluation software for application received in IFre Department relating to inspections, follow-ups, issue of NCOs and such licensing requirement so as to ensusre automatic system monitoring without any manual support."
  },
  {
    "A": "1624",
    "B": "Background:\nThe load profile of power requirement in NCT of Delhi is highly peculiar. We are witnessing huge load variations during the winter and summer months and also during day and night during the same 24-hour window. This causes imbalance in matching the requisite power purchase with the electricity demand.\nDescription:\nThe peak load in Delhi touched 8300 MW this summer while the minimum load during winters goes as low as 2000 MW. The peak during the summer months also occurs twice i.e. first during the day time at about 15:30 hrs and second time in night hours after 23:00 hrs.\nFurther, the solar generation comes during the day time and wanes by the evening hours thereby lending a Duck-curve effect. Solar plants have been allowed +/- 15% variation by CERC. Further, there is uneven load growth in the city, the upcoming areas are witnessing huge load growth while the developed areas are having the lower organic load growth. In addition to that the load curve in Delhi is highly peaky in nature due to the fact that most of the load is domestic and commercial load while industrial load is minimal. Here it may be taken note that while in other States, industrial load which is 24 x 7 in nature lends stability to the overall load curve of the State. Further, in Delhi agricultural load is minimal. In bigger States, having considerable agricultural load, the supply on agricultural feeders is normally given when ample power is available at cheaper rates, especially during early morning hours/ night hours, which in -turn provides stability to the State' Transmission and Distribution network and also balances power purchase stipulation. Most of the Long Term power is available RTC (Round the Clock) and Slot-wise power is more expensive.\nExpected Solution:\nAn Artificial Intelligence based model be developed with suitable compensation methodology to factor the weather effects (like temperature humidity, and wind speed, rains/showers), public holidays/ weekly holidays, natural load growth, and real estate development."
  },
  {
    "A": "1625",
    "B": "Background: In modern educational settings, managing classrooms efficiently while ensuring a conducive learning environment is crucial. Traditional methods of classroom management are often manual, time-consuming, and prone to human error, which can disrupt the learning process. Leveraging software-based solutions in classroom management can enhance operational efficiency, ensure safety, and create an engaging learning atmosphere for students. This project aims to develop a smart software solution to streamline classroom operations, improve resource utilization, and enhance the overall learning experience.\nDetailed Description: The Smart Classroom Management Software (SCMS) can utilize advanced algorithms, data analytics, and cloud-based technologies to automate various aspects of classroom management. The system can potentially include (but not limited to) features such as:\n1. Attendance Automation:\nUse facial recognition algorithms or mobile app-based check-ins to automatically record student attendance.\nGenerate real-time attendance reports accessible by teachers and administration.\n2. Resource Management:\nTrack the usage of classroom resources such as projectors, computers, and other teaching aids through a centralized software platform.\nAutomate the scheduling and maintenance of these resources to minimize downtime.\n3. Safety and Security Alerts:\nImplement software-based alerts for emergencies such as fire, unauthorized access, or other security concerns, integrated with existing security systems.\nAlert authorities and stakeholders through real-time notifications and reports.\n4. Interactive Learning Tools:\nIntegration with existing smart boars and interactive displays to adapt to the teaching content and student needs.\nProvide real-time feedback and analytics on student engagement and performance.\n5. Data Analytics:\nCollect and analyse data on various classroom activities to provide insights into student behaviour, attendance patterns, and resource utilization.\nGenerate predictive reports to aid in decision-making and improve educational outcomes.\nAI-based Chabot for helping students to understand their learning gaps.\nExpected Output:\nA fully functional prototype of the Smart Classroom Management Software (SCMS) demonstrating the above features through the integration of advanced algorithms, data analytics, and cloud-based technologic.\nA user-friendly interface for students, (teachers and administrators to interact with the system and access reports."
  },
  {
    "A": "1626",
    "B": "Hospitals/Departments shall be able to enter and Update Data in the Mobile Application which can be viewed by the Super Admin dynamically for efficient Implementation of Health and Family Welfare Schemes, other Health programmes and provide key inputs for policy formulation and appropriate programme interventions. This Mobile Application will facilitates the flow of physical performance from the Facility level to the Sub-district, District and State/Union Territory level using Health Data Information & Management System Mobile Application (HDIMS) interface"
  },
  {
    "A": "1627",
    "B": "With the aim to provide \"Right Quantity of \"Right Product\" on \"Right Place\" on \"Right Time\" in \"Right Condition\" at \"Right Cost\" for \"Right People\" and also to streamline the distribution of drugs to institutions and ensure availability of drugs at all times, a new, innovative system named Drug Inventory and supply chain Tracking system is required:\n To improve efficiency and effectiveness of procurement and distribution systems through robust quality controls\n To provide dashboard based online monitoring of all activities at each level\n Tracking of vendor activities like preparation of Supply Order, Shipment etc.\n Monitoring of Drug consumption pattern at the Hospitals/Medical Institutions Level"
  },
  {
    "A": "1628",
    "B": "Project Concept: Comprehensive Employment Platform/Portal\nThe current employment portal lacks a personalized and adaptive approach to job matching and skill development. There is a need for an intelligent system that not only matches job seekers with potential employers but also identifies and suggests training courses to bridge skill gaps. We wish to design a competency diagnostic which would ask a series of questions to students to test their competence and based on their scores in the test, recommend jobs to them and also appropriate training courses to them to cover the gaps in their skill curve.\nRequirements:\n1. AI-Powered Job/Training Recommendation System:\n• Implement an AI-based recommendation system trained on multiple data points (e.g., skills, experience, preferences) to analyze job seekers' profiles and recommend suitable job opportunities.\n• Training Course Recommendations: Suggest relevant online courses, workshops, and training programs based on the desired job roles.\n2. Skill Gap Analysis and Recommendations:\n• Gap Identification: The recommendation System should assess job seekers' competencies against the requirements of their desired job roles to identify areas for improvement.\n• Personalized Suggestions: Provide tailored recommendations for online courses, workshops, and training programs to help job seekers upskill and close identified gaps.\n3. Adaptive Learning Pathways:\n• Personalized Learning: Develop adaptive learning pathways based on the job seeker's progress and feedback.\n• Content Variety: Offer a mix of micro-courses, webinars, and hands-on projects relevant to the job market to enhance learning and skill development.\n4. Real-Time Job Market Insights based on candidate’s skills and competencies:\n• Dashboard: Create a dashboard displaying real-time data on trending jobs, skills in demand, and salary benchmarks.\n• Data Analytics: Use data analytics to provide insights into job market trends and forecast future skill requirements.\n5. Skills Verification and Certification:\n• Skill Assessments: Implement a system for verifying skills and certifying competencies through assessments and tests.\n• Badges and Certifications: Offer badges and certifications that candidates can display on their profiles and share on social media platforms like LinkedIn.\n6. Resume Wizard\n• Automated Resume Building: Develop a resume wizard to help candidates automatically build their resumes based on their profiles, ensuring a professional and comprehensive presentation of their skills and experiences.\n7. Community and Peer Support:\n• Community Forum: Integrate a community forum where individuals can share experiences, ask questions, and receive support from peers and mentors.\n• Virtual Events: Organize virtual events, workshops, and webinars focused on employment and career development, including special sessions for people with special needs.\nExpected Outcome: The system will facilitate a personalized job matching process and offer targeted skill development recommendations, helping job seekers become more competitive in the job market.\nNOTE : This is an innovation opportunity and students are encouraged to think out of the box to develop solutions which can be presented in newer ways + which can address the needs in out of the box ways for a certain industry OR makes the platform generic. Above description serves as a guide to specify essential needs that can be satisfied for the developed solution and is not limited only to the scope described"
  },
  {
    "A": "1629",
    "B": "Project Concept : Freelancing Opportunities for India\nThere is a significant gap in connecting freelancers and gig workers with short-term and project-based job opportunities. An platform like upwork is needed to seamlessly connect freelancers with employers and provide tools for managing freelance projects.\nRequirements:\n1. Freelance Job Marketplace:\n• Develop a marketplace where freelancers can find short-term jobs, gig work, and project-based opportunities.\n• Allow employers to post projects, specify requirements, and invite freelancers to apply.\n2. Freelancer Profile and Portfolio Management:\n• Enable freelancers to create detailed profiles showcasing their skills, experiences, and portfolio of past work.\n• Integrate a rating and review system for feedback on completed projects.\n\n3. Extensive Search & Analytics\n• Enable Employers/Freelancers to do extensive search in the available data / generated data.\n• Generation of AI enabled insights into the Data and providing newer ways of information availability for job seekers / employers to engage.\n• AI based Recommendation Systems for seeking opportunities\n\n4.Escrow Account Creation\n• Create provisions for an escrow account that can be used to hold the money until the job is fully delivered.\n• Integrate secure payment gateways to facilitate smooth financial transactions between employers and freelancers. \n\nExpected Outcome: The platform will connect freelancers with a wide range of job opportunities and provide them with tools to manage projects efficiently, leading to better job satisfaction and increased income opportunities.\nNOTE : This is an innovation opportunity and students are encouraged to think out of the box to develop solutions which can be presented in newer ways + which can address the needs in out of the box ways for a certain industry OR makes the platform generic. Above description serves as a guide to specify essential needs that can be satisfied for the developed solution and is not limited only to the scope described"
  },
  {
    "A": "1630",
    "B": "Project Concept: Mentoring - The best way\nMentoring during the Career/Education is a vital aspect for success of a candidate and this can achieve amazingly positive changes in the life of a mentee. Today , India is known due to its demographic advantage and career directions are infinite. However newer directions are demanding candidates to be coached and mentored for progress. This application or platform can be developed by students understanding this knowledge development need and bring together mentor and mentees. \nCreate a platform where candidates can connect with mentors based on the availability of the mentors and mentors should be able to help candidates with their queries and concerns around careers, skill development etc. Mentors could be senior leaders from the industry or could be subject matter experts who have spent appreciable time in the industry and are aware of intricacies around jobs in a specific industry.\nRequirements:\n1. Create an automated calendar booking system:\n• Booking Automation: Develop an automated calendar booking system that that could create bookings automatically with a mentor based on the mentor’s availability and schedules appointments with mentors based on their availability. The system will check mentors' calendars and automatically find and book suitable time slots for meetings.\n• User-Friendly Interface: Provide a simple, intuitive interface for candidates to select their preferred time slots, ensuring easy and efficient scheduling.\n• Integration with Calendly: Consider integrating with existing tools like Calendly to leverage their robust scheduling capabilities.\n2. Embedded video call feature:\n• Video Call Integration: Embed a video call feature within the platform to facilitate virtual meetings between mentors and candidates.\n• Chat Functionality: Incorporate a chat feature within the video call to allow text-based communication during the session, enabling the sharing of links, documents, and other resources.\n• Secure and Reliable: Ensure the video call and chat functionalities are secure, reliable, and easy to use.\nExpected Outcome: The platform will help connect candidates with mentors from the industries and thereby increase their chances of employment through expert guidance and referrals.\nNOTE : This is an innovation opportunity and students are encouraged to think out of the box to develop solutions which can be presented in newer ways + which can address the needs in out of the box ways for a certain industry OR makes the platform generic. Above description serves as a guide to specify essential needs that can be satisfied for the developed solution and is not limited only to the scope described"
  },
  {
    "A": "1631",
    "B": "Background: \nThere are numerous engineering and polytechnic institutes in Rajasthan running under the Department of Technical Education, Government of Rajasthan. Notably, during the admission process, there is a significant increase in enquiries from various groups, including students, their parents, and other stakeholders. These enquiries cover a wide range of queries related to admission process, eligibility criteria, information about different colleges, fee structure, curriculum , scholarship , hostel facilities, previous year's college and branch-specific allotments placement opportunities and many more. \nCurrently, stakeholders have tocontact colleges individually through phone or email, and sometimes even visit the colleges personally. This process is not only cumbersome for the stakeholders but also demanding to pool manpower for the colleges to manage these inquiries. \nDetailed Description: \nWith the continuous rise in enquiries, it is becoming increasingly difficult for the colleges to respond promptly and effectively using traditional communication methods. To address this issue more efficiently and ensure timely assistance for everyone, there is a \npressing need to adopt new technological solutions. One effective approach is to develop an \nAI-powered chatbot at centralized level that would serve as a virtual assistant, available 24/7 to answer a wide range of questions. By automating responses to common enquiries, the chatbot would significantly enhance the accessibility to important information and allow staff to focus on handling more complex queries and other critical tasks. For example, the chatbot would provide insights into information about various engineering and polytechnic colleges that falls under the jurisdiction of Department of Technical Education, and guide users through the admission processes, explain fee structures, share curriculum updates, provide details about available scholarships, share alumni information, and share information on job placement opportunities etc \nThis will empower the technical education department because of the ease of providing information, help and advice instantly to prospective students, their parents, and all interested parties. The required information provided by all colleges can be integrated with ease in software. \nExpected Solutions: \n1. Efficient Information Retrieval: The chatbot should rapidly access and provide accurate information from a comprehensive database on topics such as admissions, fees, scholarships, recommendations based on previous years cutoff, minimizing the need for human assistance. Incorporate Natural Language Processing (NLP) to support voice based assistance in English languages and can be extended in Hindi and other regional languages ensuring wide accessibility and understanding. \n2. Enhanced User Experience: Design an intuitive interface that allows users to navigate easily and find information quickly. The interface should be straightforward, accessible on common platform, and capable of understanding natural language, ensuring user-friendliness. \n3. Reduced Workload: By automating responses to Frequently Asked Questions (FAQ’s), the chatbot will reduce the workload on department staff, allowing them to concentrate on more complex and urgent tasks. \n4. Data Insights: The chatbot will gather valuable data from user interactions, helping the department to identify common concerns and optimize it’s services based on these insights."
  },
  {
    "A": "1632",
    "B": "Background: \nIn today's competitive job market, graduates are encountering enormous challenges while their transition from education to employment. Most of the existing platforms do not provide access to a wide array of job opportunities comprehensively. This limitation spans both the private and government sectors, as well as international employment avenues. Another critical shortcoming is the lack of essential resources such as counselling and guidance facilities. Additionally, there is insufficient support for students seeking internships and industrial training. \n\nDetailed Description: \nThis platform shall offer a holistic approach to job searching and career development. It focuses on: \n· Advanced algorithms and AI-driven matchmaking through connecting job seekers with employers. \n· Extensive access to job opportunities across various sectors and regions including Private sector, Government sector and Overseas Employment \n· Counseling Services and Guidance Resources \n· Emphasis on securing internships and industrial training opportunities. \n· Mentorship Programs: Pairing with industry professionals for guidance \n\nExpected Solution: \nTo address the challenges faced by graduates in the modern job market, we propose the development of a comprehensive and integrated platform that will: \n\n1. Enhance Job Market Connectivity: \n· Establish a robust and interactive platform that bridges the gap between job seekers and potential employers. \n· Utilize advanced algorithms and AI to match candidates with suitable job opportunities based on their skills, qualifications, and preferences. \n2. Expand Access to Opportunities: \n· Provide a centralized portal offering exhaustive listings of job opportunities private sector, government sector and overseas employment opportunities \n· Ensure that the platform is updated regularly with diverse and current job listings to maximize employment possibilities for job seekers. \n3. Offer Comprehensive Critical Resources: \n· Integrate a suite of resources tailored to job seekers, including professional counseling and career guidance services. \n· Provide tools and resources for resume building, interview preparation, and job application processes. \n4. Improve Student Support: \n· Implement dedicated sections for internships and industrial training opportunities to assist students in gaining practical experience. \n· Offer mentoring and support services to guide students through the process of securing \ninternships and navigating early career challenges. \n\nBy implementing this comprehensive solution, the platform will significantly enhance graduates connectivity with potential employers, broaden their access to diverse job opportunities, and provide the critical resources and support needed to succeed in the modern job market."
  },
  {
    "A": "1633",
    "B": "There is a demand for comprehensive Alumni Student interaction platform for Technical Education Department, Govt. of Rajasthan that can strengthen connections between alumni and current students. \nFollowing are the issues currently faced: \n? Lack of Centralized System: Technical education currently lacks a centralized system for \ntracking and updating alumni information, including contact details, specialization, and career paths, which resulting into lack of effective communication and engagement. \n? Need for Structured Interaction: Without organized platforms, students lack opportunities \non valuable real-world experiences and mentorship from alumni. \n? Need for Motivation and Guidance: Many students lack motivation and guidance for clarity in career path . Alumni can be essential mentors and role models, providing insights and advice based on their experiences. \nDescription: \nThis problem aims to establish a platform at Technical Education Department, Govt. of Rajasthan to provide interaction and collaboration among alumni and current students, focusing on: \n? Enhancing Alumni Engagement: Increase alumni involvement with the institution and its \nstudents. \n? Providing Mentorship and Guidance: Inspire students with real-world insights and career \nguidance from alumni. \n? Building a Supportive Network: Develop a robust network for lifelong connections and \ncollaborative opportunities, creating an ecosystem where alumni and students can learn from and support each other. \nThis innovative platform should leverage advanced technologies such as artificial intelligence, machine learning, natural language processing (NLP), etc.. By leveraging these advanced technologies, the platform can significantly enhance its functionality and user experiences such as suggest connections between students and alumni with similar interests or career paths, industry, and skills. \nExpected Solutions: \n? Create an Alumni Database: Develop a centralized database to store and update information on alumni, including their employment status, contact details, educational and professional achievements, and areas of expertise. \n? Build an Engagement Platform: Design and implement an online platform for alumni and \nstudents to connect, interact, and collaborate. This platform should support: \n? Discussion forums \n? Mentorship programs \n? Career guidance sessions \n? Placement assistance \n? Academic support \n? Conduct Interaction Sessions: Organize regular interaction events, such as: \n? Alumni meetups \n? Online webinars \n? Panel discussions \n\nThese sessions will provide students with opportunities to learn from alumni, seek advice, and expand their professional networks. Further, the platform shall detect and prevent fake profiles or fraudulent activities on the platform using blockchain or any authenticated technique. It shall detect and filter inappropriate or harmful content in forums, comments, and user profiles. It may integrate AI-driven chatbots to answer common questions, provide guidance, and assist students with navigating the website."
  },
  {
    "A": "1637",
    "B": "Background: Farmers often face challenges in accessing markets, leading to lower income due to middlemen. This gap restricts their ability to sell produce at fair prices.\nDescription: Create a mobile application that connects farmers directly with consumers and retailers. The app should include features for listing produce, negotiating prices, and managing transactions, thereby reducing dependence on intermediaries.\nExpected Solution: A user-friendly mobile platform that enables farmers to showcase their products and connect with buyers directly, enhancing their income potential."
  },
  {
    "A": "1638",
    "B": "Background: Crop diseases can devastate yields, leading to significant financial losses for farmers. Early detection and timely intervention are crucial for effective management.\nDescription: Develop an AI-driven system that analyzes crop images and environmental data to predict potential disease outbreaks. This system will provide farmers with actionable insights and treatment recommendations to mitigate risks.\nExpected Solution: A mobile and web-based application that utilizes machine learning algorithms to identify crop diseases and suggest preventive measures and treatments based on real-time data."
  },
  {
    "A": "1639",
    "B": "Background: Excessive and improper use of fertilizers leads to soil degradation and reduced agricultural productivity, negatively impacting farmers’ income.\nDescription: Create a data-driven solution that recommends optimal fertilizer types and quantities based on soil health, crop type, and weather patterns, ensuring sustainable agricultural practices.\nExpected Solution: An application that analyzes soil data and provides tailored fertilizer recommendations, promoting sustainable farming while enhancing crop yield and farmer income."
  },
  {
    "A": "1640",
    "B": "Background: Farmers often face uncertainties in market access, leading to fluctuating incomes. Contract farming can provide stability by ensuring farmers have guaranteed buyers for their produce.\nDescription: Develop a comprehensive platform that facilitates assured contract farming agreements between farmers and buyers. This platform will enable transparent communication, secure contracts, and timely payments, ensuring farmers have a reliable market for their crops.\nExpected Solution: An online marketplace that connects farmers with potential buyers, offering tools for contract management, price negotiation, and secure payment processing, thereby enhancing income stability and reducing market risks"
  },
  {
    "A": "1641",
    "B": "Description: Problem Overview\nEducational institutes generate vast amounts of data each year, including academic performance, research publications, financial statements, infrastructure developments, student and faculty achievements, and extracurricular activities. Preparing a comprehensive and insightful annual report that accurately reflects the institute's accomplishments and growth is a complex and time-consuming task. It requires the aggregation, organization, analysis, and presentation of diverse data sources in a coherent and visually appealing manner.\nChallenge\nDesign and develop a user-friendly, efficient, and robust portal that streamlines the process of preparing the annual report for an educational institute. The portal should facilitate the collection, integration, analysis, and visualization of data from various departments and stakeholders within the institute. The goal is to create a dynamic, interactive, and automated system that minimizes manual effort, enhances accuracy, and provides valuable insights.\nKey Features and Requirements\nUser Authentication and Role Management:\nSecure login for different user roles (administrators, faculty, students, etc.).\nRole-based access control to ensure data privacy and security.\nData Collection and Integration:\nImport data from various sources (databases, spreadsheets, surveys, etc.).\nIntegration with existing systems (student management systems, financial software, research databases, etc.).\nSupport for manual data entry where necessary.\nData Analysis and Visualization:\nTools for analyzing academic performance, research output, financial data, and other metrics.\nCustomizable dashboards for visualizing key performance indicators (KPIs).\nGraphs, charts, and other visual aids for presenting data trends and insights.\nReport Generation:\nAutomated generation of the annual report in various formats (PDF, HTML, etc.).\nCustomizable templates for different sections of the report.\nInclusion of multimedia elements (images, videos, infographics).\nCollaboration and Feedback:\nFeatures for collaborative editing and review of report content.\nMechanisms for collecting feedback from stakeholders.\nVersion control to track changes and maintain document integrity.\nUser Experience:\nIntuitive and user-friendly interface.\nResponsive design for accessibility on various devices (desktop, tablet, mobile).\nMultilingual support for institutes with diverse language needs.\nCompliance and Standards:\nAdherence to relevant educational and reporting standards.\nData security and privacy compliance with regulations (GDPR, FERPA, etc.).\nExpected Outcomes\nParticipants are expected to deliver a functional prototype of the annual report preparation portal that demonstrates the core features and addresses the outlined requirements. The solution should be scalable, adaptable to different types of educational institutes, and capable of handling large volumes of data."
  },
  {
    "A": "1642",
    "B": "Background: The AYUSH sector, encompassing Ayurveda, Yoga & Naturopathy, Unani, Siddha, and Homoeopathy, is burgeoning with innovative startups. However, these startups face challenges in registering their ventures due to cumbersome, opaque, and decentralized processes. An efficient registration portal is crucial for fostering growth, facilitating regulatory compliance, and promoting the integration of AYUSH solutions into mainstream healthcare.\nDescription: Participants are tasked with creating an AYUSH Startup Registration Portal that simplifies and accelerates the registration process. The portal should be user-friendly, secure, and capable of handling a high volume of registrations. Key features must include:\nUser Authentication: Secure login for startups, government officials, and other stakeholders.\nApplication Submission: Streamlined forms for submitting registration applications, with clear instructions and guidelines.\nDocument Upload: Easy upload and management of necessary documents, ensuring compliance with AYUSH regulations.\nStatus Tracking: Real-time tracking of application status, notifications, and updates for applicants.\nData Management: Efficient handling and storage of startup data, ensuring privacy and security.\nSupport and Resources: Access to resources, FAQs, and support for startups during the registration process.\nExpected Outcome: The expected solutions should deliver a functional, scalable, and secure portal that addresses the current inefficiencies in the AYUSH startup registration process. The portal should enhance user experience, reduce processing times, and ensure compliance with regulatory requirements. Participants should demonstrate innovation in user interface design, data security measures, and integration with existing AYUSH databases. The ultimate goal is to empower AYUSH startups, enabling them to contribute more effectively to the healthcare ecosystem."
  },
  {
    "A": "1643",
    "B": "Problem Overview\nInnovation is a key driver of growth and success in educational institutions. Tracking and measuring innovation excellence is essential for fostering a culture of continuous improvement, recognizing achievements, and guiding strategic decisions. However, identifying, quantifying, and presenting innovation indicators can be challenging due to the diverse nature of activities, projects, and contributions across different departments.\nChallenge\nDesign and develop a comprehensive and user-friendly portal that tracks, measures, and showcases innovation excellence within an educational institute. The portal should aggregate data from various sources, provide insightful analytics, and present key innovation indicators in an intuitive and visually appealing manner. The goal is to create a dynamic system that encourages participation, facilitates data-driven decision-making, and highlights the institute's innovative achievements.\nKey Features and Requirements\nUser Authentication and Role Management:\nSecure login for different user roles (administrators, faculty, students, etc.).\nRole-based access control to ensure data privacy and security.\nData Collection and Integration:\nImport data from various sources (research projects, grants, publications, patents, competitions, etc.).\nIntegration with existing systems (research management systems, funding databases, project management tools, etc.).\nSupport for manual data entry where necessary.\nInnovation Indicators:\nDefine and track key innovation indicators (e.g., number of research papers published, patents filed, grants received, startups incubated, awards won).\nCustomizable indicators to cater to different departments and areas of innovation.\nData Analysis and Visualization:\nTools for analyzing innovation data and identifying trends.\nCustomizable dashboards for visualizing key innovation indicators.\nGraphs, charts, and other visual aids for presenting data trends and insights.\nRecognition and Incentives:\nMechanisms for recognizing and rewarding outstanding innovation contributions.\nHighlighting top-performing individuals, teams, and departments.\nGenerating reports and certificates of achievement.\nCollaboration and Feedback:\nFeatures for collaborative data entry and review.\nMechanisms for collecting feedback from stakeholders.\nVersion control to track changes and maintain data integrity.\nUser Experience:\nIntuitive and user-friendly interface.\nResponsive design for accessibility on various devices (desktop, tablet, mobile).\nMultilingual support for institutes with diverse language needs.\nCompliance and Standards:\nAdherence to relevant educational and reporting standards.\nData security and privacy compliance with regulations (GDPR, FERPA, etc.).\nExpected Outcomes\nParticipants are expected to deliver a functional prototype of the innovation excellence indicators portal that demonstrates the core features and addresses the outlined requirements. The solution should be scalable, adaptable to different types of educational institutes, and capable of handling large volumes of data."
  },
  {
    "A": "1644",
    "B": "Background: India faces a complex challenge in balancing its reliance on coal for energy with its climate change commitments. Coal mining is a major source of carbon emissions, a greenhouse gas contributing to global warming. To achieve carbon neutrality, the Indian coal sector needs to offset its emissions. This can be done through a combination of strategies like reducing emissions from mining activities, adopting cleaner technologies, and offsetting remaining emissions by planting trees that absorb carbon dioxide. A web-based application can be a powerful tool in this journey by helping quantify a mine's carbon footprint and evaluate potential pathways to carbon neutrality.\nDescription: \nThe web based application will have following objectives:\nActivity wise quantification of Carbon emission in Coal Mines\nEstimation of existing Carbon Sinks\nGap analysis between C emission and sinks and suggesting pathways to carbon neutrality\nExpected Solution:\nA comprehensive software solution that includes:\nEmission estimation: The app would allow users to input data on various mining activities (e.g., excavation, transportation, equipment usage) and estimate the associated carbon emissions based on establishd emission factors. Estimation of Per Capita emissions of a Mine.\nCarbon Neutrality Pathways: The app could offer features for simulating different emission reduction strategies like:\nClean technologies: Assessing the impact of adopting electric vehicles, methane capture systems, and renewable energy sources for mine operations.\nAfforestation offsets: Calculating the amount of land required for tree plantation to offset remaining emissions based on state specific afforestation plan and Carbon emission reduction.\nOther Renewables: explore alternative use of energy to reduce direct electricity consumption.\nAny other pathways:\nCarbon Credits: Estimation of potential Carbon credit earned as per present market rates.\nData visualization: The app should present results visually, using charts and graphs to track emission trends and the effectiveness of implemented strategies.\nScalability: Design the app to accommodate different mine sizes and types (underground vs open-cast).\nBenefits:\nTransparency: Providing a clear picture of a mine's carbon footprint.\nDecision support: Helping mine operators make informed choices for emission reduction.\nCost savings: Identifying opportunities to optimize operations and potentially reduce costs associated with emissions.\nSustainability goals: Aiding Indian coal mines in their journey towards carbon neutrality and supporting the country's overall climate goals."
  },
  {
    "A": "1645",
    "B": "Background:\nDespite the thrust on energy transition from fossil fuel sector to a cost-competitive renewable energy sector, Coal will remain pivotal to energy security of the nation in near future. India is targeting for 1.5 Bt coal production by 2030 to cater to the burgeoning energy needs of the country. To achieve the target, improved productivity and safety in coal mining is pivotal.\nDescription:\nThe problem statement is divided into two parts: one is Digital shift handover log system and other is safety management plan as per DGMS guidelines.\nA digital shift handover log system is a valuable tool for streamlining and improving the transition of responsibilities and information from one shift to the next within an organization.\nThe problem statement envisages that an app based and web based Shift handover log system be developed as per the Statutory and non-statutory log format currently in practice, which is presently being done manually through paper logs. This will ensure sharing of critical information and briefing of the next shift digitally. It will provide supervisors and operators with an immediate, comprehensive overview of the outgoing shift’s activities.\nManual Shift handover causes loss of time and thus productivity of the mining operation. Also, some important information regarding safety may get skipped in the manual system which can cause serious damage to mining operation or loss of life.\nDigitalised system will ensure that all red flags are properly briefed and major actions which needs to be taken in the next shift is communicated to the shift in charge of next shift beforehand so that he can mentally prepare for the same.\nThis will save time in the forthcoming shift and ensure better productivity. It will also ensure better safety and monitoring of the mine.\nEvery mine has to prepare a Safety Management Plan (SMP) as per DGMS guidelines. This SMP is based on Hazard identification and devising control and monitoring mechanism and fixing responsibility. This SMP implementation needs to be digitalised in the software for better management of risks. \nAlso, this app or web based solution needs to be integrated with ERP software. While designing the software, due care should be given to data security. \nPossible Solution:\nAn app and web based application can be developed for every type of log book currently in use by supervisors and operators in mining operation and digitalising the Safety Management Plan currently being implemented by mine owners as per DGMS guidelines.\nAlso the application should be able to streamline communication by automatically converting shift logs into organized PDF reports."
  },
  {
    "A": "1646",
    "B": "Background: CMPDI is the nodal agency for assessing and monitoring of the various R&D projects funded by CIL and S&T projects funded by S&T. The monitoring of each projects is performed by checking the financial and physical progress certificates submitted in prescribed forms as per S&T guidelines. It also intervenes in case any hindrances are observed /expected which can affect the project activities and timeline. \nThe projects are classified in two, based on its funding i.e. S&T projects funded by MoC and R&D projects funded by CIL. The progress of the S&T projects is being monitored in the various Meetings such as Technical Subcommittee meeting, and SSRC meeting for S&T projects, and that of R&D projects in Apex Committee and R&D Board. The directions/ instruction/suggestion given in the above meetings are to be updated for each projects. \nAs per guidelines, the PI of the projects has to submit the quarterly progress reports along with fund utilisation reports or time extension or additional funds in prescribed forms. \nThe projects wise information’s/ quarterly progress reports of about more than 100 such reports in each quarter are received through mail and post and are maintained in physical files. The data in the above reports which consists of more than 1000 data fields is to be updated manually on the data sheets which consumes a lot of time, manpower and have chances of human errors. \nDescription: The objective is to develop a web based software app suited for windows, android, and Mac, which will incorporate each and every steps/activities involved during the progress of the research projects till it official completion/ closure and maintain the whole database in a defined server for audit and scrutiny. \nExpected Solution: A web based software app is required to be developed which will authorise the sanctioned project’s proponents to enter data and update the project’s status through the app on PC and phone including all the forms, activity wise time line, schedule table, details of fund utilisation, other necessary input etc.\nAn admin console, to be handled by CMPDI, will also be developed for the following:\nCreation of unique project code based on the funding and other criteria after approval of the project.\nOther information such as Title of the projects, Name of Principal Implementing Agencies, Name of Sub-Implementing Agencies, Name of the Project Investigator(s), Project Co-ordinator, Project Investigator, Duration of the projects, project outlay (Agency wise & Head wise), start date, Schedule completion date, etc.\nOn completion, the admin should have the control to set the final status. \nOfficial communication on the specified email ids of the authorised project co-ordinators or investigators of implementing/ sub-implementing agencies through Email for Delays, Meetings, revisions etc.\n\nResearch Investigator Console: For the investigators/ Researchers of the sanctioned project.\nInitial information of the sanctioned projects will be provided by CMPDI through the admin console and will authorise the investigators with their E-mail or Mobile no. to access their project information and for further updates as mentioned above. \nThe investigator authorised shall receive a unique username and password to access their projects. The investigator will input the desired details such as personal information, bank details of institute/ Organisation of the projects, institutions and the co- investigators in the developed platform and upload necessary documents (the details of the information to be submitted will be provided).\nThe investigator shall submit the progress of projects in prescribed forms as per S&T guidelines (forms will be provided separately), and subsequently receive digitally generated forms which shall be uploaded after competent authorization.\nThe investigator shall submit Annual Audited statement certified by an authorised auditor and data on interest earned along with basis of calculation of interest amount\nThe app should allow project proponents to input data through PC or mobile.\nThe app should further have provision for sending messages as internal chat with the Admin(CMPDI) and E-mails, in case, deadline for quarterly status submission are missed, and the necessary data along with signed documents have not been uploaded for a particular project.\nOn completion of the project, the proponent should upload necessary documents required before and after the project completion.\nAny modification in the input data should be locked after submission and generation of forms."
  },
  {
    "A": "1647",
    "B": "The Department of Consumer Affairs monitors the daily prices of 22 essential food commodities through 550 price reporting centres across the country. The Department also maintains buffer stock of pulses, viz., gram, tur, urad, moon and masur, and onion for strategic market interventions to stabilize the volatility in prices. Decisions for market interventions such as release of stocks from the buffer are taken on the basis of the price trends and outlook.\nAt present, the analyses of prices are based on the seasonality, historical and emerging trends, market intelligence inputs, crop sowing and production estimates. ARIMA based economic models have also been used to examine and forecast prices of pulses."
  },
  {
    "A": "1648",
    "B": "Background:\nVisitors to museums often face several significant challenges due to manual ticket booking systems. One prominent issue is the inefficiency and time consumption associated with the process. Long queues are common, especially during peak hours, weekends, or special exhibitions, leading to frustration and impatience among visitors. Besides the wait times, the manual system is prone to errors, such as incorrect ticket issuance, double bookings, or lost records, which can cause further delays and inconvenience. Overall, these challenges associated with manual ticket booking systems significantly detract from the visitor experience, reducing satisfaction and potentially impacting the museum's reputation and visitor numbers.\nDescription:\nThe implementation of a chatbot for ticket booking in a museum addresses several critical needs, enhancing the overall visitor experience and streamlining museum operations. Here are the key reasons for adopting a chatbot ticket booking system:\n1. Improved Customer Service\n2. Efficient Handling of High Volumes\n3. Cost-Effective Solution\n4. Data Collection and Analysis\n5. Accessibility\n6. Reduced Human Error\n7. Multilingual Support\n8. Enhanced Marketing and Promotion\nExpected Solution:\nAn efficient and responsive multilingual chatbot based ticketing system that can handle all kinds of bookings from gate entry to shows. Payment gateway should also be integrated to make it fully free from human intervention. It will also provide analytics to aid in more efficient decision making process."
  },
  {
    "A": "1649",
    "B": "Background:\nMany organization are using Cloud for hosting their web applications. The attackers can try to attack these webservers for achieving Denial of Service attack. Specifically, Distributed Denial-of-Service (DDoS) attack is a malicious attempt to disrupt the normal traffic of a targeted server, service or network of Cloud infrastructure by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing multiple compromised computer systems assources of attack traffic.\nExploited machines can include computers and other networked resources. Therefore, it is essential to develop appropriate security tools to counter and protect against these attacks.\n\n• Description:\nThe most obvious symptom of a DDoS attack is that a website or service suddenly becomes slow or unavailable. But since a number of causes such a legitimate spike in traffic can create similar performance issues, further\ninvestigation is usually required. Therefore, suitable analytics tools need to be developed to clearly identify an attack as DDoS.\nFollowing are some of the patterns for a DDoS attack:\n1. Suspicious amounts of traffic originating from a single IP address or IP range\n2. A flood of traffic from users who share a single behavioral profile, such as device type, geolocation, or web browser version\n3. An unexplained surge in requests to a single page or endpoint\n4. Odd traffic patterns such as spikes at odd hours of the day or patterns that appear to be unnatural (e.g. a spike every 10 minutes)\nThere are other, more specific signs of DDoS attack that can vary depending on the type of attack. The tool developer should be creative to consider other signs also.\nFor the above problem statements, following assumptions can be made:\n1. Cloud is hosting a website and providing some services to its users.\n2. The website should be always up and providing services to its users (high availability).\n3. The attackers can flood the website directly or via other nodes (DDoS).\n4. The attacker can also sabotage the link between a client and webserver.\n5. The attack can come from outside or from within the cloud infrastructure.\nA solution needs to be built by suitably designing the cloud architecture and developing some tool (s) to automatically detect and recover from the DDoS attack.\n\nExpected Solution:\nA set of developed tool(s) along with a suitable Cloud architecture to be demonstrated. The demonstrated website should be protected well against different types of DDoS attack. In case of an attack, the developed security tools\nshould be able to automatically detect and protect a website hosted on cloud infrastructure against DDoS attacks. The solution should also demonstrate the automatic recovery from the attack. As high availability is an essential feature, the down time (recovery time) should be minimized to the extent possible."
  },
  {
    "A": "1650",
    "B": "• Background: Glacial Lake Outburst Floods (GLOFs) occur when the dam containing a glacial lake fails, releasing large volumes of water suddenly and causing catastrophic downstream flooding. Climate change is increasing the number and size of glacial lakes, heightening the risk of GLOFs. Curent monitoring and prediction methods can be improved with advanced technologies like remote sensing, sensors installed near glacial lakes and machine learning.\n\n• Description: The aim is to develop a remote sensing and/or sensor-based Early Warning System (EWS) for GLOFs by utilizing remote sensing data, network of IoT sensors and advanced data analytics. The system will continuously monitor and identify critical changes in lake size, water level, temperature, sudden water flow, dam\nstability and ground movement etc. around glacial lakes. The machine learning algorithms will analyse the information to detect early signs of potential outbursts. This approach will significantly enhance the capability to predict and respond to GLOFs, improving safety, reducing economic losses, and contributing to resilient infrastructure planning in glacial regions.\n• Expected Solution:\nA Sensor which can be installed in glacial lake area, or a predictive model that significantly improves the Early Warning System ability for GLOFs, providing critical lead time for evacuation and mitigation efforts."
  },
  {
    "A": "1651",
    "B": "• Background: The Army of many developed countries has their own gunshot detector system which would alert the troop about the direction from where gun shot has been fired so that troop can take preventive measure to safeguard their soldiers\n• Description:\nThe system consists of number of omnidirectional microphones preferably six. The output of microphone will be fed to the analog to digital converter and then this signal is fed to the FPGA . Inside FPGA, each channel will be filtered using Bandpass filter so as to limit the band to approx. 3Khz. After this sound classification and localization algorithm will deduce the direction from where the bullet has been fired and display the result on a Graphical LCD.\n• Expected Solution:\nAn FPGA based solution with suitable algorithm for classification and localization of sound. The final result will be displayed on Graphic LCD"
  },
  {
    "A": "1652",
    "B": "• Background:\nRecruitment and Assessment Centre (RAC) under DRDO, Ministry of Defence invites online biodata applications with requisite eligibility supporting documents from candidates. Verification of these documents is presently a\nmanual process.\n• Description:\nThe verification of submitted documents such as educational certificates, marksheets, GATE scorecard, experience, caste, EWS, PwD certificate, etc. by applicants, as applicable against advertised vacancies, is presently carried out\nmanually. These documents, generally available in image or PDF form, may be in languages other than Hindi or English. In order to verify the information filled by applicants in their biodata applications can be verified using Intelligent Document Processing (IDP) techniques involving Machine Learning Deep Learning, Artificial Intelligence, Natural Language Processing, etc.\n• Expected Solution:\nThe extraction of information from submitted documents can take place at the time of application form submission and alerting applicant in case of any mismatch. Thereafter, while screening of applications more robust data\nextraction techniques may be employed to further avoid any chances of error. The extracted information may be presented using modern business intelligence tools thus highlighting the efficiency of process. The solution should be able to process documents with Three Sigma accuracy with a speed of not more than 3 seconds per document."
  },
  {
    "A": "1653",
    "B": "Background:\nRecruitment and Assessment Centre (RAC) under DRDO, Ministry of Defence carries out interviews for applications received against advertised vacancies and for promotion to next higher grade for scientific manpower inducted within DRDO.\nDescription:\nThe process of interviewing is a challenging task. An unbiased objective interviewing process helps identify the right talent. The basic process of an interview involves posing a set of questions by an interviewer and thereafter\nevaluating responses from candidates. Thus, the questions asked should be relevant and match the area/ expertise of the applicant and the responses should also be of relevance w.r.t. the question asked.\nExpected Solution:\nThe proposed solution should provide experts as well as candidates a real life Board Room experience, starting with initial ice-breaking questions leading to in-depth techno-managerial (depending on the level of candidate) questions.\nIt shall also be able to provide a quantifiable score for experts as well as the candidate for the relevancy of questions w.r.t. the area/ expertise of the applicant. Similarly, candidate responses should also be graded for relevancy w.r.t. the question asked, finally assisting in arriving at an overall score for the subject knowledge of the candidate and thus his/ her suitability against the advertised post."
  },
  {
    "A": "1654",
    "B": "Background:\nRecruitment and Assessment Centre (RAC) under DRDO, Ministry of Defence conducts interview for recommending candidates under recruitment,\nassessment and for sponsorship to acquire higher qualification.\nDescription:\nThe process of conducting an interview comprises of selection of board members i.e. experts from DRDO, industry, academia, etc. It is a challenge to\nmanually match profile of subject experts w.r.t. interview board subject and candidates’ area of expertise.\nExpected Solution:\nThe solution shall be able to provide a matching score for experts whose domain matches w.r.t. interview board subject and candidates area of expertise and\nthereafter should be able to predict suitability of expert for a particular interview board through a relevancy score. To arrive on the relevancy score for\nan expert the system should be able to determine a profile score for each selected expert w.r.t. profile of candidates to be interviewed."
  },
  {
    "A": "1655",
    "B": "Background: The impact of oil spills at sea is multifaceted, affecting the environment, economy, public health, and society at large. Preventing spills through stringent regulations, improved technology, and better safety practices is crucial to mitigate these devastating effects. Automatic oil spill detection using Automatic Identification System (AIS) and satellite datasets is essential for environmental protection, public health and safety, economic stability, regulatory enforcement, technological advancement, and operational efficiency. This approach enables timely and effective responses to oil spills, mitigating their impact and promoting sustainable maritime practices. Integrating AIS and satellite datasets significantly enhances the early detection of oil spills at sea by combining real-time vessel tracking with advanced remote sensing capabilities. \nDetailed description: \nThe automatic identification of oil leaks and spills from ships and vessels using AIS (Automatic Identification System) and satellite datasets involves integrating real-time tracking and advanced remote sensing technologies to monitor marine environments effectively. AIS provides crucial information such as the vessel's unique identifiers (IMO number, call sign), real-time positional data (latitude, longitude), speed over ground (SOG), course over ground (COG), heading, type of vessel, dimensions, draught, destination, estimated time of arrival (ETA), and cargo details. \nTo detect a vessel in distress, AIS data have to be monitored for anomalies, such as sudden changes in speed or course, erratic movements, or unexpected stops. These irregularities can signal potential distress, prompting further investigation. Once detecting the distress, the same location/vessel have to be monitored using space borne satellite datasets for oil leaks, orientation of the vessel and its change in datum. The integration of AIS data with satellite datasets, enhances the ability to detect oil leaks early and can respond to situations efficiently. As far as study area, any of the below options may be considered.\nOption 1 : off Mumbai: https://drive.google.com/file/d/1HUisEfMA20ilODdeoRYVneG2i1ZbRBNB/view?usp=drive_link\nOption 2 :Gulf of Mexico – North American waters: \nhttps://drive.google.com/file/d/1_iEcojaZNaezOqKwxHtCenjgOW58lPgA/view?usp=drive_link\nExpected solution: Automated oil spill detection system for early detection of oil spills\nA software/tool/system to be developed for detecting oil spills/vessel in distress with suitable methodology that involves programming in python. The tool/system should detect the anomalies in AIS around the vessel. The distress/anomaly zone has to be monitored for oil spills using Satellite datasets. This can help in early detection of oil leak from a ship or vessel. The information can be passed on to the regulatory authorities for quicker and efficient response."
  },
  {
    "A": "1656",
    "B": "Background: Coastal tourism is one of the priority areas highlighted in the Draft Blue economy policy of India. As such, use of technology to improve the tourism and related sectors is the need of the hour. Given the expected increase in the coastal tourism of our country, there is a need to ensure safety of the tourists. In this regard, a mobile application indicating the suitability of beaches for recreational activities (based on the current ocean state like wave heights/ocean currents, meteorological parameters like wind, water quality etc.) will be a useful value addition to the coastal tourism sector.\nDescription: The proposed app should be able to provide tourism suitability (say suitable/not suitable based on various parameters) at a particular point of time across various beaches in India.\nCreate locations of different beaches across the country.\nDifferent parameters to be considered to determine suitability of a coastal location for recreation activities like Ocean alerts (High Wave/Swell Surge/Ocean Currents/Storm Surge/Tsunami), Winds, Water quality assessments. These parameters will be available via INCOIS (Indian National Centre for Ocean Information Services) API.\nThe application should devise a method/algorithm to use the above parameters and make the safety/suitability decision at the different locations.\nVisualization using geospatial maps and colour codes based on suitability of locations.\nBased on the current location of the user, alert notifications to be provided in case of any alerts in the coastal location of the user) to be provided\nExpected Solution:\nDesign and development of a mobile application which identifies suitability of coastal tourism sites based on the current weather and oceanic conditions.\nThis can help to save lives and better plan the coastal tourist/recreational activities for the user."
  },
  {
    "A": "1657",
    "B": "Background:\nINCOIS provides fishery advisory services to fishermen through potential fishing zone (PFZ) advisories that proven to benefit fishing communities by making fishing more economical and reducing fuel consumption, as fishermen can directly target areas with abundant fish. Current research is focused on advancing the fisheries forecasting services through developing species-specific advisory services. However, predicting species-specific abundance requires a deep understanding of the habitat suitability of commercially important species. This requires analyzing fish catch data alongside environmental variables at the locations of fish occurrence and abundance, identifying the most important variables contributing to their abundance, and ultimately fitting these data to appropriate prediction models. INCOIS is striving to collect geo-referenced fish catch data from various sources, including data from other research Institutions, industry collaborators, research cruises, and a dedicated app that captures fisheries information through images from fish catch locations. However, at present there is no systematic mechanism to aggregate and store these information from multiple channels to a single data base. As a result, the data is highly scattered and disaggregated, leading to wastage of time and confusion among scientific personnel developing species-specific habitat suitability models, since this disorganization makes it difficult to access all available datasets for analysis.\nDetailed Description:\nConsidering the difficulties in collecting georeferenced fish catch data, each single dataset is highly crucial for habitat suitability models. Therefore, there is a need for a comprehensive database to store all available georeferenced fish catch information with appropriate filters and visualization tools. This would enable dedicated personnel to easily access and download all data available for a particular species. Such a dataset would also be highly beneficial for new scientists interested in working on different species, resulting in species specific advisory services for more species in future. \nData input, classification and arrangement \nThe software solution for the portal should handle input data in Excel format and organize it by date, location, depth, and species. Some datasets provide the weight of individual species, while others are only the aggregate weight of the catch with only the information on presence of individual species, not their catch weights. Therefore, there should be separate modules for occurrence and abundance of species. The module for abundance should store data that includes catch weight of individual species, while the module for occurrence should store data with and without catch weight.\nUsers, Data output and visualization\nThe users of the portal will primarily be scientific personnel working on specific species or multiple species, interested in visualizing and downloading data for their target species. Therefore, the portal should display search results for a species using appropriate maps and graphical formats, and also allow users to download the data in Excel/CSV format with columns for Date, Species, Latitude, Longitude, Catch Weight, and Depth.\n-In some instances, scientific personnel may also be interested in studying the fish assemblage patterns of multiple species within a particular geographical area over time. Thus, the output filters should also allow users to filter data by area (using latitude and longitude bounds) and display the occurrences and abundances of all available species over different time scales, along with relevant data on their depth of occurrence.\nData Accessibility\nThe Data repository should have an admin page to continuously update the database, and users should be able to login with appropriate credentials to access the data.\nExpected Solution: A comprehensive data base to feed, arrange, store and visualize disaggregated data on fish catch. This would make research towards species-specific fisheries forecasts hassle-free and smooth, saving time and effort in collecting and compiling information, allowing researchers to focus on more productive tasks."
  },
  {
    "A": "1658",
    "B": "Background: Most of the goods are transported around the world by shipping which relies heavily on fossil fuels for powering. Given the expenditure of the shipping industry on the fuel, a main objective of a shipping company is to optimize the ship route for the least fuel consumption. Depending on the type and purpose of the voyage, it is also desirable to optimize several other parameters such as, the travel time, passenger comfort and route safety, to avoid any damage to the ship, cargo, crew and passengers. Optimization of each of these parameters serves a purpose. For instance, an energy efficient route may not be safe in terms of weather. Therefore, to avoid loss of life and property, route weather safety needs to be considered. An application suggesting the optimal route based on the chosen set of optimal parameters for any voyage between two ports in the Indian Ocean, will immensely benefit the Indian shipping industry.\nDescription: At the heart of any optimal ship routing application lies the optimization algorithm. Although scientific literature is available on various methods of optimizing the ship routes, given the commercial potential, there are no applications available publicly which can be customized for the Indian Ocean region. The optimization methods reported in literature range in complexity, computation time, versatility, etc. Various factors, such as, the forcings (surface winds, currents and waves), design of the ship and ship drift characteristics, impact the ship’s motion at sea. The optimal route must be continually evolving because the weather conditions keep changing as a ship proceeds on its voyage. Therefore, it is crucial to choose a suitable optimization method that can optimize several parameters for a range of ships (with varying type, dimensions, drift characteristics of a ship) and develop an algorithm to return an optimal route within a reasonable computational time. The algorithm can optimize for the voyage time and safety to begin with but with a scope for addition of more optimization parameters. To get an idea of the problem, please visit: https://www.youtube.com/watch?v=ct9v-mQgYqE ii) https://www.youtube.com/watch?v=wCTdHRTWtNI \nExpected Solution: Identification of a versatile optimization method and development of a reasonably fast algorithm, preferably written in an open-source programming language such as Python"
  },
  {
    "A": "1659",
    "B": "Background: In an institute environment, multiple users often require access to the same datasets for various purposes. However, due to lack of communication or visibility, these users may unknowingly download duplicate copies of the same data. This leads to unnecessary consumption of resources, including bandwidth and storage, and complicates data management. The DDAS (Data download Duplication Alert System) addresses this issue by notifying users with an alert if a potential duplicate download is identified. This system helps optimize resource usage, save time, and streamline data management processes.\nDescription: Managing data downloads efficiently is crucial for optimizing resources and maintaining order in any organization. A DDAS addresses the issue of multiple users inadvertently downloading duplicate copies of the same datasets across various fields.\nThe DDAS operates by maintaining a repository or database that records metadata of all downloaded datasets. This metadata includes details such as file names, sizes, timestamps, and download locations. When a user initiates a download request, the system checks the database to determine if the dataset has already been downloaded by any user. To identify duplicates accurately, the system uses file history or unique identifiers, ensuring duplicates are detected even if file names differ.\nIf a potential duplicate is detected, the system prompts the user with an alert. This alert provides comprehensive information about the existing dataset, including its location and the timestamp of the original download. By doing so, the DDAS helps users avoid unnecessary downloads, thereby optimizing resource usage, saving time, and streamlining data management processes.\nThis system is designed to be flexible and applicable across various fields and industries, including academic institutions, research facilities, and any other domain where efficient data management is critical. By preventing duplicate downloads, the DDAS ensures that resources are used effectively, contributing to overall organizational efficiency.\nExpected Solution: To mitigate this issue, a robust solution is needed to design and develop a system that generates alerts when users attempt to download data already available within the institute's repository or any of the user accounts. The alert system should promptly notify users about the existence, properties (such as the period, spatial domain, and other relevant data attributes), and location of the required data, thereby preventing unnecessary duplication and promoting efficient resource utilization. Implementing this solution allows organizations to streamline data access processes and reduce redundancy. This system has to be applicable across various fields and industries, including academic institutions, research facilities, government agencies, and more."
  },
  {
    "A": "1660",
    "B": "Background: The 2030 Agenda for Sustainable Development, adopted by all United Nations members in 2015, created 17 world Sustainable Development Goals (SDGs). It was also accepted that these SDGs are not possible to achieve without changing humanity’s relationship with the oceans. To realize that, in 2017, it was decided that the decade of 2021-30 is to be observed as UN Decade of Ocean Sciences for Sustainable Development (or UN Ocean Decade). INCOIS is identified as UN Ocean Decade Collaborative Centre for the Indian Ocean Region to help address all the ten UN Ocean Decade challenges (https://oceandecade.org/challenges/).\n\nDescription: The creative solution proposed herein will address mainly (but not limited to) challenge-10. The gamified way of creating ocean related awareness is aimed for all age-groups and diverse education levels. Considering popularity of online gaming (multi-role playing to conventional games such as ludo) and affordable devices along with data plans, this approach is promising option for ocean literacy. For a starter, one such solution (but very limited/basic in nature) can be found at: https://www.outreachgames.org/OceanProtector/main.html.\n\nExpected Solution:\nThe user will be able to chose from a variety of sea-going roles e.g. but not limited to, fishermen, captain of a ship, tourism operator etc. Based on the role, one needs to choose the correct sea conditions to be at a location (or move away) with the help of available/applicable ocean information services form INCOIS (simulated for the game). Correct decision (e.g. going for fishing to PFZ zone or moving away from the shore when tsunami is detected) will add to the points and help player achieve next level. Wrong decision may result in loosing points and add other gaming penalties (e.g. start over or wait till certain time etc etc). Users goal would be to advance and maintain gains at the daily, weekly etc leaderboards so in that way it would be competitive among the users even though their game decisions are not affecting to the others directly.\nThe solution should be suitable for windows and android environments (web and browser based) and scalable over the time by the host institute independently post-SIH"
  },
  {
    "A": "1661",
    "B": "Background: Student dropout rates in India are influenced by socio-economic and educational factors, affecting marginalized communities the most. Addressing dropout rates is essential for equitable education and socio-economic development. The National Education Policy (NEP) 2020 emphasizes the importance of reducing dropout rates and ensuring quality education up to at least the secondary level.\nDescription: This solution focuses on creating software tools to address and reduce dropout rates. The tools will help identify at-risk students, provide personalized support, and engage communities. By leveraging technology, the aim is to improve student retention, align with NEP 2020’s goals, and support a holistic approach to education.\nInnovative Software Solutions:\na) AI-Driven Early Warning System:\no Description: Develop an AI-powered software platform that analyzes student data (attendance, grades, behaviour) to predict which students are at risk of dropping out. The system will provide alerts to educators and administrators, enabling timely interventions.\no Features: Predictive analytics, real-time alerts, data visualization, and intervention recommendations.\nb) Community Learning Hub Platform:\no Description: Create an online platform that supports community learning hubs in rural and underserved areas. This platform will offer digital resources, tutoring sessions, and virtual mentoring, providing additional educational support to students.\no Features: Online classes, resource library, virtual tutoring, and community forums.\nc) Mobile Learning Application:\no Description: Develop a mobile application that delivers personalized learning experiences, including interactive lessons, quizzes, and educational games. The app will provide resources for students who have limited access to traditional education.\no Features: Interactive content, offline access, progress tracking, and personalized learning paths.\nd) Financial Support Management System:\no Description: Build a software system to manage scholarship and financial aid applications. The platform will streamline the application process, track disbursements, and provide information on available financial support to reduce economic barriers.\no Features: Application tracking, financial aid management, eligibility assessment, and reporting tools.\ne) Parental Engagement Portal:\no Description: Develop a web-based portal to engage and educate parents about their child's education. The portal will include resources on supporting learning at home, tracking student progress, and receiving updates from teachers.\no Features: Parent-teacher communication, educational resources, progress reports, and event notifications.\nf) Flexible Schooling Management System:\no Description: Create a software system to manage flexible schooling options, such as evening classes and part-time programs. The system will allow students to enrol, track their progress, and manage their schedules.\no Features: Enrolment management, schedule tracking, progress monitoring, and integration with existing school systems.\ng) Student Support and Engagement App:\no Description: Develop an app that provides personalized support and engagement for students at risk of dropping out. Features will include counselling support, motivational content, and tools for setting and tracking academic goals.\no Features: Counselling resources, goal-setting tools, motivational content, and engagement tracking.\nBy implementing these software solutions, the goal is to reduce dropout rates significantly by addressing the key factors that contribute to student attrition. These solutions are designed to align with the NEP 2020’s objective of ensuring universal access to education and improving student retention."
  },
  {
    "A": "1664",
    "B": "Background: Rural areas in India often suffer from inadequate educational infrastructure, limited connectivity, and insufficient access to quality educational resources. This hampers the ability of students in these areas to receive a comprehensive education. Leveraging software solutions can help bridge these gaps by providing remote learning opportunities, optimizing resource management, and improving connectivity.\nDescription: The goal is to create and implement software solutions that address the challenges faced by educational institutions in rural areas. This involves developing tools for remote learning, resource management, and connectivity enhancement. Strategies will focus on creating software that can facilitate virtual classrooms, manage educational resources efficiently, and provide support for infrastructure planning and development.\nInnovative Solutions:\na) Virtual Classroom Platforms:\no Develop cloud-based virtual classroom software that supports live streaming of lessons, interactive tools for student engagement, and recording capabilities for on-demand access. This solution can help overcome the lack of physical infrastructure by bringing quality education directly to students in remote areas.\nb) Educational Resource Management Systems:\no Create software to manage and track educational resources such as textbooks, digital content, and teaching aids. This system can help schools inventory and distribute resources effectively, ensuring that materials are available where needed and reducing wastage.\nc) Internet Connectivity Optimization Tools:\no Develop software that can optimize and monitor internet connectivity in rural areas. Tools can include bandwidth management systems, connectivity diagnostics, and network optimization software to ensure stable and reliable internet access for educational purposes.\nd) E-Learning Content Creation Platforms:\no Build platforms for creating and distributing e-learning content tailored to the curriculum and local needs. These platforms can support multimedia content, quizzes, and interactive modules, providing a rich learning experience even in areas with limited physical infrastructure.\ne) Mobile Learning Apps:\no Develop mobile apps that offer offline access to educational content, interactive lessons, and quizzes. These apps can be designed to work in low-bandwidth environments and provide essential learning tools to students who may not have consistent internet access.\nf) Data Analytics for Infrastructure Planning:\no Implement software solutions for data analytics to assist in planning and developing educational infrastructure. This can include tools for analyzing data on student demographics, resource needs, and infrastructure gaps, helping policymakers and educational planners make informed decisions.\n\nBy developing and implementing these software solutions, we aim to significantly improve educational infrastructure and connectivity in rural areas, enhancing learning opportunities and educational outcomes for students."
  },
  {
    "A": "1666",
    "B": "Background: A lack of adequate career counselling and guidance in schools contributes to poor career choices among students, leading to mismatched skills, job dissatisfaction, and unemployment. In India, many students and their families are unaware of the diverse career opportunities available, often leading to choices based on limited information or societal pressure. Effective career counselling and guidance are essential for helping students make informed decisions about their futures and aligning their education with their career aspirations. The National Education Policy (NEP) 2020 emphasizes the need for holistic education, which includes providing students with the guidance necessary to make informed career choices.\nDescription: The proposed solution focuses on implementing comprehensive career counselling and guidance programs in schools. This includes training career counsellors, developing resources and tools for career exploration, and integrating career guidance into the school curriculum. Programs should provide personalized counselling sessions, workshops, and access to information on various career paths and educational requirements. Additionally, leveraging technology to create interactive platforms for career exploration can enhance student engagement and awareness. These initiatives align with NEP 2020's vision of equipping students with the knowledge and skills to pursue their career aspirations.\nInnovative Solutions:\na) AI-Powered Career Guidance Platforms: Develop AI-driven platforms that provide personalized career advice based on students' interests, strengths, and market trends.\nb) Career Mentorship Programs: Establish mentorship programs where students can receive guidance and support from professionals in their fields of interest.\nc) Interactive Career Exploration Tools: Create digital tools and apps that allow students to explore different careers through virtual simulations, videos, and interactive content.\nd) Comprehensive Career Resource Portals: Develop online portals with extensive resources on career options, required skills, educational pathways, and job market trends.\nBy implementing these innovative solutions, we aim to improve career counselling and guidance in schools, helping students make informed career choices that align with their interests and the demands of the job market. This approach supports NEP 2020's goal of providing holistic and relevant education to all students."
  },
  {
    "A": "1667",
    "B": "Background: India has a tremendous opportunity to harness the potential of its youth by addressing the skills gap between education and industry requirements. While vocational education programs exist, they are often undervalued compared to traditional academic paths and need enhancement to provide students with the skills demanded by today’s job market. Strengthening vocational education is essential for creating a skilled workforce that aligns with industry needs and supports sustainable economic growth. The National Education Policy (NEP) 2020 emphasizes the importance of vocational education and aims to integrate it into the mainstream education system to prepare students for various career paths.\nDescription: The goal is to transform vocational education into a core component of the elementary and secondary education system, as envisioned in NEP 2020. By collaborating with industry experts, we can design a curriculum that is modern and industry-relevant. Investments in infrastructure will ensure schools have the necessary tools and facilities for effective training. Specialized training programs for educators will enhance the quality of vocational teaching. Partnerships with industries will offer students valuable real-world experience through internships and apprenticeships. Awareness campaigns will shift perceptions, highlighting vocational education as a respected and viable career path.\nInnovative Solutions:\na) Virtual Reality (VR) Training Modules: Develop VR-based training modules to simulate real-world scenarios and provide hands-on experience in a virtual environment.\nb) AI-Powered Career Guidance: Implement AI tools to offer personalized career guidance and skill development pathways for students based on their strengths and industry trends.\nc) Digital Skill Badges: Introduce digital badges and certifications that students can earn upon completing various vocational training modules, making their skills easily verifiable by employers.\nd) Mobile Training Labs: Deploy mobile vocational training labs to reach remote and underserved areas, providing practical training and education on the go.\ne) Online Apprenticeship Platforms: Create online platforms that connect students with apprenticeship opportunities, facilitating easier access to industry partnerships and hands-on experience.\nBy leveraging these innovative solutions, we can enhance vocational education and ensure that students are well-prepared to enter the workforce, thus contributing to India's economic growth and development. NEP 2020’s emphasis on vocational education integration will be a guiding framework for these efforts, ensuring alignment with national educational goals."
  },
  {
    "A": "1668",
    "B": "Background:\nIn today’s digital age, a wide variety of services and processes take place online. Users of these digital facilities are required to upload government-issued containing documents or provide data for successfully availing the services. However, the uploaded documents or data which are required to facilitate these digital services and processes contain personally identifiable information (PII), i.e. any data that can be used to identify an individual uniquely. These documents can be like Aadhaar card, PAN, Credit Card, Driving License etc and can include data like names, address, phone number, email address, and financial information, among others of the user. The handling of PII is crucial as its exposure can lead to privacy breaches, identity theft, and financial fraud among other cyber related issues.\nDetailed Description:\nThe above problem statement envisages that an application be developed to identify whether PII, in the form of government-issued documents such as Aadhaar, Driving license, MHA-issued ID Cards, etc. is embedded in the uploaded document or provided data. Notable, the PII may be included inadvertently as well. PII, by its nature, is sensitive data, and its exposure must be protected against in order to safeguard users’ privacy. Entities and organizations handling documents or data containing users’ PII must be mindful of the complex challenges that arise with it – they have to balance data storage, encryption, access controls, data retention policies, data management processes with users’ knowledge and consent, notification of breaches by users, grievance redressal, etc. Such an application will aid in alerting individual users to verify whether it is necessary to upload or provide PII-containing document. Simultaneously, it will allow the personal data processing entity to check whether such PII document or data is required, and in case not necessary, help in removing, redacting or masking the PII\ndocument or data from the uploaded or provided document or alerting the individual user regarding the same. This application would be useful for the purposes of data protection compliance, risk mitigation, enhanced security, improved data quality, operational efficiency, and legal and regulatory compliance.\n\nExpected Solution:\nA software application or library package to detect and alert users when there is personally identifiable information (PII) related to identified government-issued identification documents (Aadhaar card, PAN, Driving License to start with) embedded in the uploaded documents or providing data, while uploading or reviewing. In addition, the software application may be placed in public domain and shall allow the receiver of the document in removing, redacting or masking the PII from the document and data, if required."
  },
  {
    "A": "1669",
    "B": "Background:\nIn today's digital age, the ability to efficiently manage documents is crucial for organizations. However, a significant challenge arises when dealing with non-machine-readable documents such as PDFs or Word documents. These formats hinder automation and make it difficult to extract meaningful insights from the data they contain. Therefore, there is a pressing need for a solution that can both restrict the ingestion of non-machine-readable documents and facilitate the creation of machine-readable documents seamlessly.\nDescription:\nThe above problem statement envisages:\n1. To develop an application that can restrict software applications from ingesting any non-machine-readable document format such as PDFs, DOCs, or any other document types.\n2. To create a mechanism within the application to generate machine-readable documents automatically whenever a new document is created, regardless of its source - scanned, generated through a software application, or otherwise.\nExpected Solution:\nThe TransformoDocs application aims to address the challenges associated with managing non-machine-readable documents by developing a comprehensive document transformation application. It will help in realizing the benefits of search-ability, artificial intelligence, accessibility to persons with disability, machine translation and access to data across applications and data exchanges. This application may offer efficient data extraction, standardized processing, workflow automation, data quality improvement, scalability, integration with external systems, advanced analytics, and compliance with regulatory requirements ultimately unlocking the value of their data."
  },
  {
    "A": "1670",
    "B": "1. Background. UIDAI is exploring possibilities to enable Face authentication on the desktop in a browser context. The proposed architecture to provide Face\nAuthentication in the browser context,requires AI on the edge to perform liveness check of the face being captured by the webcam or connected camera. UIDAI is considering the injection of ML model by using an appropriate binary code delivery mechanism.\nThe security of these models is important for transaction integrity and therefore seeking an innovative solution that will protect the model from any tampering and\nreverse engineering.\n2. Problem Description. As part of the challenge, participating teams to demonstrate model security in a browser context by using either obfuscation or\ncryptography. Models are typically 5~7Mb in size and structured as flatbuffers. These models would be downloaded, when for the first time accessed on a desktop and then cached in the browser context. For subsequent face authentication transactions, a cached model would be preferred, unless otherwise the model has changed or updated.\nTo solve the above problem statement, teams are free to choose either ONNX web runtime or Tensor.js or any other innovative model to distribute the model in the\nbrowser context.\nThe proposed solution must meet the following functional objectives.\n1 Model Security. The solution must provide a mechanism to protect the model from any reverse engineering or tampering.\n2 Model Size Optimisation. The solution must not significantly increase the size of the model post-implementation of security frameworks. Models are\nexpected to be downloaded in 3G/4G/5G wireless networks and hence any increase in size may lead to deteriorated user experience.\n3 The solution must feature backend components to prepare the ML model either using obfuscation or cryptography. The backend activity can be a one-time\ntask during the release of the ML models or a just-in-time approach. In the just-in-time approach, the model would be obfuscated or encrypted before being downloaded to the end user’s desktop.\n\n3. Expected Solution. The expected outcome of this project is a functional solution that incorporates the security of the ML model at the edge. The backend for the proposed solution system must be designed to handle the high volume of transactions that is expected for any population-scale solutions."
  },
  {
    "A": "1671",
    "B": "1. Background. UIDAI is building a browser-based face authentication platform, which will enable the aadhaar number holders to start and end the face authentication on the same device i.e desktop, mobile or tab. One of the key drivers for the success of the solution is face liveness detection in the browser context. This challenge seeks an\ninnovative approach to implement face liveness using ML models which can be used in all forms of interfaces.\n2. Problem Description. As part of the challenge, participating teams to develop passive or active liveness detection models that can be used in the browser context to prevent the use of photo-of-photo, video or any form of face spoofing mechanism. Teams may opt for passive - which would the use environment to detect the liveness of the actor or active - which engages the aadhaar number holder for some “action” to detect the liveness. \nThe proposed solution must meet the following functional objectives.\n3. The proposed solution must meet the following objectives.\n3.1 Feature Requirement. Liveness detection of the Actor in the edge.\nLiveness detection to happen in the browser (Chrome/Firefox/Edge context using ONNX or Tensor.js framework.\n3.2 Model Inference Time. Liveness detection should be completed within 500ms for enhanced user experience.\n3.3 Mode. The model may use active or passive or a combination of both to detect the liveness of the actor. 3.4 Model Size. The liveness model must not be more than 5Mb, so that it can be downloaded in the narrow bandwidth (3G/4G/5G) network without impacting the page load timing.\n4. Expected Solution. The expected outcome of this project is a functionalsolution that demonstrates the face liveness detection in the edge."
  },
  {
    "A": "1672",
    "B": "1. Background. UIDAI has multiple portals on the Internetfor resident engagement and back office operations. These portals are protected with CAPTCHA for denial of service- related attacks. UIDAI believes that CAPTCHA is a barrier to smooth resident engagement with the aadhaar portals and therefore intends to remove it soon. Instead of\nactive CAPTCHA, UIDAI is looking for a passive solution that can differentiate between a bot and a human operator.\n2. Problem Description. As part of the challenge, participating teams to develop a solution, mostly following a passive approach through collection of environmental parameters and using AI/ML to analyze it in the backend to differentiate between bot and human-being. The passive solution may capture environmental details\nthrough the browser context and analyze the same with the help of ML models deployed in the backend. This solution, once accepted would be used by the UIDAI to protect all backend APIs from DoS/DDoS based vulnerabilities. \nThe solution must meet the following requirements:-\n3. The proposed solution must meet the following objectives.\n\n3.1 Feature Requirements. The solution must define the list of environmental parameters that need to be captured to differentiate between a bot and a human being. If passive parameter analysis is unable to differentiate, then\nthe user may be asked to do a few minimal interactions with the portal. User experience is important to UIDAI and hence human interaction is to be limited.\n3.2 Frontend code to capture environmental or human interaction data must be compliant with the javascript framework. Participating teams may choose to use any framework like React/TypeScript/Flutter to demonstrate the solution.\n3.3 As part of the solution, the required backend ML model to analyze the front- end capture of environment parameters or human interaction data must be developed to demonstrate the solution. The ML model must be pluggable so that it can be integrated with the UIDAI application stack to protect the APIs.\n3.4 The solution must adhere to the core privacy policies of UIDAI.\n5. Expected Solution. The solution must be complete with both frontend and backend design, corresponding code and ML model to demonstrate the solution."
  },
  {
    "A": "1673",
    "B": "Background- Agricultural productivity and food security are heavily dependent on the\n health of crops and livestock. Farmers, especially in remote or resource-limited areas,\n often face challenges in diagnosing and reporting diseases that affect their livestock\n and crops. Early diagnosis and timely reporting are crucial for effective disease\n management and prevention of widespread outbreaks.\n Description - A mobile portal powered by Artificial lntelligence (Al) for disease diagnosis\n and reporting can revolutionize how farmers manage animal and plant health. This\n portal enables farmers to use their smartphones to access diagnostic tools, report\n symptoms, and receive actionable advice. Al algorithms can analyze reported data to\n provide accurate diagnoses and suggest appropriate treatments or interventions. This\n technology can empower farmers with the knowledge and tools to manage diseases\n more effectively, ensuring the health and productivity of their farms.\n lntegrate Al-based software with existing NDLM to allow farmers to submit images and\n descriptions of disease signs and symptoms. The Al will generate suspected\n disease/condition reports with preventive measures and send alerts to veterinarians for\n appropriate action (Al-based software, Mobile application).\n Expected Outcomes\n . Enhanced Disease Diagnosis:\n . Timely Reporting and lntervention:\n . lncreased Access to Expert Knowledge:\n . lmproved Farm Productivity. Data Collection and Analysis:\n Cost-Effective DiseaseManagement:\n Empowerment and Education of Farmers:\n lntegration with Existing Surveillance Systems\n . Community Engagement and Support:\n Sustainable Agriculture Practices"
  },
  {
    "A": "1674",
    "B": "Background: Use of encrypted messaging/social media apps like Telegram, WhatsApp and Instagram for drug trafficking are on the rise. Channels operating on Telegram and WhatsApp and Instagram handles are blatantly being misused by drug traffickers for offering various narcotic drugs and Psychotropic substances for sale.\nDescription: WhatsApp and Telegram channels and Instagram handles are created by drug traffickers to offer various drugs for sale to their subscribers. Customized\nTelegram bots are also created by some of the drug traffickers to sell drugs. It is most worrisome that majority of the drugs which are being offered on sale through Telegram, WhatsApp and Instagram are dangerous synthetic drugs like MDMA, LSD, Mephedrone etc. The above three apps are also used by drug traffickers for drug communication.\nExpected Solution: Development of a software solution to identify live Telegram and WhatsApp channels/bots and Instagram handles that are offering drugs for sale in India. Solution also should focus on triangulating identifiable parameters like IP address, mobile number, email id etc of the users behind the channel/bot/handle."
  },
  {
    "A": "1675",
    "B": "Background: Use of cryptocurrencies like bitcoin, USDT, Monero etc. for drug trafficking activities are increasingly becoming common. The relative anonymity and speed provided by cryptocurrencies are misused by drug traffickers as a mode of transaction for drug sales and also as an asset to amass the proceeds of crime.\nDescription: Drug traffickers operating on darknet and elsewhere on internet enabled platforms like social media apps, messaging services etc receive the value of drugs through cryptocurrencies. In a few cases, the drug traffickers save their proceeds of crime in cryptocurrencies. During the course of investigations and also through intelligence, wallet addresses and transactions hash related to drug transactions are obtained by Drug Law Enforcement Agencies, Further, it has also been observed that these finds are often passed through variety of services like tumblers, mixers, bridges etc to further anonymize the transactions. It is important to follow the trial of funds associated with drug transactions to identify the real persons behind the drug trafficking network.\nExpected Solution: Development of a software solution to follow the cryptocurrency transaction trial associated with a wallet id/transaction to find out the real receiver of the funds in a drug related transaction."
  },
  {
    "A": "1676",
    "B": "Background:\n Critical Sector organisations uses a number of IT and OT equipment (e.g. Networking and hardware device, Operating Systems, Applications, Firmware etc.). These devices/application come with vulnerabilities from time to time. There should be timely information sharing mechanism by which the concerned equipment users at critical sector orgs should be altered regarding any critical / high severity vulnerabilities in their equipment within the shortest possible time.\n Detailed description:\n The ICT components (HW/SW) being used by Critical Sector Organisations become vulnerable from time to time. These vulnerabilities can be categorised as Critical, High, Medium and Low. Any exploitation of these vulnerabilities can cause havoc in multiple Critical Sector Organisations where such vulnerable equipment are being used.\n Keeping in view of the above, there is a need to monitor all such vulnerability information published at the equipment’s OEM websites and also other relevant websites. Once a critical or high severity vulnerability information is published at OEM website or any other relevant website, the ‘to be developed scrapper’ will immediately take that vulnerability input along with possible mitigating strategy published in the website and send the information to predefined email id(s).\n Note: The NVD website publishes such OEM vulnerable information. But the same comes with a time lag. It is therefore needed to get such information directly from OEM websites and /or from other relevant websites where such vulnerable information is published almost in real time.\n Expected Outcome:\n An automatic script using open source tools to be developed for the OEM vulnerability information scrapping and reporting. Tool should know various vulnerability information published data formats/syntax at OEM websites (both for IT and OT hardware and application) and come up with optimum solution for monitoring and reporting of such vulnerability information.\n \n The output of the tool that will be emailed to pre-designated email id(s) is as per following (shared with example; all fields may not be available at the time of reporting):\n * Product Name: Chrome\n * Product Version: - NA\n * OEM name: Google\n * Severity Level (Critical/High): High\n * Vulnerability: The N-able PassPortal extension before 3.29.2 for Chrome inserts sensitive information into a log file.\n * Mitigation Strategy: Install patch from https://me.n-able.com/s/security-advisory/aArHs000000M8CCKA0/cve202347131-passportal-browser-extension-logs-sensitive-data\n * Published Date: Jan 2024\n * Unique ID: CVE-2023-47131"
  },
  {
    "A": "1677",
    "B": "Background:\nNCIIPC shares detail of cyber incidents to corresponding stakeholders in order to inform them about cyber activities related to their IT/OT infrastructure. This empowers them to take necessary actions to mitigate further risk.\nDescription:\nIn order to achieve objective of protecting Critical Information Infrastructure (CIIs) of the Nation, it is very vital to have real time information related to cyber threats and incidents specific to Indian Cyber space. This may enhance the Threat Assessment potential based on the incidents that have already happened or the ones that currently exists. Therefore, a framework to crawl/scrap/collect the cyber incident activities reported anywhere on the web related to Indian cyber space is required to be developed.\nExpected Solution:\n1. Using Machine Learning, find platforms that publish or works as intermediate platform for sharing cyber incident activities related to cyber incidents.\n2. Design a model framework for the cyber incidents feed generator which collects data from various forums, paste sites, social media, developer or any other platforms as identified by Machine learning model generated in accordance to point 1 above.\n3. Creation of well-structured database of cyber incidents extracted by framework developed in accordance with point 2 above.\n4. Generation of valuable insights from the data collected and its visual representation of cyber incidents specific to sectors, APTs and strategic issues.\nNote: Students are encouraged not to use paid APIs for solving the problem."
  },
  {
    "A": "1678",
    "B": "Background: Easy to use and secure redaction tool “RE-DACT” which allows redaction/masking/anonymization on various input formats based on a gradational scale defined by the user and providing customized output. Over a time, model will learn and have the ability to generate realistic synthetic data in any sought format.\nDescription: The proposed solution is a natural language processing (machine learning) based redaction tool. The tool will redact or obfuscate from original data leaving the output structurally/logically the same but stripped of key identifiers and other content which may in any way allow the identity, actual data, markers or issues in the input content to be revealed. The correlational logic may be appropriately obfuscated based on the degree of redaction. This will have an easy to use GUI and will be available for use on online and offline systems.\nThe degree of the redaction will be up to the user- the higher the degree set by the user, the more the degree of redaction. This will work with all different commonly used formats for text and data sets. Security of data will be assured by ensuring that the input data is not stored or retrievable in any fashion by third party entities. User will have complete control over the input data.\nIt is also an important aspect that sometimes data may be required to be stored or submitted, however specific sensitive details may not necessarily be required. In such a situation- anonymized data authenticated as having being redacted from original would suffice.\nDeclassification processes are long and arduous; anonymization is largely manual or custom script driven. By providing a gradational redaction option, ordinary users can strip away the specificity to the extent of liking-from merely name removal/anonymization to completely synthetic data with only faint traces of original structure/pattern. This can allow generation of large number of databases with realistic but anonymized data that can be shared for learning, growth and commercial ventures.\nExpected Solution:\nProblem Statement: Easy to use and secure redaction tool “RE-DACT” which allows redaction/masking/anonymization on various input formats based on a gradational scale defined by the user and providing customized output. Over a time, model will learn and have the ability to generate realistic synthetic data in any sought format.\nStage 1\nData: Curate and use own data set for building PoC\nTask/Result: Input/Output: Supports common input formats (text files, images) and basic output formats (redacted files, logs). Web based version\nTraining Dataset: Publicly available dataset can be used for the purpose.\nMetrics: Precision, Recall, F1 Score on Open Source Testing dataset.\nStage 2\nData: Dataset will be provided in Grand Finale\nTask/Result: Input/Output: Expands to handle more data formats (e.g., PDFs, videos) and advanced output options (e.g., redacted versions with annotations).\nTraining Dataset: Diverse data set prepared from commonly used formats\nMetrics: Precision, Recall, F1 Score on Open Source Testing dataset.\n\nPerformance/Evaluation Criteria:\n• PoC will be preferred over just concept or presentation.\nThe performance may be ascertained on the following metrics:\n• Efficacy of the redaction/anonymization- whether appropriate data has been redacted\n• Gradational effect achieved based on user preference and ability to calibrate.\n• Ability to work on a variety of input sources\n• Security of the input data by minimal retention\n• Speed\n• Optimized computing usage and ability to operate at scale.\n• Ease of use, UI, UX.\n• Performance benchmarked against COTS solutions.\n• Web Based and Offline solution.\n• Minimal API dependency\n• Use of Secure Coding Practices and cybersecurity built in design"
  },
  {
    "A": "1679",
    "B": "Background:\nOrganisations across various industries face significant challenges in maintaining robust cyber security posture. Compliance with industry standard bench marks and guidelines, such as those provided by Center for Internet Security (CIS), is crucial for ensuring the security and integrity of their IT Infrastructure. However, manually auditing and ensuring adherence to these benchmarks and guidelines can be time- consuming, error prone, and resource intensive. Current practises often involve manual checks. To address these challenges, there is a critical need to develop automated auditing scripts tailored to CIS benchmarks.\nDetailed description:\nThis software solution aimed to list out the control guidelines as per CIS benchmark for the following operating systems: -\nWindows (Reference\nwww.cisecurity.org/benchmark/Microsoft_winodws_desktop)\ni. Windows 11 (Enterprise version)\nii. Windows 11 (Standalone version)\nLinux (Reference:www.cisecurity.org/benchmark/red_hat_linux, www.cisecurity.org/benchmark/ubuntu_linux)\ni. Redhat Enterprise (8 and 9)\nii. Ubuntu desktop (20.04 LTS, 22.04 LTS)\niii. Ubuntu server (12.04LTS and 14.04 LTS)\nPreferable scripting language (PowerShell for Windows, bash/python for Linux).\nExpected solution:\ni. A user-friendly GUI based solution with capability to generate a report of findings.\nii. Should be customizable as per organizational needs and scale to audit large and diverse IT environments effectively.\niii. Scripts should be reliable and accurate in identifying the deviations from\niv. best practices outlined in CIS benchmarks.\nv. Should facilitate easy update and maintenance to accommodate changes in benchmarks over time."
  },
  {
    "A": "1680",
    "B": "Description: The problem statement envisages development of Few Shot Language Agnostic Key Word Spotting system (FSLAKWS) system which would be able to localize and classify the presence of keywords of Interest in a variable duration audio file. The system to be able to function at high performance when very few (Few Shot) examples per keyword are given for training. The key features of the system would be as mentioned below: -\n(a) The system should be language agnostic\n(b) The system should be able to handle audio files at various sample\nrates (8k-48k).\n(c) The system should be able to upgrade to additional keywords.\nPerformance Criteria: For creating a system with Few Shot capabilities, the participants may need to do pre-training of their model on a large corpus. This corpus should be obtained by the participants themselves. We will provide few examples per keyword at the training time during the conduct of the hackathon. The participants will be judged on a separate test set having the same keywords as the train set. The performance would be ascertained on the following:\n(a) Metric\n(b) Latency and throughput of the responses.\n(c) Smaller model size."
  },
  {
    "A": "1681",
    "B": "Background: There are large number of cryptographic algorithms available for ensuring data confidentiality and integrity in secure communication. Identification of the algorithm is a research activity that leads to better understanding of the weakness in its implementation, in order to make the algorithm more robust and secure.\nDescription: The above Problem Statement envisages that approach(s) be developed using AI/ML techniques for identification of the cryptographic algorithm by analyzing given data. The provided datasets are generated using modern cryptographic algorithms. The algorithm is expected to be identified by using a combination of AI/ML and innovative approaches. The successful approaches may also be automated by developing a software solution which takes the given dataset as input and gives probable cryptographic algorithms as output.\nExpected Solution: Logical approach be developed to successfully identify the algorithm for the given dataset. The approaches should either be implemented in software form or should be feasible to be developed as a software."
  },
  {
    "A": "1682",
    "B": "2.1 Background:\n2.1.1 Procurement is an essential component of any project. There are set rules and procedures to undertake various kinds of procurements. Each procurement methodology has several milestones, which too need careful planning and execution, to avoid time and cost over runs.\n2.1.2 As such, Government procurements are driven by the General Financial Rules (GFRs) and the Manuals for Procurement of Goods and of Services. Needless to say, all procurements are made keeping in mind transparency, fair competition amongst vendors as well as cost reasonability for the product services, as public money is involved.\n2.1.3 One of the important methodologies often employed in procurement processes is establishing the ‘price reasonability’ for a certain product/service. This methodology is generally applied at two stages, viz. while obtaining administrative approval for procuring the said product/service, and before opening the commercial bids of qualified vendors.\n2.1.4 The process of ascertaining the price reasonability of any product/service of interest is commonly known as Price Benchmarking.\n2.2 Detailed Description:\n2.2.1 There are various strategies to benchmark the cost. Some of them are as follows:\ni. Sometimes, the cost of the product or the rate at which service is to be hired are already defined by the Government. For example, labor rates.\nii. It may be possible that a similar product/service has been procured by the department in recent past. This can be taken as reference, known as the Last Purchase Price.\niii. When none of the above is known, the most prevalent technique to gather information about the approximate value of the product/service is Market Survey.\n2.2.2 Market Survey may be carried out physically by a team, as the name suggests, by actually visiting the market. However, this practice is only feasible for common goods/services such as stationery, common electrical appliances (AC, Fan, Lights etc), common services (sanitation, horticulture, maintenance etc). In case of sophisticated systems like Networking Solutions, Communication Systems, Sensors, Payloads and other Electronic Systems, this method does not work. In such cases, the market survey is carried out from information available in public domain.\n2.2.3 This presents a complex problem. Information about prices of items which are used in abundancy by various departments (e.g. routers, switches, Hard Disk Drives, Laptops, Workstations, Graphics Cards etc), are available in the public domain, generally speaking. On the other hand, Information about prices of not so common items (e.g. Microwave Devices, Waveguides, Transmission Lines, Antennae, HF/VHF equipment, Software Defined Radios, etc) may or may not be available, resulting in a hit- and-trial approach).\n\n2.2.4 Therefore a web-based application, which can assist various teams to tabulate the approximate price of products/services from various sources from information available in public domain, would be very useful. The contours of such an application is explained in subsequent paragraphs.\n2.3 Expected Solution:\n2.3.1 The solution will be web based. Users will first register themselves and thereafter use it, through their login credentials. The application interface will be simple without unnecessary graphics and multimedia for quick loading and fast responsiveness.\n2.3.2 The users can query the applications either by providing the exact make/model or the most relevant specifications in case of Products, or by providing general information in case of Services.\n2.3.3 Based on the inputs provided by the user, the application will use an appropriate method to crawl the web and gather information, which will then be presented to the user. The minimum input fields and the expected output fields are explained below, for various scenarios.\n(Drive link for further explanation of the expected solution : https://drive.google.com/file/d/1oAwvekZ54TZpntQUnGdVF6gBvGk_NbIu/view?usp=sharing)"
  },
  {
    "A": "1683",
    "B": "Background: Synthetically-generated audios and videos i.e. deep fakes are in trends nowadays. Although these have caught imagination of computer and tech savvy generation, at the same time, these have created concerns because of their ability to disrupt nation’s politics, committing frauds, create dis-information and creating non-consensual contents. Use of Deep fake has also been seen recently to purposefully defame the character of a person in specific. Due to enhancements in AI/ML and Large Language Models for Generative AI, identification and detection of deep fakes have created a huge challenge for Security Agencies. Research on multiple aspects of deep fake identification has been started. As a use case for the problem statement, a forensic technique to authenticate face-swap deep fake videos in which a person's facial identity is replaced with another's may be developed.\nDetailed description: Addressing the deep fake problem requires a multi-pronged approach, combining technology, regulation, education, and collaboration to mitigate the risks and protect individuals and society. However, on the technological front Detecting deep fakes involves development and testing with numerous advanced algorithms and tools. Here are some of the prominent approaches and technologies that can be used in deep fake detection: \ni.Convolutional Neural Networks (CNNs): CNNs can be trained to detect inconsistencies in facial features, expressions, and movements. CNNs can also analyse video frames over time to identify unnatural transitions and discrepancies. \nii.Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) Networks: RNNs and LSTMs can be used to analyse the sequence of frames in a video to detect temporal anomalies and inconsistencies indicative of deep fakes. \niii.Capsule Networks: Capsule networks can identify discrepancies in facial pose and texture. \niv.Adversarial Training: Adversarial training involves using Generative Adversarial Networks (GANs) to generate deep fakes and simultaneously training another model to detect them improving the robustness of detection algorithms. \nv.Audio-Visual Inconsistencies: Combining audio and visual analysis can also help detect deep fakes by identifying mismatches between lip movements and speech, or inconsistencies in ambient sounds. \nvi.Blockchain Technology: Using blockchain to create immutable records of media, providing a verifiable chain of custody for digital content to ensure its authenticity. \nvii.Frequency Analysis: Analysing the frequency domain of images and videos to detect anomalies and artefacts introduced during the deep fake creation process. \nviii.Biometric Verification: Analysing subtle behavioural traits such as micro-expressions, eye and head movement to detect anomalies. \nix.Hybrid Models: Using a combination of spatial, temporal, audio and frequency analysis to improve the robustness and accuracy of deep fake detection. \nExpected solution: A solution based on AI/ML technology may be developed to authenticate face-swap deep fake videos in which a person's facial identity is replaced with another's. This technique may be based on any of the above-mentioned methods or it may combine multiple methods and demonstrate the final deliverable of detection of deep fakes with accuracy. The input of the system will be a video which is suspected of deep fake and the output should contain detailed report w.r.t various characteristics of deep fake e.g. whether confirmed fake (details of abnormalities observed), mathematical underlying techniques of its creation."
  },
  {
    "A": "1684",
    "B": "Background: It has been observed that most individuals are hasty when it comes to upgrade or update their Windows systems to mitigate any adversary actions. Henceforth, a system vulnerability detector and scanner should be in place to audit and verify the system and network based vulnerabilities (if exist) to rectify the misconfigurations and mitigate any prominent threats to the individual or organization. \nDescription: The above problem statement envisions a blue team approach to identify and map potential vulnerabilities of a Windows OS subsystem to better secure and mitigate against various threats (System Level and Network Level). \nExpected Solution: \n• The problem statement should result in a solution which can provide possible vulnerabilities of the underlined Windows OS \n• The AV/EDR friendly solution should have an agent-less mechanism to find the vulnerabilities and must be able to search and crawl for the related available open-source exploits and their patches \n• Some of the key information at the system level that must be promptly identified by the proposed solution should fall under the following categories: \n? System Information: \n? Basic OS info \n? DotNet versions \n? Providers registered for AMSI \n? Registered antivirus (via WMI) \n? Classic and Advanced audit policy settings present in registry keys \n? Auto run executable/scripts/programs \n? Standard and Non-standard firewall rules \n? Windows Defender settings ? User and machine personal certificate files \n? Current environment PATH folders, environment variables and SDDL information \n? Lists files/folders. By default, lists users' downloads, documents, and desktop folders \n? Information about a file (version information, AMSIProvidersProviders registered for AMSI) \n? Installed hotfixses (via WMI) \n? Installed products via the registry \n? Local Group Policy settings applied to the machine/local users \n? Non-empty local groups, displays all groups \n? Local users, whether they're active/disabled \n? All Microsoft updates (via COM, WMI) \n? NTLM authentication settings \n? Saved RDP connections stored in the registry \n? Current incoming RDP sessions \n? Remote Desktop Server/Client Settings \n? Secure Boot configuration \n? Sysmon configuration from the registry \n? UAC system policies via the registry \n? Windows Defender settings (including exclusion locations) \n? Searches PowerShell console history files for sensitive regex matches \n? Network Information: \n? Lists the current ARP table and adapter information \n? DNS cache entries (via WMI) \n? Windows network profiles \n? Network shares exposed by the machine \n? Current TCP and UDP connections and their associated processes and services \n? Current RPC endpoints mapped \n? Open ports status \n• Additionally, the underlined solution should have the capability to provide information at the network level that must fall under the following categories: \n? System interface connectors \n? LLDP / CDP connections (to infrastructure devices) \n? Attached network vectors (systems connected within the VLAN) \n? And the capability to formulate network diagram using these information \n• Should be able to work with latest Windows 10/11 builds \n• The proposed solution should be able to consolidate its findings into a report file (pdf and/or html format)"
  },
  {
    "A": "1685",
    "B": "Background: No single Antivirus is perfect, however each AV product has its own strength and weaknesses, and is more efficient at detecting some threats than others. In addition, one important requirement of Critical Information Infrastructure (CII) is that solution should be “offline and on-premise” and should be “updated with latest definition on regular basis”. Therefore, the reliable and effective solution can be developed by creating a pipeline combining multiple AV engines working parallelly offline. \nDescription: To develop a scanning pipeline in which the data residing in “Target Folder” will be scanned automatically by multiple antiviruses and accordingly the cleaned files will be in same folder and the infected files will be segregated and transferred in a specific folder i.e. “Infected Folders” with their analysis report. In addition, the path of each infected file will also be recorded in a separate doc file in same Infected folders.\nThe functional block diagram is depicted below: \nTarget Folder -> Offline Parallel -> Infected Files\nOne VM may be used for one AV which will be updated regularly (as per respective AV update policy) with latest definition of respective AV. The free/trail version of AVs can be used for building and testing the features of parallel AV pipeline. Atleast following three AVs should be included in AV pipeline: \n1. Window Defender \n2. Trend Micro Maximum Security \n3. Eset Internet Security \nExpected Solution: The details of expected outcomes are given below: \n(a). Raw Data will be kept at “Target folder” and available multiple antiviruses should recognize the presence of data and start scanning automatically. \n(b). Cleaned file will be in same folders and Infected files & its Analysis Report should be move to a dedicated defined “Infected folder”. The path of each infected file will also be recorded in one doc file.\n(c). The scanning process shall be continued till all infected files are segregated. After successful completion by multiple AVs, a popup message of “Scanning Completed” should be displayed. The solution should have dashboard like VirusTotal where the results with each AV should be displayed. \n(d). The scanning shall be started simultaneously by all the multiple AVs (Parallel Processing) for efficient processing."
  },
  {
    "A": "1686",
    "B": "Background: Group Policy Objects (GPOs) are powerful tools in Windows environments, used to centrally manage and enforce system settings, security configurations, and user preferences across a network of computers. The Center for Internet Security (CIS) provides detailed guidelines and benchmarks for securing various operating systems, including Windows 10 and 11. Implementing CIS benchmarks through\ncustomized GPOs ensures that systems adhere to industry best hardening practices, reducing vulnerabilities and enhancing overall security posture.\nDetailed Description :\na) Deploying customized GPOs, based on CIS guidelines or user requirements is essential for hardening Windows systems. It will help in ensuring robust security and maintaining compliance with industry standards. \n(b) The guidelines contain multiple system configurations in terms of registry settings and group policy settings. Deploying of these settings as per user requirement is a daunting task, considering the availability of limited tools and human-intensive efforts. \n(c) Present problem statement is an attempt to explore the possible tools and techniques to automate the task of generating and managing the GPOs as per user requirements for various types of systems including airgapped/standalone machine.\nExpected Solution: Following functionalities have been envisaged for the expected solution: - \n(a) To create, edit and manage GPOs as per CIS guidelines and user requirements, if needed. \n(b) The customised GPOs generated should be deployable on airgapped / standalone system. \n(c) To maintain multiple group / category of system hardening settings with appropriate documentation to define the configuration details for each of the group / category. \n(d) Import / Export of configuration details for catering to user requirement to maintain multiple group / category of system configurations. \n(e) Tool should be able to import documentation from CIS guidelines available in PDF format. \n(f) Envisaged tool should support in deploying GPOs on the target machine. \n(g) Envisaged tool should support in testing and auditing of system configurations on the target machine"
  },
  {
    "A": "1687",
    "B": "Background: Disaster response agencies often stuggle to gather timely and specific information about emergencies from various sources. Social media platforms serve as a valuable repository of such data, but manually monitoring and sorting through the vast amount of information is inefficient and resource-intensive.\nDescription: There is a pressing need for a software solution that can efficiently aggregate and categorize specific disaster-related data from social media, news portals, and other open sources. This software would utilize advanced algorithms to sift through the abundance of information and classify it into different categories data would then be presented on a user- friendly dashboard, allowing disaster response agencies to quickly access relevant information and plan their actions accordingly.\nExpected Solutions: The software solutions will streamline the process of gathering and categorizing disaster-related data from various soucres, significantly reducing the time required for response efforts. By providing real-time insights and actionable information, the software will enhance the effectiveness of disaster response operations, ultimately saving lives."
  },
  {
    "A": "1688",
    "B": "Background: The Jal Jeevan Mission (JJM) is a flagship initiative of the Government of India aimed at ensuring safe and sustainable drinking water to all rural households in the country.\nDevelop a handheld device/Mobile based application designed to support the operation and maintenance (O&M) of drinking water supply schemes. This tool will assist the GP/PHED person to manage assets and consumable inventories, as well as finance-related tasks, enhancing the efficiency and effectiveness of water supply operations. This tool would also have capabilities of bill generation & payment interface such as UPI, Net Banking, Credit cards etc. The panchayat should be able to operate and procure the tool. The tool should enable panchayat to manage in village infrastructure.\nExpected Solution: \na)The tool should record on GIS all assets related to the water supply infrastructure, such as pumps, pipelines, valves, and treatment plants along with attributes.\nb) It should store detailed information about each asset, including location, installation date, and other historical data.\nc) Manage inventories of consumables like chemicals, filters, spare parts, and other supplies and forecast demand and plan for replenishment.\nd) It should be able to record receipts from various sources credited to a/c of GP.\ne) Record expenditure for activities, repairs, replacements and consumable purchases.\nf) Manage consumer list, generate bills, prepare cash book for GP.\ng) User friendly and easy to use for GP level operation.\nh) Local language may be provided\ni) The payment gateway may be integrated\nj) Provision of online UPI payment may be provided\nk) It should have payment interface & bill provisioning."
  },
  {
    "A": "1689",
    "B": "Background \nThe water footprint measures the amount of water used to produce each of the goods and services we use. The water footprint helps us understand for what purposes our limited freshwater resources are being consumed. The impact of it depends on where the water is taken from and when, if it comes from a place where water is already scarce, the consequences can be significant and require action. \nDetailed Description \nThe increase in the amount of non-available water due to pollution and scarce groundwater level has added more water footprints, at the community as well as at the personal levels. An increased \n· water footprint directly affects the health and future of the citizens. Preventing severe drought in water-stressed areas is only going to be possible if water is used with more care and efficiency, this can be achieved if we have readily available data of water footprints. \nExpected Solution \nHence, by using digital technologies like AI, Big Data, Block chain etc. and computer languages, a user friendly app or website may be developed which can provide the water footprints of different items/ final products we eat by feeding little inputs like name, or just by scanning through camera like Google lens. The app should support local languages; this will ensure the pan India usage and sensitize the people about water footprints of items they use in daily life."
  },
  {
    "A": "1690",
    "B": "Background: \nThe absence of a centralized knowledge-sharing platform like wikis significantly hampers the dissemination of water-efficient techniques, which could mitigate water scarcity. Despite the existence of various methods to conserve water, especially in agriculture, the lack of awareness and accessibility to this information perpetuates inefficient water use. This gap in knowledge sharing contributes to the overuse of water resources and exacerbates water stress, particularly in regions where agriculture is heavily dependent on irrigation. Establishing a comprehensive, accessible platform could catalyze the adoption of sustainable practices, crucial for addressing the global challenge of water scarcity. \nDetailed Description: \nA centralized knowledge-sharing platform akin to Wikis would facilitate the exchange of innovative methods, successful case studies, and research findings, fostering local and global collaboration. Without it, valuable insights remain siloed, hindering the adoption of practices that could conserve water resources and enhance sustainability. The creation of an accessible, comprehensive repository of water conservation strategies is thus critical for addressing the pressing challenge of water scarcity worldwide. \nExpected Solution: \nTo address the lack of knowledge sharing platforms on water efficiency, creating a dedicated wiki-style database is the key. This platform would host peer-reviewed articles on water-saving techniques, community forums for sharing local knowledge, videos and interactive tools for calculating water usage and savings. Additionally, integrating social media sharing can amplify reach and engagement, while mobile app development ensures accessibility for users in remote areas, contributing significantly to the reduction of water scarcity globally."
  },
  {
    "A": "1691",
    "B": "Background \nMany existing Dams and Reservoirs are built several decades ago with certain intended purposes. However, due to increasing population, change in extreme climatic conditions, improvement in agricultural practices there is a necessity for re-evaluation of the current infrastructure and water management practices. \nDescription \nIt is likely that existing dams get silted up over time and are unable to store sufficient water. Due to which there will be a shift in the command area or the cropping pattern. It is also a known fact that changing climate issues is also posing a problem, due to which there is need to review the agricultural requirement. The existing dams and reservoirs are increasingly vulnerable to the adverse climate change and shifts in agricultural practices. These changes can lead to structural stress, altered water availability and inefficiencies in water distribution and usage. There is an urgent need to develop and implement new monitoring and water management models to ensure the safety, efficiency, and sustainability of these critical infrastructures. \nExpected Solution \nThis problem will address the safety and resilience of dams and reservoirs against climate - induced risks, enhance water resources management and optimally support the agricultural needs and environmental sustainability. There will also be a long-term planning of water \ninfrastructure in the face of climate and agricultural changes. \nThis needs work on the Hydrological impact due to changes in the climatic conditions, which in turn effect the water demand in the command area. The changing technology, and adaption of new agricultural practices should be taken into account. It is essential to implement a decision support system along with predictive analysis that provide insights to the water managers and policy makers on real-time data."
  },
  {
    "A": "1692",
    "B": "Background \nWater resources are fundamental to sustaining human life, agriculture, industry and ecosystem. Accurate forecasting of future water requirements along with the assessment of current storage capacities are crucial for effective water resources management and planning. With growing population. The domestic, Industrial, Agricultural and ecological demands increase, which in turn leads to strain on existing water Infrastructure. \nDescription \nAnalyzing the storage capabilities of the reservoirs in the country is essential. It is also essential for the policy makers to plan for a sustainable water resource management. The challenge involves in creating a predictive model, that can accurately forecast the future water requirements and evaluate the current and future storage capabilities. The model must integrate various data sources, including historic water usage, climate projections, population growth trends, and agricultural practices. It should also account for variability in climate conditions, demographic shifts and changes in land use. A strategic planning and decision-making support system can to provide clear insights into future water demand and storage needs, by identifying potential risks. \nExpected Solution \nIt is expected to assess the existing and future storage capabilities, identify the anticipated conditions and impact on the storage capabilities. Identify the potential gaps where additional storage and infrastructure capabilities are needed. It is also required to create a scenario taking into account the extreme weather events and population demands. The Policy makers should have an insight of water management issues for providing sustainable water management. A strategy should be evolved for enhancing water storage capacities, optimizing water usage and mitigating identifying risks."
  },
  {
    "A": "1693",
    "B": "Background \nHydraulic transients, or water hammer phenomena, occur when there is a sudden change in water flow velocity, causing rapid pressure fluctuations within a hydraulic system. In hydropower and pumped storage schemes, these transients can lead to severe consequences such as pipe bursts, equipment damage, structural failures, and operational inefficiencies. Accurate prediction and management of these transients are essential to maintain the integrity, safety, and efficiency of these systems. Due to certain limitations in the existing models, there is a need for more precise, comprehensive and adaptable models that can simulate complex transient scenarios under varying operational conditions. \nDescription \nThere is a need for developing an advanced hydraulic transient analysis model that can accurately predict and manage the dynamic behavior of water within hydropower and pumped storage systems. This model should provide accurate and reliable results during tripping of units or sudden power failure. Under these conditions, the machine and water conductor system needs to be protected from damages. The time of closure of the guide vanes play an important role in avoiding adverse effects. The delay in closure of guide vanes causes speed rise on the machine and fast closure causes pressure rise issues. The goal is to enhance the resilience and performance of hydropower and pumped storage infrastructures by addressing the causes and consequences of hydraulic transients comprehensively. \nExpected Solution \nThere is need to develop a sophisticated model that can incorporate computational fluid dynamics (CFD) to simulate the transient behavior of water within the water conductor system. This model should be able to handle complex scenarios such as sudden load changes, emergency shutdowns, start-up and other operational variations. Provide clear visual representations of pressure fluctuations, flow velocities and potential risk areas. This model should be adaptable to different hydropower and pumped storage systems with varying configurations and operational requirements."
  },
  {
    "A": "1694",
    "B": "Background: Namami Gange is a flagship program of the government of India for the rejuvenation of Ganga and its tributaries. NMCG Authority order of Oct 2016 States the the pollution in River Ganga and its tributaries shall also be monitored by use of satellite and other remote sensing technologies.\nAs pupulations increase in the Ganga Basin, there are growing water demands, and hence higher levels of sewage flow into rivers of the Ganga Basin from both rural and urban areas. Excess untreated water entering the Ganga river systems transports high organic and pathogen loads. Their use generates high levels of pollution with significant organic loads, with very high Biochemical Oxygen Demand. This will inevitably lower Dissolved Oxygen (DO) concentrations in rivers, thereby threatening fisheries and biodiversity (maacroinvertebrates). At the same time, the high sewage discharges affect the suitability of the river for bathing due to the higher levels ofpathogens in rivers. With climate change increasing the frequency and intensity of rainfall events, this is becoming a significant problem, threatening the water quality and ecology of Ganga river system. The societal impact of providing forecast data that is easily and openly accessible will change how we see and value our rivers and enable citizens to make better decisions based on better data for our health and the health of the rivers of Ganga Basin.\nDescription: An AI-enabled decision support system may be developed to Integrate data from multiple sources such as satellite data, IOT-based sensor-generated data, intrumental meteorological measurements, in-situ flow, water quality observations, and miltiple hydrological & hydrodynamic models to work together in real-time to generate historical patterns of behaviour and water quality forecasts for Ganga River.\nModel source code can be seamlessly incorporated into a cloud platform infrastructure. The models may receive daily inputs of current and forecasted precipitation and temperature data that drive real-time observations, may be stored in a time series database and automated workflows continually check observations against forecasts. The observed data may act as ground truth and help fine-tune the model's parameters and predictions. This dynamic calibration process may endure the system adapts to changing environmental conditions. The entire workflow may operate within a Software as a Service (SaaS) platform, making it accessible to a wide range of users and organization. Users can access the daily water quality forecasts through an intuitive and user-friendly interface, allowing them to set up early warning alert and conduct scenario modeling.\nThe overall strategy for the forecasting scheme synthesizes satellite data collected across the basin or watershed which is them linked to a model chain to generate flow and water quality data at key locations down a Ganga river system. The daily time series of flow and water quality data can then be displayed online or via a mobile app, to show recent and past changes in water quality. The system should forecast future flows and water quality, up to 3-5 days ahead. This then provides a warning system for operational managers who might want to switch supplies if a significant pollution pulse is moving down the river system. Also, rather like weather forecasts, a probability can be assigned to any forecast, so that users can evaluate predictions in terms of a familiar risk assessment. Regulatory agencies can make use of the system and App to help validate environment agency sampling at locations of interest that are not formal sample points for compliance, and for tracking pollution incidents that occur along river systems.\nExpected Solution: 1. To prepare an AI-enabled decision support system with focus on predictive and adaptive (query based) solutions. A mobile app is envised that utilizes satelliter data to procduce real-time forecasts of flow and water quality using hydrological & hydro dynamical models at multiple locations in a river network.\na. To create historical simulations of flow and water quality, as well as a three to 5 day ahead forecast at any location down the Ganga River, and to provide a tool that scientists, managers, or the general public might use.\nb. Dashboard may show the following options \ni. Ganga River set up a map with options for plotting flow, nitrate, ammonia, phosphorus, DO,BOD,Fecal Coliform and; etc.\nii. It may show a time series plot of paramenters such as rainfall, flow, DO, BOD, Fecal Coliform and nitrate for the Ganga River over the past 10 days and a forecast ahead of 3 days.\n2. Alrets can be sent out to decision makers providing notice of an extreme event, e.g., pollution discharge, combined sewer pverflows discharges, high pathogen events, or a pulse of high nitrate water moving down the river system.\n3. DSS-based post-project monitoring to validate the benefit of government investments."
  },
  {
    "A": "1695",
    "B": "Central Ground Water Board is in the process of installing Digital Water Level Recorders (DWLRs) across the country. CGWB will be monitoring 14,000 DWLRs by 2026, which will generate high-frequency water level measurements. Each DWLR will record 4 ground water level data per day, generating 1460 measurements per year. \nAnalysing all the 14,000 wells will be an enormous task. Accordingly, a software application is proposed to analyse and flag anomalous data. Input to the application will be high frequency water level data collected through the telemetry systems. The application should be able to identify DWLRs recording no data/abnormal data or DWLRs with low battery level. The application will raise alarms and send messages to the concerned officer and vendors to initiate immediate action."
  },
  {
    "A": "1696",
    "B": "Groundwater Level is the cardinal parameter that best describes the health of an Aquifer. Long term groundwater level data acquired through regular monitoring of groundwater levels provide an opportunity to understand the behavior of the aquifers to changing stress regime. Central Ground Water Board periodically monitors ground water levels from nearly 26000 wells. CGWB is also in the process of installing Digital Water Level Recorders (DWLRs) across various parts of Indiaeach capturing and transmitting water level data four times per day. In addition to CGWB there are many other agencies measuring water levels. \nThe software application is expected to analyse groundwater levels and factors impacting groundwater level like rainfall, hydrogeology, landuse, population, surface elevation, natural features, tidal cycles etc. Based on these factors and based on observed water level data, the software application should be able to predict and forecast groundwater levels both in space and time. The application will be accessible to all for predicting groundwater level at any place at any point on time. This will also help in filling data gaps in time-series data."
  },
  {
    "A": "1697",
    "B": "The Chatbot should be able to answer queries related to - water level scenario, hydrogeological scenario, water quality, available reports for an area. Additionally it should generate a comprehensive report of the Aol on - Ground Water Resource Assessment, Categorization of the area, GW management practices to be adopted, Conditions for obtaining NOC for ground water extraction, guidance on how to obtain NOC, definition of groundwater terms, training opportunities related to ground water etc."
  },
  {
    "A": "1698",
    "B": "Learn while you play is considered the most effecting way of teaching. Internet/mobile based games could be one of the best ways to lure school kids, youth and water enthusiasts to learn the nuances of ground water management. With this backdrop it is proposed to develop an internet/mobile based game that teaches good practices in groundwater conservation in an interactive and fun way. The game should take into account various interventions (artificial recharge, microirrigation, crop diversification) and possible scenarios (drought, surplus rain, contamination etc). The gamer can earn points or coins based on the choices that he (or she) makes. The scores of registered gamers will be stored online and water-smart youths can be identified and certified. The game can be used for training and awareness creation."
  },
  {
    "A": "1699",
    "B": "Objective\n The objective is to develop an innovative digital solution, termed the \"Sansthaein Aur Samvidhan”/Institutions & Constitution,\" designed to spread constitutional literacy among citizens. This solution may be in a form of a gamified platform/tool which aims to simplify the language of the Constitution of India pertaining from Institutional perspective (three organs of the Constitution i.e Legislature, Executive & Judiciary) in the form of an engaging activity/ game.\n Parameters to Consider for integration in the Tool:\n 1. Simplifications of the Articles of the Constitution of India :\n o Comprises of Chapters of Constitution of India pertaining to Legislature, Executive & Judiciary. (Part V & Part VI )\n o Develop a comprehensive backend database to map the above mentioned concept of the Constitution in a simpler form.\n o Accessible and user-friendly design, incorporating multimedia elements and language translation features to promote inclusivity and accessibility.\n 2. Multiple Format\n o Solution may be in a diverse format of games (Product coming in the form of Spin a Wheel/Cards games/Board Games/Snake & ladder/Monopoly, etc)\n o Preference may be given if multiple formats are developed.\n o All the topics need to be covered comprehensively ,(products can cover topics separately or in combination)\n \n Deliverables:\n • A functional prototype of the gamified platform, demonstrating key features and functionality.\n • User testing and feedback data, indicating the effectiveness and usability of the platform.\n • A comprehensive report and presentation on the development process, including design decisions, technical challenges, and ethical considerations.\n Expected impact:\n • Increased literacy and awareness among citizens regarding the Constitution of India including children and youth in India and common citizens irrespective of their educational standards enabling them to make informed decisions about their rights and duties."
  },
  {
    "A": "1700",
    "B": "Background: Department of Justice (DoJ) headed by the Secretary is a part of Ministry of Law & Justice, Government of India. Along with the functions of the Department of Justice as per the Allocation of Business (Rules), 1961, implements important schemes for Development of Infrastructure Facilities for Judiciary, setting up of Special Courts for speedy trial and disposal of cases of sensitive nature (Fast Track Special Court for cases of rape and POCSO Act), eCourts Project on computerization of various courts across the country, legal aid to poor and access to justice, financial assistance to National Judicial Academy for providing training to the Judicial Officers of the country.\n• Description: The above problem statement envisages a Chatbot or virtual assistant be developed to understand the user and allow them to ask questions and get information related to DoJ such as\no Know about the various divisions of DoJ,\no Number of Judges appointed at Supreme Court, High Courts, District & Subordinate Courts and current vacancies.\no Pendency of cases through National Judicial Data Grid (NJDG)\no Procedure to pay fine of traffic violation\no Live Streaming of Court Cases\no Steps for the eFiling and ePay\no Know about working Fast track courts\no Ways to download eCourts Services Mobile app\no Availing Tele Law Services\no Know current status of case\nThis chatbot should be able to learn over time to add excellent value to customer interactions and should be capable for handling large data sets if scope expanded.\n• Expected Solution: An interactive Chatbot or virtual assistant be developed for the Department of Justice website resulting into desired information as per the command."
  },
  {
    "A": "1701",
    "B": "Background: With a view to address the issue of faster resolution of commercial disputes and for fostering a conducive environment for ease of doing business in India, the Commercial Courts Act, 2015 was enacted to provide for setting up of commercial courts. Over the years, various legislative and policy reforms have been undertaken by the Government of India with the active support of the judiciary to strengthen the commercial\ndispute resolution machinery in the country. However, expediting the resolution of commercial disputes without addressing the broader issue of huge pendency in courts is unlikely to be successful. Accordingly, it is proposed to leverage the use of technology for expediting the process of dispute resolution.\n? Description: A solution is invited to develop an AI-Driven Research Engine exclusively for commercial courts thereby easing the legal research process for judges and judicial officers ultimately contributing to faster dispute resolution.\no Role: The Research Engine must aggregate and process legal data sources, including case laws, statutory provisions, rules, etc. After aggregation and processing of data, it must extract relevant information, identify key legal principles, precedents, etc. and furnish results.\no Customization: The Research Engine must provide results in a customized manner i.e. as per the needs and demands of each commercial suit.\no Use of Predictive Analytics: The Research Engine must be capable of forecasting case outcomes based on historical trends and patterns.\no Data Localization: The Research Engine must ensure that the results meet the diverse requirements of different High Courts of the country and that adequate emphasis is laid on local laws, rules and procedures.\no Feasibility: The solution must be technically feasible as per the requirements of the Indian Judicial System.\no Reliability: The Research Engine must ensure that the results are relevant and reliable.\no User-Friendly: The Research Engine must be user-friendly.\no Multilingual: The Research Engine must ensure that it supports multiple languages.\no Ethical Concerns: Giving primacy to ethical concerns surrounding the use of artificial intelligence, measures must be taken to ensure that the engine works in a neutral and transparent manner as a ‘facilitator’ and not a ‘decision-maker’.\n? Expected Solution: Development of an “Artificial Intelligence-Driven Research Engine for Commercial Courts” that may be considered for a pilot project for reforms associated with commercial courts with the ultimate objective of ease of doing business in India. The solution is expected to assist in expediting legal research and streamlining judicial processes."
  },
  {
    "A": "1702",
    "B": "Objective\nThe objective is to develop an innovative digital solution, termed the \"Bail Reckoner,\" designed to assist undertrial prisoners, legal aid providers, and judicial authorities in streamlining the bail process. The Bail Reckoner aims to simplify and expedite the bail application and evaluation process by considering various legal and procedural parameters.\nParameters to Consider for integration in the Tool:\n1. Nature of the Offense and Penal Provisions:\no Seek the inputs for the charges framed (can be multiple charges, and if they are compoundable etc). In this regard Statutes like Indian Penal Code,1860 and the upcoming Bhartiya Nyaya Sanhita 2023; Bhartiya Suraksha Sanhita 2023; and Bhartiya Saakshya Adhiniyam 2023; should be covered. Special statutes on the following under-mentioned areas should also be covered:\n1. Cyber Crimes\n2. Crimes Against SCs and STs:\n3. Crimes Against Women\n4. Crimes Against Children\n5. Offences Against the State\n6. Economic Offence\n7. Crimes Against Foreigners\na. Develop a comprehensive backend database to map penalties with sections of various Acts/Laws.\nb. Link and provide detailed information on the nature of offenses and corresponding legal provisions.\n2. Duration of Imprisonment Already Served:\na. Track the duration of imprisonment undertrial prisoner has served.\nb. Highlight the eligibility timeline for bail based on the time already served.\n3. Considerations of Judge’s Discretion:\na. Evaluate the risk of the undertrial prisoner escaping the judicial process, such as leaving the country.\nb. Assess the potential influence the prisoner may have on evidence or witnesses.\n4. Procedural Pre-requisites:\na. Outline requirements such as surety bonds, personal bonds, fines (if applicable), and identity verification.\nb. Ensure compliance with procedural aspects under IPC/CrPC.\n5. Judicial Pronouncements on Bail Eligibility:\na. Integrate key judicial pronouncements regarding bail eligibility.\nb. Automatically identify undertrial prisoners who are eligible for bail if they have served half the term during the undertrial stage, based on the prescribed sentence for their charges.\nSolution Requirements\n. The Bail Reckoner should be a user-friendly, plug-and-play tool that can be integrated into existing software systems. It must provide a clear and accessible interface for:\n1. Undertrial Prisoners: To understand their eligibility and process for applying for bail.\n2. Legal Aid Providers: To assist in preparing and submitting accurate bail applications.\n3. Judicial Authorities: To streamline the evaluation process and ensure timely decisions.\nBy leveraging technology and innovation, the Bail Reckoner aims to make the bail process more transparent, efficient, and just, contributing to a more equitable legal system."
  },
  {
    "A": "1703",
    "B": "Objective\n The objective is to develop an innovative digital solution, termed the \"Nagrik Aur Samvidhan”/Citizen & Constitution,\" designed to spread constitutional literacy among citizens. This solution may be in a form of a gamified platform/tool which aims to simplify the language of the Constitution of India pertaining to a Common Man in the form of an engaging activity/ game.\n Parameters to Consider for integration in the Tool:\n 1. Simplifications of the Articles of the Constitution of India :\n o Comprises of Preamble, Fundamental Rights (Part III), Directive Principles of State Policy (Part IV) & Fundamental Duties(Part IV A).\n o Develop a comprehensive backend database to map the above mentioned concept of the Constitution in a simpler form.\n o Accessible and user-friendly design, incorporating multimedia elements and language translation features to promote inclusivity and accessibility.\n \n 2. Multiple Format\n o Solution may be in a diverse format of games (Product coming in the form of Spin a Wheel/Cards games/Board Games/Snake & ladder/Monopoly, etc)\n o Preference may be given if multiple formats are developed.\n o All the topics need to be covered comprehensively ,(products can cover topics separately or in combination)\n \n Deliverables:\n • A functional prototype of the gamified platform, demonstrating key features and functionality.\n • User testing and feedback data, indicating the effectiveness and usability of the platform.\n • A comprehensive report and presentation on the development process, including design decisions, technical challenges, and ethical considerations.\n Expected impact:\n • Increased literacy and awareness among citizens regarding the Constitution of India including children and youth (level of minimum 8th Std) in India and common citizens irrespective of their educational standards enabling them to make informed decisions about their rights and duties."
  },
  {
    "A": "1704",
    "B": "Background\n1. Article 243G of the Constitution of India acknowledges Panchayats as institutions of local self-government and mandates them to prepare plans for economic development and social justice. As local government, Gram Panchayats (GPs) are responsible for delivery of basic services to local citizens and address the vulnerabilities of poor and marginalized ones. This can only be achieved through implementation of well thought out\nplans through efficient and responsible utilization of available resources.\n2. An efficient and robust planning process as part of GP’s core functioning becomes necessary. GP development plan should ideally match people’s needs and priorities with the available resources. It should be prepared through a fair, inclusive, transparent, and participatory process. The focus should be on local development issues, local perception of need and priority, local analysis of problems and solutions, and local resources management all within a collective local vision.\n3. Gram Panchayat Development Plans (GPDP) to be prepared for effective implementation of flagship schemes/ programmes on subjects of National importance.\nThe formulation process of Panchayat Development Plans (PDP) must be comprehensive and based on participatory process, which inter alia involves the full convergence of the schemes of Central and State Governments related to 29 subjects listed in the Eleventh Schedule of the Constitution.\n4. A need was felt to take forward the Sustainable Development Goals (SDGs) up to the last mile, i.e., up to the GP level, leveraging a wide network and strong institutional mechanism of third tier of Government including Traditional Bodies of non-part IX areas.\nAccordingly, the Ministry has adopted a thematic approach aggregating 17 SDGs into 9 broad themes for Localization of Sustainable Development Goals (LSDGs) at grassroot level through Panchayats adopting ‘Whole of Government and Whole of Society Approach’ and the PDPs will be prepared adopting thematic approach to achieve localization for SDGs in rural India.\n\n29 Subjects defined in the Eleventh Schedule\n1. Agriculture\n2. Poverty all eviation programme\n3. Land Improvement.\n4. Education\n5. Minor Irrigation\n6. Vocational education\n7. Animal Husbandary\n8. Adult and non-formal education\n9. Fisheries\n10. Libraries\n11. Social Forestery\n12. Cultural activites\n13. Minor forest produce\n14. Markets and fairs\n15. Small scale industires\n16. Health and Sanitation\n17. Khadi, village and cottage industries\n18. Family welfare\n19. Rural Housing\n20. Women and child development\n21. Drinking water\n22. Social Welfare\n23. Fuel and fodder\n24. Welfare of the weaker sections\n25. Roads\n26. Public distribution system\n27. Rural electrification\n28. Maintenance of community assets\n29. Non-Conventional energy\n\nDescription\nDesign a game for a Hackathon event that enhances participant engagement, fosters planning, and develops a better Panchayat/Village development\nThe objective is to create a gamified experience that can help villagers/youth, etc. to prepare a village development plan. A simulated environment is needed to develop a self-sustained village development plan game where the user can plan various facilities in the\n\nvillage using the resources available. It is envisaged to develop ‘Farmville’ kind of a game for a village. Developers can use any game development platform to create the game for android platform. SVAMITVA Scheme GIS data maps of villages will be provided as input.\nKey Components to include for the game app:\nBudget Estimate: Functionality to add the estimate for each type of activity for which planning is required. For example, if new/extension road needs to be constructed for the gram panchayat / village, it should allow us to add the budget for road feature planning.\nWork Model: Development of a game for taking up works under Gram Panchayat Development Plan (GPDP) such as road construction, drainage construction, establishment of toilets, streetlights, etc.\nThe basic steps of the Game broadly involve: -\ni. Select the village, where development plan is required by the villagers.\nii. Based on the input received such as the village building footprints, road network, etc., develop the 3D visualization of the existing village for which development plan is required.\niii. Superimpose the SVAMITVA Scheme maps/drone data to have a real-world visualization of the village.\niv. Developmental activities would provide the list of activities that a plan would be composed. For example, a new road laying for a stretch in the village, laying of\ndrainage pipeline for the village, drinking water pipeline for all the villagers, etc.\nv. There is resource envelope/money available with Panchayats under different Schemes for different types of developmental work. Once the development activity\nas in point iv above is planned in the game, the amount shall be deducted from the Resource Envelope allocated to Panchayats.\nvi. Generate a more realistic 3D model with other existing features.\nvii. Arrive at a tentative estimate for the planning being performed.\nviii. Ability to provide a walkthrough of the 3D platform.\nix. Ability to provide a fly-through of the 3D platform.\nA few examples of probable use cases are indicated below: -\nCase1: Road laying activity\n\n• The player selects the start point and endpoint with intermediate points wherever required for road construction. It needs to validate that any road laying activity may not be a duplicate road construction plan.\n• The player can select the type of the road, width of the road; height of the road etc., based on the selection, the road should be built in the game. Based on\nchanging the parameters like type of road from BT road to cement road, it should be regenerated.\n• Once the road construction is done by the player, cost of construction should be auto generated.\n• Ability to measure the road dimensions and road shoulders.\n\nCase 2: Streetlight\n\n• The player selects the road where streetlight is required. The streetlight is added based on the game artefacts.\n• The player has option to check the light illumination based on the time of the day for best location for streetlight along the road. Option to change the type of lamp, based on the lamp change – the changes to reflect on the game for best results.\n• Once finalized, the cost estimate of the street lighting to be generated.\n\nCase 3: Ability to measure the building height and width of each side.\n\n• The player selects the village for developmental activity.\n• The player is presented with a 3D simulated environment representing selected village.\n• The player can measure the height of building and all sides to create the dimension of the house along with roof type area.\n\nExpected Solution\nPanchayats have been the fulcrum of local self-government since ancient times, exercising both executive and judicial powers over village-level issues. We plan to\ndevelop a virtual 3D environment-based gaming platform for village/Panchayat development plan activities.\n• A detailed game outlining the work model.\n• Prototypes or mock-ups of the game platform/interface.\n• Documentation on implementation guidelines and best practices for integrating the gamification system into the Hackathon event.\n1. Article 243G of the Constitution of India acknowledges Panchayats as institutions of local self-government and mandates them to prepare plans for economic development and social justice. As local government, Gram Panchayats (GPs) are responsible for delivery of basic services to local citizens and address the vulnerabilities of poor and marginalized ones. This can only be achieved through implementation of well thought out plans through efficient and responsible utilization of available resources.\n2. An efficient and robust planning process as part of GP’s core functioning becomes necessary. GP development plan should ideally match people’s needs and priorities with the available resources. It should be prepared through a fair, inclusive, transparent, and participatory process. The focus should be on local development issues, local perception of need and priority, local analysis of problems and solutions, and local resources management all within a collective local vision.\n3. Gram Panchayat Development Plans (GPDP) to be prepared for effective implementation of flagship schemes/ programmes on subjects of National importance.\nThe formulation process of Panchayat Development Plans (PDP) must be comprehensive and based on participatory process, which inter alia involves the full convergence of the schemes of Central and State Governments related to 29 subjects listed in the Eleventh Schedule of the Constitution.\n4. A need was felt to take forward the Sustainable Development Goals (SDGs) up to the last mile, i.e., up to the GP level, leveraging a wide network and strong institutional mechanism of third tier of Government including Traditional Bodies of non-part IX areas.\nAccordingly, the Ministry has adopted a thematic approach aggregating 17 SDGs into 9\nbroad themes for Localization of Sustainable Development Goals (LSDGs) at grassroot\nlevel through Panchayats adopting ‘Whole of Government and Whole of Society\nApproach’ and the PDPs will be prepared adopting thematic approach to achieve\nlocalization for SDGs in rural India.\n\n\n29 Subjects defined in the Eleventh Schedule\n\nDescription\nDesign a game for a Hackathon event that enhances participant engagement, fosters\nplanning, and develops a better Panchayat/Village development\nThe objective is to create a gamified experience that can help villagers/youth, etc. to\n\nprepare a village development plan. A simulated environment is needed to develop a self-\nsustained village development plan game where the user can plan various facilities in the\n\nvillage using the resources available. It is envisaged to develop ‘Farmville’ kind of a game\nfor a village. Developers can use any game development platform to create the game for\nandroid platform. SVAMITVA Scheme GIS data maps of villages will be provided as input.\nKey Components to include for the game app:\nBudget Estimate: Functionality to add the estimate for each type of activity for which\nplanning is required. For example, if new/extension road needs to be constructed for the\ngram panchayat / village, it should allow us to add the budget for road feature planning.\nWork Model: Development of a game for taking up works under Gram Panchayat\nDevelopment Plan (GPDP) such as road construction, drainage construction,\nestablishment of toilets, streetlights, etc.\nThe basic steps of the Game broadly involve: -\ni. Select the village, where development plan is required by the villagers.\nii. Based on the input received such as the village building footprints, road network,\netc., develop the 3D visualization of the existing village for which development\nplan is required.\niii. Superimpose the SVAMITVA Scheme maps/drone data to have a real-world\nvisualization of the village.\niv. Developmental activities would provide the list of activities that a plan would be\ncomposed. For example, a new road laying for a stretch in the village, laying of\ndrainage pipeline for the village, drinking water pipeline for all the villagers, etc.\nv. There is resource envelope/money available with Panchayats under different\nSchemes for different types of developmental work. Once the development activity\nas in point iv above is planned in the game, the amount shall be deducted from the\nResource Envelope allocated to Panchayats.\nvi. Generate a more realistic 3D model with other existing features.\nvii. Arrive at a tentative estimate for the planning being performed.\nviii. Ability to provide a walkthrough of the 3D platform.\nix. Ability to provide a fly-through of the 3D platform.\nA few examples of probable use cases are indicated below: -\nCase1: Road laying activity\n\n• The player selects the start point and endpoint with intermediate points wherever\nrequired for road construction. It needs to validate that any road laying activity may\nnot be a duplicate road construction plan.\n• The player can select the type of the road, width of the road; height of the road\netc., based on the selection, the road should be built in the game. Based on\nchanging the parameters like type of road from BT road to cement road, it should\nbe regenerated.\n• Once the road construction is done by the player, cost of construction should be\nauto generated.\n• Ability to measure the road dimensions and road shoulders.\n\nCase 2: Streetlight\n\n• The player selects the road where streetlight is required. The streetlight is added\nbased on the game artefacts.\n• The player has option to check the light illumination based on the time of the day\nfor best location for streetlight along the road. Option to change the type of lamp,\nbased on the lamp change – the changes to reflect on the game for best results.\n• Once finalized, the cost estimate of the street lighting to be generated.\n\nCase 3: Ability to measure the building height and width of each side.\n\n• The player selects the village for developmental activity.\n• The player is presented with a 3D simulated environment representing selected\nvillage.\n• The player can measure the height of building and all sides to create the dimension\nof the house along with roof type area.\n\nExpected Solution\nPanchayats have been the fulcrum of local self-government since ancient times,\nexercising both executive and judicial powers over village-level issues. We plan to\ndevelop a virtual 3D environment-based gaming platform for village/Panchayat\ndevelopment plan activities.\n• A detailed game outlining the work model.\n• Prototypes or mock-ups of the game platform/interface.\n• Documentation on implementation guidelines and best practices for integrating the\ngamification system into the Hackathon event.\nThese are few of the cases described by this concept. Students should try to model maximum topics and also have a comprehensive guided documentation which leads to development of a super fine game."
  },
  {
    "A": "1705",
    "B": "Background\n1. The Hon’ble Prime Minister launched the SVAMITVA Scheme on the National Panchayati Raj Day, 24th April 2020 with a resolve to enable the economic progress of Rural India by providing “Record of Rights” to every rural household owner. The scheme aims to demarcate inhabited (Abadi) land in rural areas through the latest surveying drone technology, Continuous Operating Reference System (CORS), and Geographic Information System (GIS) technology. The scheme covers multifarious aspects viz. facilitating monetization of properties and enabling bank loan; reducing property-related disputes; comprehensive village-level planning\n2. With the use latest drone technology and CORS technology for the Abadi land survey, the high resolution and accurate image base maps of 50 cm have facilitated creation of the most durable record of property holdings in these areas with no legacy revenue records. Such accurate image-based maps provide a clear demarcation of land holdings in a very short frame of time compared to on ground physical measurement and mapping of the land parcels.\nDescription\ni. Develop an AI model capable of identifying key features in orthophotos with high precision: Use of AI/ML techniques for extraction of the following features from SVAMITVA Drone Imagery using a cloud-based solution: -\na. Building footprint extraction (built-up area from the drone image and classified roof-top based on observation on the imagery as RCC, Tiled, Tin, and Others. These built up area can be used for various service such as solar energy calculation, property tax calculation, etc.)\nb. Road feature extraction\nc. Waterbodies extraction, etc\nii. Achieve a target accuracy of 95% in feature identification.\niii. Optimize the model for efficient processing and deployment.\n\nThe broad scope of work includes:-\ni. Data Preparation: Utilize the SVAMITVA Scheme drone-labeled datasets for 10 villages to train and validate the AI model.\nii. Model Development: Employ Convolutional Neural Networks (CNNs) or other suitable AI/ML models for image segmentation and feature identification.\niii. Model Training: Efficient training of the model ensures it learns to identify the desired features accurately.\niv. Model Optimization: Fine-tune the model to achieve the target accuracy of 95%, optimizing for speed and resource utilization.\nv. Testing and Validation: Rigorously test the model on a separate dataset to ensure its accuracy and reliability.\nvi. Deployment and Integration: Prepare the model for deployment and integration into the Ministry of Panchayati Raj’s existing systems for practical application.\n\nExpected Solution\ni. A fully trained and optimized AI model for feature identification in orthophotos.\nii. Documentation detailing the model architecture, training process, and deployment guidelines.\niii. A final report summarizing the project outcomes, including accuracy metrics and recommendations for future improvements."
  },
  {
    "A": "1706",
    "B": "Description:\nDevelop a chatbot using deep learning and natural language processing techniques to accurately understand and respond to queries from employees of a large public sector organization. The chatbot should be capable of handling diverse questions related to HR policies, IT support, company events, and other organizational matters. (Hackathon students/teams to use publicly available sample information for HR Policy, IT Support, etc. available on internet.)\n\nDevelop document processing capabilities for the chatbot to analyse and extract information from documents uploaded by employees. This includes summarizing a document or extracting text (keyword information) from documents relevant to organizational needs. (Hackathon students/teams can use any 8 to 10 page document for demonstration).\n\nEnsure the chatbot architecture is scalable to handle minimum 5 users parallelly. This includes optimizing response time (Response Time should not exceed 5 seconds for any query unless there is a technical issue like connectivity, etc.)\n\nEnable 2FA (2 Factor Authentication – email id type) in the chatbot for enhancing the security level of the chatbot.\n\nChatbot should filter bad language as per system-maintained dictionary.\nYoutube Link/Video Link (3 Minute video explaining the Problem Statement): https://youtu.be/Q3pP7mRk5Qk\n\nNOTE: GAIL (INDIA) LTD will not provide any hardware, software, license, data or any other resource to SIH hackathon Teams. The teams should use free and/or open-source resources, as applicable, for the entire project."
  },
  {
    "A": "1707",
    "B": "Description:\nA mobile application needs to be developed to streamline and automate the attendance tracking of its employees across multiple office locations. This application will leverage geolocation technology to record employee check-in and check-out times along with geo-location as they enter and leave the office premises.\nAim of this App is to enhance operational efficiency, reduce manual attendance tracking errors, and provide a seamless experience for employees to manage their work-related movements. \n\nKey Requirements:\n1) Geolocation-Based Check-In and Check-Out:\nAutomatically record check-in time and geo-location when an employee enters within a 200-meter radius of his office.\nRecord check-out time when the employee leaves the 200-meter radius.\nEnsure that each check-in is paired with a corresponding check-out, regardless of the frequency of entries and exits.\n2) Manual Location Check-In / Check-Out for Offsite Work:\nProvide a manual check-in and check-out feature for employees working at locations other than his offices.\nAutomatically suggest relevant locations based on real-time longitude and latitude data, allowing employees to confirm their check-in and check-out at these suggested locations.\n3) Calculate the employees total working hours.\n4) Data Accuracy and Integrity:\nEnsure the application maintains accurate and tamper-proof records of all check-in and check-out events.\nEnable real-time data synchronization and secure storage to prevent data loss and ensure reliability.\nYoutube Link/Video Link (3 Minute video explaining the Problem Statement): \nhttps://youtu.be/bmw8unoxA7U \n\nNOTE : GAIL (INDIA) LTD will not provide any hardware, software, license, data or any other resource to SIH hackathon Teams. The teams should use free and/or open-source resources, as applicable, for the entire project."
  },
  {
    "A": "1708",
    "B": "BACKGROUND: \nIn a SCADA system, for a pipeline network spanning thousands of kilometres, the network devices (both layer 2 and layer 3) are spread all along the geographical area. With such a large network, it becomes crucial, from both the maintenance and security point of view, to continuously monitor the complete network topology. Automatic topology discovery provides a complete and up-to-date map of all devices, connections, and pathways within the SCADA network. This comprehensive overview is essential for network administrators to understand the network's structure and dynamics. It ensures that any changes in the network, such as new devices being added or existing ones being removed, are automatically detected and documented in real time. When issues arise, knowing the exact layout and connections within the network helps in pinpointing problems more quickly, reducing downtime and improving response times. More significantly, automatic topology discovery helps in identifying unauthorized devices or unexpected changes in the network, which could indicate security breaches or cyber-attacks and allows for better network segmentation and implementation of access controls, limiting the spread of potential threats and protecting critical assets. Conventionally, automatic topology discovery tools utilize Cisco Discovery Protocol (CDP) or Link Layer Discovery Protocol (LLDP). However, these protocols are vulnerable due to lack of authentication, broadcast of sensitive information, etc. and hence are not suitable for use in a critical pipeline SCADA network.\nProblem Statement Details:\n“Develop a tool for automatic network topology discovery, for a network using EIGRP routing protocol, that does not rely on CDP or LLDP protocols. The tool may use secure SNMPv3 polls/traps, ARP/MAC tables, NetFlow, routing protocol or syslog data for creating the automatic network topology. The challenge is accurate device identification without relying on the broadcast capabilities of CDP/LLDP and determining the physical and logical connections between devices. It must have a provision to keep the topology map updated with real-time changes in the network along with scalability to ensure that the solution works efficiently across small to large-scale networks. The most important component is to maintain network security to prevent unauthorized access or data leakage during the discovery process.”\nNOTE : GAIL (INDIA) LTD will not provide any hardware, software, license, data or any other resource to SIH hackathon Teams. The teams should use free and/or open-source resources, as applicable, for the entire project."
  },
  {
    "A": "1709",
    "B": "Background: The current manual process of verifying documents for various official purposes is time-consuming, error-prone, and lacks efficiency. This process involves verification of numerous documents such as birth certificates, academic transcripts, identification cards, and experience certificates. There is a pressing need for an online solution that automates and secures the document verification process.\n\nDescription: This problem statement addresses the urgent requirement for an online platform, empowered by artificial intelligence (AI) and blockchain technology, to automate document verification for all official purposes. The proposed solution aims to establish a user-friendly portal accessible to issuing authorities (e.g., schools, universities, employers), verifying authorities (government offices, banks, legal entities), and individuals. Issuing authorities will generate digital certificates for individuals, including birth certificates, academic transcripts, and experience certificates. These certificates will be securely stored on the blockchain for tamper-proof authenticity. Individuals will have access to the portal to view all documents issued in their name.\n\nExpected Solution: Participants are tasked with developing a comprehensive portal that facilitates the generation, verification, and accessibility of essential documents for any official purpose. The platform should utilize Al algorithms to efficiently verify the authenticity of uploaded documents. Verifying authorities will have access to a secure interface to validate submitted documents against predefined criteria. Individuals will be able to access the portal to view all documents issued to their name. The implementation of blockchain technology will ensure the immutability and integrity of the verified certificates. Ultimately, the solution aims to streamline the document verification process, reducing time and resources required for all stakeholders involved in official documentation."
  },
  {
    "A": "1710",
    "B": "Background:\nRailway stations are complex environments with numerous facilities and locations such as ticket counters, platforms, restrooms, food courts, and waiting areas. Passengers often face difficulties in navigating these spaces, especially in large or unfamiliar stations. Efficient and user-friendly navigation systems are crucial for improving passenger experience, reducing congestion, and ensuring timely travel connections.\n\nDescription:\nThe problem involves developing a comprehensive navigation solution for railway stations that assists passengers in locating various facilities and destinations within the station premises. This includes creating detailed maps, providing real-time directions, and integrating features such as accessibility options for individuals with disabilities. The solution should be intuitive, easy to use, and accessible via multiple platforms, including mobile devices and digital kiosks. Key challenges include updating navigation information in real-time, ensuring accuracy, and accommodating the diverse needs of all passengers.\n\nExpected Solution:\nThe expected solution is a multi-platform navigation system that provides detailed, real-time directions to all facilities and locations within a railway station. This system should include:\nA mobile application with 3D interactive maps and step-by-step navigation.\nDigital kiosks located throughout the station with touch-screen interfaces.\nVoice-guided navigation for visually impaired passengers.\nRegular updates to reflect changes in station layout and facility locations.\nIntegration with existing railway apps and services for seamless user experience.\nThe solution should enhance the overall passenger experience by reducing confusion, saving time, and improving accessibility within the station"
  },
  {
    "A": "1711",
    "B": "Background: Rail Madad is a vital platform for passengers to report issues and seek assistance during their train journeys. However, the current process relies heavily on manual complaint registration, leading to delays and inefficiencies. After a grievance is registered on Rail Madad, it is acknowledged with a unique ID, categorized into type of complaints, and assigned to the relevant department. Responsible officials investigate and take corrective actions, updating the system with the status. Categorizing the complaints needs some improvements and can be made to enhance the Rail Madad complaint resolution process using Artificial Intelligence (AI). especially when complainants share photos, videos and audios only.\nDescription: According to the problem statement above, it is imperative that complaints are correctly assigned and classified, and that departmental transitions be seamless. The aforementioned problem necessitates an Al-based solution.\nExpected Solution:\n1. Automated Categorization and Prioritization: Integrate the system with the existing Rail Madad platform to streamline the complaint management process.\n? Image and Video Analysis: Use Al-powered image and video recognition to automatically categorize the nature of the complaint (e.g., coach cleanliness, damage, staff behaviour).\n? Urgency Detection: Implement Al to assess the severity of the issue from visual content and prioritize complaints that need immediate attention.\n2. Enhanced Data Extraction:\n? Text Recognition (OCR): Utilize Optical Character Recognition (OCR) to extract textual information from images or videos, such as signage or documents, to gather more contexts about the complaint.\n? Metadata Analysis: Extract metadata from images and videos (e.g., timestamp, location) to provide additional information for more accurate and quicker resolution.\n3. Automated Response and Routing:\n? AI Chatbots: Deploy Al chatbots to provide instant acknowledgment and preliminary responses, collecting additional necessary information from the complainant.\n? Smart Routing: Use Al algorithms to route complaints to the most appropriate department or official based on the content of the photos or videos.\n\n4. Predictive Maintenance:\n? Issue Prediction: Implement machine learning models to predict recurring issues from the analysis of visual data trends, helping in proactive maintenance and reducing future complaints.\n5. Feedback and Continuous Improvement:\n? Sentiment Analysis: Use Al to analyze the sentiment of feedback provided by complainants, identifying areas needing improvement. \n? Performance Monitoring: Continuously monitor the effectiveness of the complaint\nresolution process through Al-driven analytics, making data-driven adjustments for process enhancement. \n? Accuracy detection: Accuracy of Al-powered complaint detection can be analysed.\n? Speed Analysis: Speed of complaint registration and resolution.\n? User experience and satisfaction.\n? Scalability and integrability with existing system.\n6. Training and Support:\n? Al-Assisted Training: Provide Al-based training tools for staff to help them better analyze and resolve complaints efficiently using visual data.\n? Resource Allocation: Use Al to analyze complaint patterns and allocates resources dynamically, ensuring that high-priority issues receive prompt attention.\n7. Evaluation Criteria:\n? Accuracy of Al-powered complaint detection\n? Speed of complaint registration and resolution\n? User experience and satisfaction\n? Scalability and integrability with existing systems"
  },
  {
    "A": "1712",
    "B": "Project Concept: Enhanced Education System for specially abled \nBackground:\nInterpersonal skills are learned and mastered by children when they interact with the world, but for children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID) this is where the challenges lie. As traditional classroom settings cannot cater to their unique learning requirements, prompting a demand for innovative educational tools that enhance learning engagement and effectiveness. The Virtual Reality (VR) technology which is capable of simulating controlled and immersive environments. It supports safe, repeatable, personalized, interactive experiences with children with unique sensory and cognitive profiles. Existing research demonstrates the potential that VR has for enhancing social functioning in ASD. supporting the benefits of computer-assisted technology on learning and the quality of life for children with special development needs.\nDescription:\nThe Interactive Skills Enhancer (ISE)-a virtual reality software designed primarily for children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID) to catalyze their social skills interlaces with their personal growth. This piece of VR kit places the user into a range of virtual, socially realistic scenarios that can be customized, including classroom environments and playground social structures. It includes not just advanced Al for emotion recognition, in-the-moment feedback to steer social behavior appropriately, and opportunity for skills reinforcement. Featuring sensitivity & sensory needs specific attributes - ISE provides a fun, nurturing, & secure space that facilitates children to progressively develop, learn, and refine social cues and interactions in a personalized setting. The monitoring dashboard for parents and educators, can help to follow the progress and individualize the learning experience provided through ISE, making the latter a complete package for boosting the social skills in children with children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID).\nExpected Outcome:\nThe proposed solution titled Interactive Skills Enhancer (ISE) is a Virtual Reality (VR) based application intended for teaching social skills to children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID) ISE leverages interactive VR environments designed to enable children to participate in virtual social scenarios that are typical of everyone daily routine. They are developed in order to foster the skills, both to learn and to reinforce such as recognizing emotion, acquiring, or beginning a social conversation, and to respond appropriately in social interaction. ISE is customizable for individual sensitivities, and includes a dashboard for educators and parents to track progress using data and to offer a wide range of engaging, effective tools for children with ASD and ID, all designed to make the biggest impact on their interpersonal capabilities.\nNOTE : This is an innovation opportunity and students are encouraged to think out of the box to develop solutions which can be presented in newer ways + which can address the needs in out of the box ways for a certain industry OR makes the platform generic. Above description serves as a guide to specify essential needs that can be satisfied for the developed solution and is not limited only to the scope described\"\""
  },
  {
    "A": "1713",
    "B": "Project Concept: Enhanced Education System for specially abled \nBackground:\nInterpersonal skills are learned and mastered by children when they interact with the world, but for children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID) this is where the challenges lie. As traditional classroom settings cannot cater to their unique learning requirements, prompting a demand for innovative educational tools that enhance learning engagement and effectiveness. The Virtual Reality (VR) technology which is capable of simulating controlled and immersive environments. It supports safe, repeatable, personalized, interactive experiences with children with unique sensory and cognitive profiles. Existing research demonstrates the potential that VR has for enhancing social functioning in ASD. supporting the benefits of computer-assisted technology on learning and the quality of life for children with special development needs.\nDescription:\nThe Interactive Skills Enhancer (ISE)-a virtual reality software designed primarily for children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID) to catalyze their social skills interlaces with their personal growth. This piece of VR kit places the user into a range of virtual, socially realistic scenarios that can be customized, including classroom environments and playground social structures. It includes not just advanced Al for emotion recognition, in-the-moment feedback to steer social behavior appropriately, and opportunity for skills reinforcement. Featuring sensitivity & sensory needs specific attributes - ISE provides a fun, nurturing, & secure space that facilitates children to progressively develop, learn, and refine social cues and interactions in a personalized setting. The monitoring dashboard for parents and educators, can help to follow the progress and individualize the learning experience provided through ISE, making the latter a complete package for boosting the social skills in children with children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID).\nExpected Outcome:\nThe proposed solution titled Interactive Skills Enhancer (ISE) is a Virtual Reality (VR) based application intended for teaching social skills to children with Autism Spectrum Disorder (ASD) and Intellectual Disabilities (ID) ISE leverages interactive VR environments designed to enable children to participate in virtual social scenarios that are typical of everyone daily routine. They are developed in order to foster the skills, both to learn and to reinforce such as recognizing emotion, acquiring, or beginning a social conversation, and to respond appropriately in social interaction. ISE is customizable for individual sensitivities, and includes a dashboard for educators and parents to track progress using data and to offer a wide range of engaging, effective tools for children with ASD and ID, all designed to make the biggest impact on their interpersonal capabilities.\nNOTE : This is an innovation opportunity and students are encouraged to think out of the box to develop solutions which can be presented in newer ways + which can address the needs in out of the box ways for a certain industry OR makes the platform generic. Above description serves as a guide to specify essential needs that can be satisfied for the developed solution and is not limited only to the scope described\"\""
  },
  {
    "A": "1714",
    "B": "Background: The rehabilitation institutes involved in this activity face high therapy cases load and more number of student therapists with less number of therapy supervisors. Following this system in manual mode impedes providing prompt services.\nDescription: Clinical services with respect to speech language therapy begins with patient allocation to the therapist. The therapist then prepares therapy plan with goals and activities. The respective case supervisor needs to check the therapy plan and provide the inputs for further continuation of regular therapy sessions. At least post ten therapy sessions the therapist writes the progress report of the therapy case. Further, it is evaluated by the supervisor. This Cycle of speech language therapy clinical services in continuous until the therapy case has completely improved or discontinued due to various reasons. The supervisor based on overall handling of therapy sessions gives clinical ratings.\nExpected Solution: The process needs to become digitized with the use of software where in right from the allocation of cases, therapy related documentation by both therapist and supervisor, clinical evaluation of therapy, feedback and clinical rating can be performed."
  },
  {
    "A": "1715",
    "B": "Background: Indian Sign Language (ISL) is a visual-gestural language used by deaf and hard-of-hearing individuals across India. It encompasses a rich vocabulary of hand movements, facial expressions and body postures to convey messaging. ISL facilitates communication and fosters community among deaf individuals, enabling them to express emotions, share ideas and engage in every day interactions.\nDescription: The need for audio to Indian Sign Language (ISL) conversion arrises from the communication barrier between the deaf community, which primarily uses ISL, and individuals who do not know sign language but communicate through spoken language. This barrier hinder effective communication in various settings, including education, healthcare and various interactions. Without a mean to convert audio into ISL, deaf individual faces challenging in accessing information and participating fully in society.\nExpected Solution: The expected solution entails developing technology-such as software or devices-capable of accurately converting spoken language to Indian Sign Language (ISL). This technology should use speech recognition, natural level processing, and computer vision to transcribe and interpret audio input, generating corresponding ISL gestures in real-time. It should prioritize accuracy, user-friendliness, and adaptibility to regional variation of ISL, thereby facilitating seamless communication between deaf individual and those who do not know sign language. \nFor example: 1. Development of application by which announcement/ text display in railway platform Display Unit Converted to Indian Sign Language, so that deaf people can see it and understand the announcement.\n2. Development of Mobile app through by which using Mobile Camera, normal person can understand sign language used by dead individuals."
  },
  {
    "A": "1716",
    "B": "Create a solution that translates Indian Sign Language (ISL) into text and speech in real-time, facilitating communication for the deaf and hard-of-hearing community with the hearing world. The application should be capable of recognizing and interpreting a comprehensive library of ISL signs and gestures, and then provide accurate text and speech output in multiple Indian languages."
  },
  {
    "A": "1717",
    "B": "Develop a mobile application that enables real-time voice-to-text and text-to-voice translation for Indian regional languages, aimed at assisting individuals with hearing and speech impairments to communicate effectively. The app should support multiple Indian languages and dialects, be user-friendly, and have a simple interface for easy navigation.\n\nKey Features to Include:\n\nReal-time voice-to-text translation for Indian regional languages.\nText-to-voice feature to convert typed text into spoken words in the selected Indian language.\nSupport for multiple Indian languages and dialects, with the ability to easily switch between them.\nAn intuitive user interface that is accessible for individuals with hearing and speech impairments.\nOffline functionality for basic translations without the need for an internet connection.\nIntegration with other communication apps to allow for seamless translation during conversations.\nPrivacy-focused design to ensure user data is secure and not shared without consent.\nChallenges to Address:\n\nEnsuring high accuracy in voice recognition and translation, considering the diverse accents and dialects within Indian languages.\nDeveloping a text-to-speech engine that sounds natural and is easy to understand.\nCreating an interface that is inclusive and easy to use for individuals with varying levels of tech-savviness.\nBalancing app performance with offline capabilities to ensure it remains functional in areas with poor internet connectivity.\nThis problem statement aligns with the need for inclusive communication tools and leverages technology to bridge the gap for those with hearing and speech impairments. It also presents an opportunity to innovate in the field of language translation and speech recognition technology."
  },
  {
    "A": "1718",
    "B": "Develop an advanced system capable of capturing the nuanced non-manual features (NMFs) of Indian Sign Language (ISL), such as facial expressions, head movements, and body posture, and accurately converting them into written text. This system should enhance the translation of ISL by including these essential components of sign language communication, which provide critical context and meaning beyond manual signs.\n\nKey Features to Include:\n\nHigh-precision recognition of NMFs using advanced image processing and machine learning techniques.\nReal-time conversion of recognized NMFs into contextually appropriate text.\nA comprehensive database of NMFs associated with ISL, including regional variations.\nUser-friendly interface for both sign language users and those learning ISL.\nCapability to integrate with existing ISL to text translation systems to provide a more complete translation experience.\nOffline functionality to ensure accessibility and usability in various environments.\nChallenges to Address:\n\nCreating a recognition system sensitive enough to capture the subtleties of NMFs in ISL.\nEnsuring the system can operate in diverse lighting and background conditions.\nDeveloping an extensive and representative database of NMFs in ISL.\nBalancing system performance with the need for real-time processing and output.\nThis problem statement addresses the need for a more holistic approach to ISL translation by incorporating NMFs, which are often overlooked in current translation technologies. It presents an opportunity for innovation in the field of sign language recognition and translation, aiming to improve communication accessibility for the deaf and hard-of-hearing community."
  },
  {
    "A": "1719",
    "B": "Background: In the context of the skill development training program, there is a need to establish a robust automated monitoring system to assess and enhance effectiveness of classroom training so as early detection of below average training institutions can be done. \nDescription: The above problem requires a system capable of analyzing classroom images thus can help identify the types of activites and interactions taking place during training sessions. Undestanding these activites can shed light on the quality and relevance of the training content. A dataset consisting of classroom pictures can be provided for various job roles along with course curriculam, infra requirements etc required for the skill development training programme. \nExpected Solution: System should be able to analyze the images and flag cases which need enhanced monitoring or cancellation."
  },
  {
    "A": "1720",
    "B": "Background: Education and awareness are critical components of the National Anti-Doping Agency’s mission to promote clean sport. Despite ongoing efforts, the reach and impact of current educational initiatives remain limited, particularly in remote and rural areas. The rapid advancement of technology presents an opportunity to bridge these gaps and ensure that comprehensive anti-doping education is accessible to all stakeholders in the sporting community.\nDescription: The above problem statement envisages to design and develop innovative technological solutions to effectively disseminate anti-doping information to athletes, coaches, support staff, and the broader sporting community. The solution should utilize modern digital tools and platforms to ensure comprehensive coverage, engagement, and retention of critical anti-doping knowledge. It should cater to diverse linguistic and cultural backgrounds and be accessible across various digital devices.\nKey Objectives\n(a) Comprehensive Coverage: Ensure that anti-doping information reaches a wide audience across various sports and regions in India, including remote and underserved areas.\n(b) Engagement: Create interactive and engaging content that captures and retains the attention of athletes and stakeholders, making learning about anti-doping practices impactful.\n(c) Retention: Develop methods to ensure that the information is not only received but also retained and applied by the target audience. This includes periodic assessments and interactive elements to reinforce learning.\nDetailed Requirements\n(a) Platform Development\nCreate a multilingual mobile application and web portal to disseminate anti-doping information. Ensure the platform is user-friendly, accessible, and compatible with various devices, including smartphones, tablets, and computers.\n(b) Content Creation Develop engaging multimedia content, including videos, infographics, podcasts, and interactive modules. Include real-life scenarios and case studies to provide practical insights into anti-doping practices. Regularly update the\ncontent to reflect the latest anti-doping rules, guidelines, and best practices. \n(c) Interactive Features Implement quizzes, puzzles, and gamified elements to enhance user engagement. Include discussion forums and chat features for real-time interaction and support. Provide certifications or badges for users who complete specific educational modules.\n(d) Real-Time Updates Integrate a notification system to provide real-time updates on anti-doping regulations, news, and events. Allow users to subscribe to newsletters and alerts for the latest information. \n(e) Analytics and Feedback Incorporate analytics tools to track user engagement, progress, and learning outcomes. Collect user feedback to continuously improve the platform and its content.\nExpected Solution\nA comprehensive and accessible digital platform for anti-doping education. High levels of engagement and interaction from athletes and stakeholders. Improved understanding and adherence to anti-doping regulations. Measurable improvements\nin knowledge retention and application among users."
  },
  {
    "A": "1721",
    "B": "Background: Effective intelligence and investigative capabilities are essential for uncovering and addressing doping violations. Current methods often lack the sophistication needed to keep up with evolving doping strategies. nhancing these capabilities through advanced technologies can significantly improve the National Anti-Doping Agency’s ability to detect, investigate, and act upon doping violations.\nDescription: The above problem statement envisages the designing of a comprehensive intelligence and investigation system to enhance NADA’s ability to detect, investigate, and act upon doping violations. The solution should integrate multiple data sources and provide robust analytical tools, enabling proactive and reactive measures against doping.\nKey Objectives\n(a) Data Integration: Combine data from various sources, including testing results, athlete biological passports, and third-party information, to create a comprehensive database.\n(b) Advanced Analytics: Utilize advanced analytics and AI to identify patterns and anomalies indicative of doping.\n(c) Actionable Intelligence: Generate actionable intelligence to guide investigations and enforcement actions, ensuring timely and effective responses to doping violations.\nDetailed Requirements\n(a) Centralized Database Develop a secure and scalable database to store and manage data from diverse sources. Ensure the database supports real-time data updates and access controls.\n(b) Data Sources Integrate data from testing results, athlete biological passports, medical records, and other relevant sources. Include external data sources such as social media, financial transactions, and travel records to provide a holistic view.\n(c) Analytical Tools Implement AI and machine learning algorithms to analyze data and identify suspicious patterns. Develop predictive models to assess the risk of doping among athletes. Provide visualization tools to help investigators understand and interpret complex data.\n(d) Investigation Management\nCreate a user-friendly interface for investigators to track and manage cases. Include features for case ocumentation, evidence management, and collaboration among investigators. Develop automated reporting tools to\ngenerate comprehensive investigation reports.\n(e) Confidential Communication Establish secure communication channels for whistleblowers and confidential\ninformants. Ensure anonymity and protection of informants’ identities.\n(f) Training and Resources Provide training for investigators on the use of the new system and analytical\ntools. Develop a resource library with guidelines, best practices, and case studies on anti-doping investigations.\nExpected Solution:\nA centralized and comprehensive intelligence and investigation system. Enhanced ability to detect and investigate doping violations using advanced analytics. Improved coordination and efficiency in managing doping cases. Increased protection for whistleblowers and informants, encouraging more reports of doping activities."
  },
  {
    "A": "1722",
    "B": "Background: Traditional methods of disseminating anti-doping information often fail to engage\nyounger athletes effectively. Gamification, the application of game-design elements and game principles in non-game contexts, can be a powerful tool to make learning about anti-doping rules more engaging and interactive. By incorporating gamification, the National Anti-Doping Agency can enhance its educational initiatives and foster a\nculture of clean sport among young athletes.\nDescription: The above problem statement envisages the creation of a gamified platform to educate athletes on anti-doping rules and practices. The solution should be engaging, informative, and foster a culture of clean sport among young athletes. It should incorporate game elements such as points, badges, leader boards, and challenges to motivate users to learn and apply anti-doping information.\nKey Objectives\n(a) Engagement: Develop engaging and interactive content that motivates athletes to learn about anti-doping, leveraging the appeal of gaming to enhance educational outcomes.\n\n(b) Education: Ensure that the gamified content effectively conveys critical anti-doping information, covering rules, prohibited substances, testing procedures, and the importance of clean sport.\n(c) Behavioural Change: Encourage positive attitudes and behaviours towards clean sport, promoting a sense of responsibility and commitment among young athletes.\nDetailed Requirements\n(a) Platform Development Develop a gamified mobile app and web-based platform that is accessible to athletes across different devices. Ensure the platform is user-friendly, visually appealing, and easy to navigate.\n(b) Game Elements Incorporate points, badges, leader boards, and levels to incentivize participation and learning. Design challenges, quests, and mini-games that teach anti-doping concepts in an engaging way. Include social features that allow users to compete with friends, share achievements, and collaborate on challenges.\n(c) Educational Content Develop comprehensive educational modules covering various aspects of anti-doping. Use multimedia content, including videos, animations, and interactive infographics, to make learning enjoyable. Include real-life scenarios and case studies to provide practical insights and reinforce learning.\n(d) Assessment and Feedback Implement quizzes and assessments to test users’ knowledge and understanding of anti-doping rules. Provide immediate feedback and explanations to help users learn from their mistakes. Offer rewards and recognition for users who demonstrate high levels of knowledge and commitment.\n(e) Analytics and Reporting Integrate analytics tools to track user engagement, progress, and learning outcomes. Generate reports on user performance, highlighting areas of strength and areas needing improvement. Use data insights to continuously improve the platform and its content.\nExpected Solution:\nA highly engaging and educational gamified platform for anti-doping information. Increased knowledge and awareness of anti-doping rules and practices among young athletes. Positive behavioural changes towards clean sport, with athletes demonstrating greater commitment to anti-doping principles. Enhanced engagement and participation rates in anti-doping education programs."
  },
  {
    "A": "1723",
    "B": "Background:\nAuminium wire rod is produced in Wire rod mills of cast house, where an aluminium cast bar of trapezoidal cross section having area 3437 sq. mm is first casted and then further rolled by 15 nos. of stand in series to gradually reduce the cross section to obtain final 9.5 mm diameter rod.\nDescription:\nThe casting parameters that affects the wire rod properties like UTS, Elongation and Conductivity are dependent on chemical composition, casting temp. Cooling water temp. , Casting speed, Cast bar entry temperature at rolling mill, Emulsion temperature and pressure at rolling mill, Emulsion concentration and finally rod quench water pressure. These parameters are dynamic in nature and any deviation on one of the above affects the final rod properties.\nExpected Solution:\nUse of AI, ML or any modern technique to analyze those parameters and control them to effectively obtain the final desired parameters of the Wire rod produced."
  },
  {
    "A": "1724",
    "B": "Background: Multiplicity of authorities and implementing agencies in Indian Urban landscape is one of the biggest challenges for urban governance. Not only does it lead to underutilization of resources available with various departments, execution of multiple projects at same site may also lead to interference and delays due to miscoordination. A digital platform for interdepartmental cooperation can potentially resolve these issues and make inter-departmental cooperation more streamlined.\n Example- A road developed by one agency, may get damaged due to installation of gas pipelines or utility ducts on road 2 months later. This can be resolved with preemptive collaboration between both implementing agencies.\n Description: The digital platform can provide solutions for-\n 1. Exchange of data and resources (technical expertise, machinery, technology etc.), and list of ongoing and upcoming projects between various agencies.\n 2. Scheduling of tasks, reports, and work distribution between agencies for projects categorized as \"Inter-departmental\"\n 3. Identification of projects in different departments which share the project site, and tools for assistance in organizing meetings of various departments, unified project phasing (to reduce costs incurred), planning and execution of projects.\n 4. Training and capacity building exercises, workshops & seminars.\n 5. Discussion forum with (Intra department, inter department, and public form sections.\n Expected Solution- A digital platform for interdepartmental cooperation which allows functions of-\n a. Registering departments, employees, officers, technical experts etc. with their accounts.\n b. Sharing data, ongoing projects with location, and inventory of available resources between departments/agencies.\n c. Creation of tasks, scheduling, reporting and work distribution across departments for inter-departmental and multi-departmental projects.\n d. Identification, unified phasing, planning, and implementation of projects on same site\n e. Discussion forum, with different forum sections allowing access to specific groups of users."
  },
  {
    "A": "1725",
    "B": "Background: The monitoring of physical progress of construction activities requires a technical expert to visit and observe the site. Due to large number of projects in Indian cities, field visits by technical experts for weekly/daily monitoring becomes non-feasible. A machine learning based solution, which can identify the status of construction activities based on images, can allow the ULBs, state agencies, and central agencies to monitor physical progress daily, or even in real time.\n Description: The problem requires a machine learning based software solution in which images from sites of ongoing building construction projects can be processed, to identify the stage of construction.\n As the construction activities include multiple components, stages in construction, and interior works; the software can take inputs regarding (number of building in image, type of progress in construction activities to be assessed (foundation, super-structure, facade, interiors, etc.)), to identify the type of algorithms to be used to analyze the images.\n For different components of construction activities, different machine learning algorithms will need to be developed with training using images from construction site. If the selected category of construction activity and uploaded images have different activities/ components, the software should raise an error and ask for selection of appropriate category.\n While similar monitoring solutions are required for all types of projects, the current problem statement only includes \"building construction projects\" to keep scope of problem statement limited and assess the feasibility of similar solutions in future.\n Expected Solution: A software solution utilizing machine learning algorithm to identify stage of construction/progress of construction activities from uploaded site images. Which should be able to:\n A. Allow users to upload images and provide information regarding type of activity to be assessed (foundation, super structure, furnishing, interiors, etc.) \n B. Analyze the images and describe the construction activity and stage of construction.\n C. Compare status of construction with previous site images and provide data regarding progress of work.\n D. Raise error in case of incorrect image/details have been uploaded and ask the user for necessary corrections."
  },
  {
    "A": "1726",
    "B": "Background: The monitoring of physical progress of construction activities requires a technical expert to visit and observe the site. Due to large number of projects in Indian cities, field visits by technical experts for weekly/daily monitoring becomes non-feasible. A machine learning based solution, which can identify the status of construction activities based on images, can allow the ULBs, stage agencies, and central agencies to monitor physical progress daily, or even in real time.\n Description: The problem requires a machine learning based software solution in which aerial/drone-based images from sites of ongoing road construction projects can be processed, to identify the stage of construction.\n As the road construction activities include multiple components and stages in construction; the software can take inputs regarding (type of activity, exact road stretch (from which location to which location) etc.), to identify the type of algorithm to be used to analyze the images. \n For different components of construction activities, different machine learning algorithms will need to be developed with training using images from road construction site.\n While similar monitoring solutions are required for all types of projects, the current problem statement only includes \"road construction projects\", to keep scope of problem statement limited and assess the feasibility of similar solutions in future.\n Expected Solution: A software solution utilizing machine learning algorithm to identify stage of road construction works or progress of construction activities from uploaded site images, which should be able to:\n - Allow users to upload images and provide information regarding type of activity to be assessed (installation of utility ducts, macadamization, road construction, installment of pedestrian infrastructure, etc.)\n -Analyze the images and describe the construction activity, stage of construction, and road lengths for which different components have been completed.\n -Compare status of road construction with previous site images and provide data regarding progress of work.\n -Raise error in case of incorrect image/details have been uploaded and ask the user for necessary corrections."
  },
  {
    "A": "1727",
    "B": "Background: In metro system OEM install the switches and bind these switches with their MAC address mostly so it is difficult to install or upgrade the different switch in network without compromising the cyber security. Retrofitting these systems with modern security protocols can he challenging and costly, particularly for organizations with limited resources or technical expertise.\nDescription: The problem statement aims to develop a universal switch set equipped with data encryption and decryption capabilities that can be seamlessly integrated into various legacy applications lacking cyber safety measures. The switch set will provide a standardized interface for encrypting sensitive data before transmission and decrypting it upon receipt, thereby enhancing the security of legacy systems.\nThe switch set will support industry-standard encryption algorithms and protocols to ensure compatibility with a wide range of legacy applications. It will be designed to be easily configurable and customizable to accommodate different encryption requirements and data formats used by various applications.\nFurthermore, the switch set will include robust key management features to securely generate. store, and distribute encryption keys to authorized users. This will prevent unauthorized access to encrypted data and ensure the integrity and confidentiality of sensitive information.\nExpected Solution: The proposed solution will involve the development of a universal switch set with data encryption and decryption capabilities tailored for legacy applications without cyber safety measures. This switch set will consist of modular components, including encryption/decryption engines, key management systems, and integration interfaces. The switch set will seamlessly integrate with existing infrastructure and protocols. requiring minimal configuration and customization.\nBy retrofitting legacy applications with data encryption and decryption capabilities, the proposed solution will enable organizations to safeguard their sensitive information and comply with regulatory requirements without the need for costly system upgrades or replacements"
  },
  {
    "A": "1728",
    "B": "Background:\nThe Prime Minister's Special Scholarship Scheme (PMSSS) aims to support the education of students across India. Traditionally, the process of disbursing scholarships involves significant paperwork, including the submission and verification of documents, which can be time-consuming and prone to delays. The SAG Bureau seeks to streamline this process by developing an online mechanism that allows students to submit their documents digitally. This initiative will facilitate quicker verification and disbursement of scholarships without the need for hard copies, promoting efficiency and reducing the environmental impact of paper usage.\nDescription:\nThe proposed system will allow students to upload their required documents through a secure online portal. Upon submission, the documents will be automatically sent to the SAG Bureau for verification. Once verified, the SAG Bureau will forward the approved documents to the Finance Bureau for the release of payments. The system will ensure that the entire process, from document submission to scholarship disbursement, is conducted digitally, eliminating the need for any hard copy submissions.\nKey features of the system should include:\n• A user-friendly interface for students to upload and manage their documents.\n• Secure authentication and verification mechanisms to ensure the authenticity of the submitted documents.\n• An automated workflow to route the documents from the SAG Bureau to the Finance Bureau after verification.\n• Real-time tracking and notification system to keep students informed about the status of their submissions and payments.\n• Compliance with data privacy and security standards to protect the personal information of the students.\nExpected Solution:\n\nThe expected solution is a comprehensive, fully digital system for the submission, verification, and disbursement of PMSSS scholarships. The solution should:\n• Enable students to upload their documents digitally and track their submission status.\n• Allow the SAG Bureau to verify the uploaded documents without the need for physical copies.\n• Facilitate the automatic forwarding of verified documents to the Finance Bureau for payment processing.\n• Ensure a seamless, paperless process that enhances efficiency, reduces processing time, and minimizes the risk of document loss or misplacement."
  },
  {
    "A": "1729",
    "B": "Background:\n\nThe All India Council for Technical Education (AICTE) is the primary body responsible for the accreditation and approval of technical education institutions across India. This process, which includes application submissions, document verification, and detailed evaluations by multiple stakeholders, is currently burdened by inefficiencies. The existing system relies heavily on manual processes and paperwork, leading to delays, administrative overhead, and limited visibility into the approval process.\n\nProblem Statement:\n\nThe AICTE approval process involves numerous steps and interactions among educational institutions, regulatory authorities, and evaluators. There is a need for an innovative AI-supported portal that can modernize and streamline the approval workflow, enhance transparency, and significantly reduce processing times.\n\nDescription:\n\n1. Automate and Optimize Workflow: Design an AI-driven portal that automates and refines the submission, verification, and evaluation stages, reducing manual intervention and expediting the approval process.\n\n2. Enhance Document Verification:Deploy AI technologies to facilitate automatic verification and validation of documents, ensuring compliance with AICTE standards and improving accuracy.\n\n3. Improve Transparency and Communication: Develop an intuitive interface that offers real-time tracking of application status, deadlines, and feedback, fostering better communication between institutions and evaluators.\n\n4. Efficient Resource Allocation:Utilize AI to forecast and allocate resources effectively, ensuring optimal distribution of workload among evaluators and reducing process bottlenecks.\n\n5. Strengthen Security and Compliance: Integrate advanced AI-based security features to safeguard sensitive information and ensure adherence to data privacy regulations and compliance standards.\n\nScope:\n\nApplication Processing: Automate the intake and preliminary review of applications to streamline the workflow.\nDocument Verification: Implement AI tools for authenticating and validating documents, checking for completeness and adherence to guidelines.\nEvaluator Matching: Use AI algorithms to match applications with suitable evaluators based on expertise and current workload.\nReal-Time Tracking: Create a system for tracking application progress, providing timely updates, and facilitating communication.\nAnalytics and Reporting: Offer AI-powered insights and reporting tools to monitor process efficiency and identify areas for continuous improvement.\nDigital Dimension Tracking of the Infrastructure: Develop a system to digitally track and verify the dimensions of the infrastructure provided by the applicants. Utilize AI and computer vision to analyze photographs, videos, and other documents to ensure the physical infrastructure meets AICTE standards.\n\nExpected Benefits:\n\n- Accelerated processing times and reduced administrative burden.\n- Enhanced accuracy and reliability in document validation.\n- Improved transparency and communication between all parties involved.\n- Better resource management and a balanced workload for evaluators.\n- Robust security measures and compliance with data privacy regulations.\n\nBy developing this AI-supported AICTE Approval Process Portal, the goal is to revolutionize the approval process, making it more efficient, transparent, and user-centric, thereby benefiting educational institutions, regulatory authorities, and the broader educational ecosystem. \nProcess Document:\n https://aicte-india.org/sites/default/files/approval/APH%20Final.pdf"
  },
  {
    "A": "1730",
    "B": "Background:\nInstitutional inspections are crucial for maintaining educational standards and ensuring compliance with regulatory guidelines. Traditional inspection methods are manual, time-consuming, and often lack consistency. There is a need for a more efficient, consistent, and data-driven approach to institutional inspections.\nDetailed Description:\nAn AI-driven Inspection System for Institutions aims to revolutionize the way inspections are conducted by incorporating AI technologies to enhance accuracy, efficiency, and consistency. This system would leverage AI algorithms to analyze various aspects of an institution, such as infrastructure, faculty qualifications, student performance, and adherence to regulations.\nThe system can utilize image recognition for facility inspections, natural language processing for analyzing reports and documentation, and machine learning for identifying patterns and potential issues. Real-time data collection and analysis would enable inspectors to make informed decisions and provide actionable insights for institutional improvements.\nExpected Solution:\n1. Automated Facility Inspections: Use image recognition to assess infrastructure and facilities.\n2. Document Analysis: Employ natural language processing to evaluate reports, qualifications, and compliance documents.\n3. Real-time Data Collection: Continuously gather and analyze data from various sources to provide up-to-date insights.\n4. Pattern Recognition: Identify trends and potential issues using machine learning algorithms.\n5. Actionable Insights: Generate comprehensive reports with suggestions for improvements and compliance adherence"
  },
  {
    "A": "1731",
    "B": "As the global shift towards renewable energy intensifies, solar trackers, which adjust solar panels to follow the sun’s path, are crucial for maximizing solar energy efficiency. Consequently, it is essential to design controllers for solar trackers that can optimize the angle of incidence between solar panels and sunlight. This tracking of the sun’s trajectory can be done accurately by managing at least one mechanical axis (azimuth, elevation, roll). As a preliminary step, a simulation-based control system, using tools such as SimscapeTM MultibodyTM and Simulink®, can be designed with a single-axis control based on location-specific solar paths. The workflow would involve integrating an electrical motor model (developed using tools like SimscapeTM ElectricalTM), designing a PID control system, developing an algorithm for optimal axis positioning, and validating the system through simulation. In the subsequent steps after validation, the motor control system can be deployed on low-cost hardware (e.g., using Simulink® Support Package for Arduino) to demonstrate a prototype of this solar tracking mechanism.\nReferences: \n1. Pre- Requisite: https://matlabacademy.mathworks.com/details/control-design-onramp-with-simulink/controls?s_eid=PSM_33221 \n2. Optimizing Solar Array Performance Using MPPT (https://in.mathworks.com/videos/optimizing-solar-array-performance-using-mppt-1657880084126.html?s_tid=srchtitle_site_search_8_solar%20tracker) \n3. Pre- Requisite: Power Systems Simulation Onramp - CHAPTER 4 (System Integration) (https://matlabacademy.mathworks.com/details/power-systems-simulation-onramp/orps?s_eid=PSM_33222) \n4. Using the Worm and Gear Constraint Block - Solar Tracker (https://in.mathworks.com/help/sm/ug/using-the-worm-and-gear-constraint-block-solar-tracker.html)\n5. Program the Device from Simulink | Arduino Light Meter Project, Part 2 (https://in.mathworks.com/videos/arduino-light-meter-project-part-2-program-the-device-from-simulink-106500.html)\n\nRequire MATLAB® and Simulink® PRODUCT LICENSE for SIH 2024, please send an email to 'ageethag@mathworks.com'."
  },
  {
    "A": "1732",
    "B": "Description: This project aims to enhance (Low Light Image Enhancement) the feeble light reflected from PSR regions of Lunar craters into a better SNR image for interpretations.\nChallenge: Feeble signal to better signal image generation.\nLow light image noise removal.\nUsage: For generating first of its kind PSR image map of lunar poles captured by OHRC of Chandrayaan-2.\nUsers: Landing site selection users and geomorphological application users.\nAvailable Solutions (if Yes, reasons for not using them): Specific solution of Chandrayaan-2 needs to be developed. General techniques and algorithms are available.\nDesired Outcome: Software for generating low light image enhancement."
  },
  {
    "A": "1733",
    "B": "Description: Synthetic Aperture Radar (SAR) imagery is rich in structural and textural information but lacks the intuitive appeal of color, which can provide more comprehensive insights for space borne applications. SAR image colorization using Deep Learning (DL) models offers a transformative approach for enhancing the interpretability of monochromatic SAR image data. The project aims to develop an innovative solution to colorize grayscale SAR images for enhanced interpretation and analysis of feature targets. A novel DL model needs to be designed and trained using pairs of SAR and Optical images, minimizing a loss function that captures the difference between predicted and actual color images. The participants are challenged to create a DL system that can accurately predict and apply colors to SAR images, making surface features more distinguishable and interpretable.\nChallenge: The challenges require innovative approaches in data pre-processing, DL model design, and evaluation methodologies to develop effective and reliable SAR image colorization solutions.\nUsage: The goal is to improve the usability of SAR data in applications like geological studies and environmental monitoring by providing more intuitive and informative visual representations.\nUsers: Remote Sensing Image Analysts\nAvailable Solutions (if Yes, reasons for not using them): Existing Deep Learning models have been proposed and used but their performance is not satisfactory.\nDesired Outcome: DL based SAR Image Colorization Software"
  },
  {
    "A": "1734",
    "B": "Description: Develop an AI/ML (Artificial Intelligence/Machine Learning) model to generate fine spatial resolution air quality map from coarse resolution satellite data. It should utilise existing python-based ML libraries. Developed model need to be validated with unseen independent data.\nChallenge: \nTo utilise large satellite data having gaps under cloudy conditions \nTo select suitable ML algorithm and ensure optimal fitting of ML model for desired accuracy\nTo validate model output with unseen independent data\nUsage: To enhance air quality knowledge, Sharpen focus at local level\nUsers: Researchers and government bodies monitoring/working on air quality assessment \nAvailable Solutions (if Yes, reasons for not using them): Individual components are available, comprehensive and proven solution does not exist.\nDesired Outcome: Fine resolution air quality map of NO2"
  },
  {
    "A": "1735",
    "B": "Description: Develop a mobile or desktop (qgis plugin) or web application that uses on-device GPU/NPU for interactive semantic segmentation on images loaded using WMS service.\nChallenge: To ensure the system is user-friendly and accessible, even for non-technical users.\nTo utilize the computational power of GPUs/NPUs to enhance the performance and responsiveness of the system and reduce reliance on server side GPU compute.\n\nUsage: Useful for assisting on-screen digitization for various remote sensing applications.\nUsers: WebGIS application developers and the end users of these applications.\nAvailable Solutions (if Yes, reasons for not using them): Individual components are available, comprehensive and proven solution does not exist.\nDesired Outcome:\n1. The tool should be compatible with and OGC compatible WMS service.\n2. It should provide data export in geospatial format of user selected features (geojson/kml).\n3. It should make maximum utilisation of on-device GPUs/NPUs available in modern desktop/mobile devices."
  },
  {
    "A": "1736",
    "B": "Description: Develop a system that automatically generates videos using frame interpolation techniques given a WMS service that provides satellite imagery at regular intervals (e.g. every 30 minutes) and a bounding box. The AI based video generator should interpolate frames (for e.g. at every minute between 30 minutes) for smooth visualization of moving objects. This video should be displayed on an interactive browser based map (using openlayers or leaflet). \nChallenge: Frame interpolation of objects such as clouds which are deformable and even appear disappear between frames.\nOverlaying videos on web based map visualization libraries is straightforward on commercial libraries such as mapbox. Developing the same functionality for modern open-source webgis libraries will be an added effort.\nUsage: Can be implemented for visualization on VEDAS/MOSDAC/BHUVAN\nUsers: WebGIS application developers and the end users of these applications.\nAvailable Solutions (if Yes, reasons for not using them): Individual components are available, comprehensive and proven solution does not exist.\nDesired Outcome: \nThe tool should be compatible with and OGC compatible WMS service.\nShould demonstrate video visualization overlay on an OpenLayers (> version 6) web map. \nBonus points for utilisation of on-device GPUs/NPUs available in modern desktop/mobile devices. (not mandatory)"
  },
  {
    "A": "1737",
    "B": "Description: DVB -S2X waveforms is have various types of modulation scheme like QPSK, APSK etc. The selection of modulation scheme is based upon channel. A novel AMR based soft algorithm is need to develop to detect the DVB S2X modulation waveform on ground in order to synchronized the ground receiver from satellite\nChallenge:\n1. To develop the algorithm compliant to existing DVB S2X waveform. \n2. To ensure the develop algorithm should not complex to implement and not taking much hardware resources.\n3. To integrate all DVB S2X waveform together and having a single detection algorithm.\n\nUsage: To develop Automatic modulation recognition algorithm of software define radio based upon DVB S2X waveform.\nUsers: All software define radio user who are designing the new SDR based upon DVB S2X waveform will required this algorithm.\nAvailable Solutions (if Yes, reasons for not using them): Solution exits but more versatile, less complex and more generic nature algorithms is required, which can accommodate future waveform also\nDesired Outcome: Develop a tool or proof-of-concept model. The solution should be able to detect and recognize DVB S2X waveform, data rate and other modulation parameter. The model should be scalable to accommodate all current DVB S2X waveform and also able to accommodate future waveform also."
  },
  {
    "A": "1738",
    "B": "Description: Design and development of novel applications of Cloud Optimized GeoTIFFs for Efficient Streaming and On-the-Fly processing of INSAT Satellite Data.\nChallenge: \n1. Data Acquisition and Preprocessing: Acquire Level 1 INSAT satellite data from relevant sources. Pre-process the data to ensure compatibility with the COG format.\n2. COG Generation: Develop a pipeline to convert INSAT Level 1 data into Cloud Optimized GeoTIFFs. Ensure the pipeline supports multiple spectral bands and their efficient encoding.\n3. Selective Streaming and Partial Download: Implement selective streaming capabilities to allow users to access specific data regions and bands without downloading entire files. Enable partial downloads for efficient data handling and reduced bandwidth usage.\n4. On-the-Fly Manipulations: Develop tools for real-time manipulations of multiple spectral bands, including band arithmetic, colour adjustments, and custom visualizations. Integrate these tools into a user-friendly interface for seamless interactions.\n5. System Integration and Testing: Integrate the COG generation pipeline and on-the-fly manipulation tools into a cloud-based system. Conduct thorough testing to ensure performance, reliability, and user experience.\nUsage: To make INSAT Data Cloud compatible\nUsers: Meteorologist\nAvailable Solutions (if Yes, reasons for not using them): No ( To be verified if existing tools exist )\nDesired Outcome:\na. A fully functional system capable of generating and serving Cloud Optimized GeoTIFFs from INSAT data.\nb. Tools for real-time manipulation of multiple spectral bands.\nEnhanced accessibility and usability of INSAT satellite data for various applications"
  },
  {
    "A": "1739",
    "B": "Description: Building Integrated Photovoltaic (BIPV) systems are the solar power generating products or systems that are seamlessly integrated into the building envelop. The satellite data from Indian Satellites such as Cartosat-2/3 and Cartosat-1 are capable of generating 3D city models up to LoD-1. These LoD1 models, which are derived by extruding a footprint to a uniform height, can be used for simulating building shadows. This project aims to develop an interactive application for assessing BIPV potential using LOD-1 3D city model. It will involve simulating shadow of adjoining buildings on each face of the building and estimating incident solar energy on the vertical face of the building. The application will render the building surface according to available BIPV potential.\n Challenge:\n * 3D Visualisation of LOD-1 City Model\n * Simulating Building Shadows in 3D\n * 3D Rendering of BIPV Potential on Building\n Usage: Application of Space-based inputs for Renewable Energy\n Users: The application will be deployed on VEDAS portal's '3D City Model and Rooftop Solar Potential' application. It will be usefu for Policy-makers (State & Central Government), Solar Energy Solution Providers, Architects and citizens.\n Available Solutions (if Yes, reasons for not using them): Commercial Architectural Packages like Autodesk are suitable for building-level analysis and require substantial level of details. 3D GIS packages such as ESRI City Engine or Cesium provide visualisation capabilities. \n Software for city-wide BIPV potential estimation are currently not available in public domain.\n Desired Outcome: An interactive application where user provides a date (for calculating sun-position) and daily Global Horizontal Irradiation (GHI) value, and the application generates corresponding 3D city model rendered according to incident solar energy for that day. The application also provide total BIPV and rooftop PV energy potential available in the building."
  },
  {
    "A": "1740",
    "B": "Description: Algorithm development using AI-ML techniques to distinguish vehicular movement on highway and service road.\nChallenge: The algorithm shall be able to distinguish the vehicle movement on highway or service road even if intermittent GNSS position is not available or large bias is observed in GNSS coordinates.\nUsage: To support the applications such as GNSS-based tolling\nUsers: Vehicles moving on highways\nAvailable Solutions (if Yes, reasons for not using them): Not available as a comprehensive solution\nDesired Outcome: \nThe developed algorithm shall provide the following:\n1. Use the coarse GNSS position of the moving vehicle and plot the movement on a map\n2. Using map-matching techniques, identify the movement of vehicle on the highway or the service road\n3. Apply AI-ML techniques to improvement map-matching performance."
  },
  {
    "A": "1741",
    "B": "Description: Develop an application firewall for end-points that can identity and restrict access of application to external network/hosts. The application firewall should provide further granular control of restricting domains, IP addresses and protocols for each application. The firewall should be manageable through a centralized web console where policies for each end-point and application can be centrally deployed. Firewall agent should also be able to monitor network usage behaviour of each application and generate alerts on central dashboard for any traffic anomaly using AI/ML.\nChallenge: Applying separate firewall policies for each application running on the end-point and managing them through a central web console.\nUsage: End-point security, network security\nUsers: Cyber security teams\nAvailable Solutions (if Yes, reasons for not using them): Individual components are available\nDesired Outcome: The solution should provide following components:\n1. Solution should identify the domains and protocols that any application is trying to access. Further, it should enable allowing of any such network traffic which is not already allowed via centralized console.\n2. Context-aware application firewall agent that shall manage firewall policies for each application running on end-point. The agent shall also collect network usage logs of each application and send it to central server.\n3. Central web management console that shall be able to manage all end-points and applications\n4. Solution should work for Windows end-points. Bonus points for Linux\n5. Solution should also detect abnormal network behaviour of applications"
  },
  {
    "A": "1742",
    "B": "Background:\nODD School Structure refers to schools that do not conform to the standard categories\ndefined by the Ministry of Education under the UDISE+ portal. These standard categories are\ndesigned to align with the Samagra Shiksha framework, which aims to ensure uniformity\nand consistency in the educational structures across the country. Schools falling outside\nthese categories, due to variations in grade configurations, are classified as having \"\"odd\nstructures.\"\"\n\nHowever, 145,012 schools across the country fall into the \"\"odd\"\" school structure category\ndue to variations in grade configurations. These odd structures pose challenges for the\nuniform implementation of educational policies and schemes, such as Samagra Shiksha. This\nmisalignment is particularly significant in states like Goa, Mizoram, West Bengal, and Kerala,\nwhere the majority of schools do not conform to the standard categories.\n\nDescription:\nThe problem of odd school structures affects the equitable distribution of resources,\neffective policy implementation, and the overall quality of education. Schools with odd\nstructures are often excluded from the streamlined processes and benefits that come with\nstandardization. The national average of schools with odd structures is 14.28%, but in some\nstates, the percentage is much higher, complicating the delivery of educational initiatives.\nThe objective is to standardize these odd school structures by aligning them with the\ndefined categories under Samagra Shiksha, thereby improving the uniformity and\neffectiveness of educational policies across the country.\n\nInnovative Solutions:\n\nA. AI-Driven School Structure Analysis Tool: Develop software that uses AI to analyze\nschool data and automatically classify schools into standard categories or identify\nthem as odd structures. This tool can also suggest optimal restructuring options to\nalign schools with the standard categories.\nB. Standardization Support Platform: Create a platform that provides guidelines, best\npractices, and resources for schools to transition from odd to standard structures.\nThe platform could include modules on infrastructure planning, grade\nreconfiguration, and community engagement strategies.\nC. Dynamic Resource Allocation System: Develop a system that allows for flexible\nresource allocation based on school structures. This system would help in\ndistributing resources more equitably by taking into account the specific needs of\nschools with odd structures during the transition period.\nD. Progress Monitoring Dashboard: Implement a real-time dashboard for monitoring\nthe progress of schools as they transition from odd to standard structures. This\ndashboard would provide insights to policymakers and administrators, allowing them\nto track changes, identify bottlenecks, and intervene as necessary.\nE. Interactive Stakeholder Engagement Portal: Develop an online portal to engage with\nschool administrators, teachers, and the community. This portal could include\nforums, feedback tools, and support resources to facilitate the transition to standard\nstructures, ensuring that the process is inclusive and addresses local concerns."
  },
  {
    "A": "1743",
    "B": "During investigation when the social media accounts of accused/suspect are opened for examination or creating Panchnamas, it would be better if some tool is designed which can automatically parse the data and provide the screenshot of the posts, messages, timeline, friend list, following, followers, account info, etc and provide screenshots in a documented form.\n * The examiner may choose to print the screenshots as per requirements. This will omit any human error during the process and also help to thoroughly reviewing the data found for the said social media account.\n * Separate options for Facebook, Twitter, Instagram, Telegram, WhatsApp, Google account etc may be provided in the tool.\n * Many a times, the social media accounts do not open in Desktops even if we have the right credentials and the examiner have to use a dummy android phone. So, two separate versions (Android and windows) of this tool will be helpful."
  },
  {
    "A": "1744",
    "B": "To design and develop an innovative digital forensics and incident response tool with an intuitive and accessible interface for investigators, that streamlines the process of importing evidence, conducting automated analysis, and generating detailed reports. The tool should feature an interface with clear navigation & real-time data visualization and should support: 1. Automated data collection from RAW images (forensic images) and other formats using disk imaging tools 2. Automate the scanning and analysis of data, including files, system logs, registry entries, network activity etc. 3. Identify indicators of compromise (IOCs) and related suspicious activities 4. Integrate AI/ML algorithms for anomaly detection and pattern recognition. The AI/ML feature should incorporate a scoring system and recommendation engine that allow investigators to quickly focus on the important artifacts. 5. User-friendly review options should include interactive timelines and graphical summaries, while comprehensive reporting capabilities should allow exports in various formats such as PDF, JSON, and CSV."
  },
  {
    "A": "1745",
    "B": "Background: Dark web is being used for illegal purposes and number of market places are being operated by the underground operators which facilitate illegal buying/selling of drugs/weapons/data leaks/counterfeit moneys/documents etc. Platforms, being anonymise to the LEA, make it difficult to identify the market place running on dark web mainly TOR Network.\nDescription: Running the illegal sites on dark web network only requires the access of TOR Browser and TORRC file to run the market from local system. For hosting the services, people may utilise the paid or freely available hosting servers. Being on TOR network (V3), it is very difficult to identify the underground operator running the market. Amid running market on TOR network, the underground operator provides the access of his portal though his ISP/VPN services which has been taken from the respective ISP of his country and the VPN service provider.\nExpected Solution: It is expected that any solution like tool or technique may be developed the underground operator running the market may be identified. The participants may target finding the actual IP/VPN IP being used by the players of the onion sites. The participants may also try to find out other personally identifiable information (PII) regarding the underground operators active on the onion sites."
  },
  {
    "A": "1746",
    "B": "Background: Fuzzing is an automated process of identifying software vulnerabilities by supplying unexpected and faulty inputs to the software. The main aim of fuzzing is to identify the crucial edge cases where a software might fail. Therefore, fuzzing provides a crucial insight into the stability and security of the software. The process of fuzzing can be divided into following broad steps –\n1. Identification of Target Function(s) – Target function(s) are typically those functions that act as entry points for processing input data. They use various APIs to perform operation on the input data.\n2. Developing harness – Harnesses are small code stubs whose sole purpose is to invoke the target function by using mutated data inputs. A harness bridges the gap between how the fuzzer generates input and how the target application receives and processes the input.\n3. Fuzzing - In this step, a fuzzer is used to generate numerous data inputs which are then passed to the target function using the harness. The fuzzer checks whether the application crashes by processing a certain input. If a crash occurs, then it saves the input and the memory state of the crash to file for later analysis.\nDescription:\nFuzzing has proven its effectiveness in discovering thousands of vulnerabilities in file-processing and stateless applications. In fuzzing, and automated testing in general, designing test oracles is crucial. In this challenge the team is supposed to fuzz an open source software namely the Windows variant of Sumatra PDF Reader software (version 3.5.2 or later). Sumatra PDF Reader is a very popular open source and widely used PDF viewing software. In this challenge, teams are required to develop a working harness for fuzzing of the latest version (version 3.5.2 or later) of Windows Sumatra PDF Reader software solution, fuzzed on any fuzzer of their choice.\nThe submission will be evaluated on the following criteria –\n1. Target functions identified\n2. Live demonstration of fuzzing harness developed\n3. Code Coverage achieved\n4. Technical report submitted by the team.\nExpected Solution: Each team must provide a fuzzing harness that is capable of fuzzing the windows software solution of the Sumatra PDF Reader (version 3.5.2 or later). This fuzzing harness must identify target functions and supply appropriate arguments for the invocation of such functions. The fuzzing harness will be run using a fuzzer (preferably WinAFL). Each team must submit a working harness along with a technical report stating –\n1. Reversing steps undertaken\n2. Target functions identified\n3. Dependencies identified"
  },
  {
    "A": "1747",
    "B": "Background: It is a requirement for some organizations to add features by modifying an existing android application. The current security scenario requires a secure mobile operating environment and applications, allowing organizations to quickly modify the apps being used and also test their working on the latest versions of Android.\nDescription: A framework for adding new security features in an existing application is a valuable tool in the toolkit of android application developers. The challenge is to add new features and functionalities in the existing android applications for Android 14 or higher. This framework is required for adding layers of security to the app, known only to the user organization and catering to its specific requirements.\nExpected Solution: Web based framework for adding security layers in given APKs while maintaining their original functionalities is required. Modified APK should be able to function on Android 14 having access to all the system resources which the original APK has. Solutions will be evaluated based on the capabilities like feature addition without application crash, retaining functionality of the original app and quality of implementation of the framework"
  },
  {
    "A": "1748",
    "B": "Background: Android applications are increasingly becoming an integral part of daily life, offering various services and functionalities. However, their widespread use also makes them prime targets for security vulnerabilities. Identifying and mitigating these vulnerabilities during the development phase is crucial for ensuring the security and integrity of these applications. Static analysis provides a method to examine code for vulnerabilities without executing it, allowing developers to catch and fix security issues early.\nDetailed Description: This report outlines a comprehensive framework for conducting static analysis to detect vulnerabilities in Android applications. The framework covers the following key aspects:\n1.Preparation\nâ€¢ Gather Requirements: Define the scope and objectives of the static analysis process. Determine which parts of the application will be analyzed and the specific types of vulnerabilities to look for.\nâ€¢ Select Tools: Choose appropriate static analysis tools tailored for Android development such as MobSF, SonarQube, Android Lint, FindBugs, and PMD.\n2. Code Review\nâ€¢ Manual Code Review: Perform a thorough review of the source code to identify obvious security flaws. This step involves examining the code for insecure coding practices, such as hardcoded credentials, improper exception handling, and insecure data storage.\nâ€¢ Automated Static Analysis: Use automated tools to scan the codebase for vulnerabilities. These tools can quickly identify issues such as insecure API usage, improper permissions, and potential injection points.\n3. Configuration Analysis\nâ€¢ Manifest File Review: Analyze the AndroidManifest.xml file for insecure configurations, such as exported components that should be private, overly broad permissions, and improper use of intents.\nâ€¢ Build Configuration Review: Examine build.gradle files to ensure secure configurations and identify potential issues related to dependency management and build settings.\n4. Dependency Analysis\nâ€¢ Third-Party Libraries: Identify and evaluate third-party libraries for known vulnerabilities. Ensure that all dependencies are up-to-date and do not introduce security risks into the application.\n5. Reporting\nâ€¢ Document Findings: Prepare a detailed report outlining the identified vulnerabilities, their severity, and potential impact. The report should include specific examples of the code where vulnerabilities were found and explanations of why they pose a risk.\nâ€¢ Prioritize Issues: Rank vulnerabilities based on their severity and potential impact on the application. This helps in focusing remediation efforts on the most critical issues first.\n6. Mitigation and Remediation\nâ€¢ Propose Fixes: Provide specific recommendations for addressing the identified vulnerabilities. This includes suggesting secure coding practices, configuration changes, and updates to third-party libraries.\nâ€¢ Integrate Fixes: Work with the development team to integrate the recommended fixes into the codebase. This step may involve revising the application architecture, modifying code, and updating dependencies.\nExpected Solution:\n1.Early Detection of Vulnerabilities: Identifying security issues early in the development process, allowing for timely remediation.\n2. Improved Code Quality: Encouraging secure coding practices and reducing the likelihood of introducing security flaws.\n3. Increased Security Awareness: Raising awareness among developers about common security issues and how to avoid them.\n4.Enhanced Application Security: Reducing the risk of exploitation by addressing vulnerabilities before the application is deployed to production."
  },
  {
    "A": "1749",
    "B": "Background : Digital evidence has become increasingly crucial in forensic investigations. The recovery of deleted data from storage devices is essential for reconstructing timelines, identifying suspects, and uncovering critical information. Traditional file systems like FAT and NTFS have been extensively studied, and tools for recovering deleted data from them are relatively mature. However, modern file systems like XFS and Btrfs, designed for performance and reliability, employ complex data structures that pose signifycant challenges for data recovery.\nForensic investigations often involve recovering various file types, including documents files, log files, and system files. These files contain valuable information about system activities, user behaviour, and potential criminal activities. The ability to recover deleted files along with their complete metadata, such as creation, access, modification, and deletion timestamps, is crucial for establishing timelines and corroborating evidence.\nDetailed Description :XFS and Btrfs file systems offer advanced features like journaling, copy-on-write, and efficient data allocation. While these features enhance system performance and data integrity, they also complicate the process of recovering deleted data. When a file is deleted in these file systems, the data itself is not immediately erased; instead, the file system marks the allocated blocks as free for reuse. This delayed overwriting of data presents an opportunity for recovery, but it also requires specialized techniques to extract and analyse the deleted data.\nMoreover, recovering accurate metadata associated with deleted files is equally challenging. Metadata is critical for establishing the context of the recovered data and determining its relevance to the investigation. Extracting metadata from XFS and Btrfs file systems requires a deep understanding of their internal structures and data allocation mechanisms.\nExpected Solution: An ideal solution would be a comprehensive data recovery technique specifically designed for XFS and Btrfs file systems. These techniques should able to:\n1. Efficiently recover deleted data: Develop algorithms and techniques to identify and extract deleted files from the complex data structures of XFS and Btrfs.\n2. Support a wide range of file types: Recover Text-Based Document Formats(doc,docx, rtf, pdf, txt, odt, html, xml, ppt, odp, xls, ods, log, csv, tsv, txt, conf, ini, cfg etc), archives file(zip, tar, rar, iso, rpm, deb etc), Image-Based Document Formats(jpg, jpeg, png, gif, tif etc), executables binaries(.elf, .so, .a, exe, dll, bat, cmd) scripts files(ps, ps1, sh, bash, zsh, py etc), database file(.db etc) and other relevant data formats.\n3. Extract complete metadata: Recover accurate creation, access, modification, and deletion timestamps, file names, and other essential metadata associated with deleted files.\n4. Provide user-friendly interface: Offer an intuitive interface (GUI/CLI) for easily navigate recovered data and generate reports.\n5. Ensure data integrity: Implement robust data validation and verification mechanisms to maintain the integrity of recovered data."
  },
  {
    "A": "1750",
    "B": "Background: Web applications are ubiquitous and serve as the backbone for a myriad of online services. However, their complexity and extensive use make them prime targets for cyber-attacks. Hidden directories, virtual hosts, API endpoints, URL parameters, and subdomains can all harbour vulnerabilities that attackers might exploit. Identifying these vulnerabilities through comprehensive fuzzing can significantly enhance the security of web applications. A versatile fuzzer that automates the discovery and testing of these components is essential for proactive security measures.\nDetailed Description: This documentation outlines the development of a comprehensive web application fuzzer, detailing its functionalities and usage across various web application components:\n1. Preparation\no Gather Requirements: Define the objectives and scope of the fuzzing process. Identify the web application components to be tested and the types of vulnerabilities to target.\no Select Tools: Choose the appropriate fuzzing tools and libraries that support testing of directories, virtual hosts, API endpoints, URL parameters, custom test cases, and subdomains.\n2. Directories and Files\no Enumeration: Perform a systematic enumeration of directories and files to uncover hidden content. This involves brute-forcing directory names and file extensions to identify unlinked or forgotten resources.\no Testing: Test the discovered directories and files for common vulnerabilities such as directory traversal and insecure file uploads.\n3. Virtual Hosts (VHosts)\no Discovery: Identify virtual hosts configured on the server by fuzzing the Host header with various subdomain values.\no Assessment: Evaluate the discovered virtual hosts for configuration issues and vulnerabilities that might arise from improper isolation of web applications.\n4. API Endpoints\no Identification: Detect API endpoints by analyzing common patterns and URL structures used in the application.\no Vulnerability Testing: Test API endpoints for security flaws such as insecure data transmission, improper authentication, and authorization, as well as injection vulnerabilities.\n5. Parameters\no Fuzzing: Fuzz URL parameters to uncover vulnerabilities like SQL injection, cross-site scripting (XSS), remote code execution, and parameter pollution.\no Payloads: Use a variety of payloads and encoding techniques to ensure comprehensive coverage of potential attack vectors.\n6. Custom Test Cases\no User-Defined Scenarios: Allow users to create and integrate custom test cases to target specific application logic or unique vulnerabilities.\no Execution: Execute custom test cases in conjunction with standard fuzzing techniques to maximize the depth and breadth of security testing.\n7. Subdomains\no Discovery: Perform DNS enumeration and brute-forcing to identify subdomains associated with the main domain.\no Security Testing: Assess the discovered subdomains for common vulnerabilities and misconfigurations that could expose the application to risk.\n8. Reporting\no Document Findings: Prepare detailed reports highlighting identified vulnerabilities, their severity, and potential impact. Include specific examples and explanations to aid in understanding and remediation.\no Prioritize Issues: Rank the discovered vulnerabilities based on their severity and potential impact to help prioritize remediation efforts.\n9. Mitigation and Remediation\no Propose Fixes: Provide actionable recommendations for addressing the identified vulnerabilities, including secure coding practices, configuration adjustments, and updates to dependencies.\no Integrate Fixes: Collaborate with the development team to implement the recommended fixes, ensuring the application is secured before deployment.\nExpected Solution:\n1. Early Detection of Vulnerabilities: Identifying security issues early in the development process, allowing for timely remediation.\n2. Improved Code Quality: Encouraging secure coding practices and reducing the likelihood of introducing security flaws.\n3. Increased Security Awareness: Raising awareness among developers about common security issues and how to avoid them.\n4. Enhanced Application Security: Reducing the risk of exploitation by addressing vulnerabilities before the application is deployed to production."
  }
]
